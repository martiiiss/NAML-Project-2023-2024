{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB8IlWMiOCbW"
      },
      "source": [
        "#Forecasting spot electricity prices: Deep learning approaches and empirical comparison of traditional algorithms\n",
        "\n",
        "Deep Learning methods:\n",
        "1. A DNN as an extension to the traditional MLP.\n",
        "2. A hybrid LSTM-DNN structure.\n",
        "3. A hybrid GRU-DNN structure.\n",
        "4. A CNN model.\n",
        "\n",
        "Other benchmark models for electricy price forecasting.\n",
        "\n",
        "Performance metrics: sMAPE (symmetric mean absolute percentage error)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1aalrIQwxfI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Concatenate, GRU, Dropout, Conv1D, MaxPooling1D, BatchNormalization, Flatten, concatenate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.optimizers import Adam, schedules\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras import regularizers\n",
        "from sklearn.svm import SVR\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import zscore, boxcox\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ARXnb56GoQqT"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DmQLfasQziq"
      },
      "source": [
        "#Data\n",
        "Prices of Belgium, with generation forecast and system load forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovN6Gfo-O880",
        "outputId": "bdb86787-6d49-4435-e5e6-9202d35d03fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Date   Prices   Generation forecast   System load forecast\n",
            "0  2011-01-09 00:00:00    32.54               63065.0                63000.0\n",
            "1  2011-01-09 01:00:00    21.55               62715.0                58800.0\n",
            "2  2011-01-09 02:00:00    15.71               61952.0                58500.0\n",
            "3  2011-01-09 03:00:00    10.58               59262.0                54300.0\n",
            "4  2011-01-09 04:00:00    10.32               56883.0                51900.0\n"
          ]
        }
      ],
      "source": [
        "file_path = 'BE.csv'\n",
        "df = pd.read_csv(file_path, parse_dates=['Date'], dayfirst=True)# Load the dataset\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d8KSCxVi_Vn"
      },
      "source": [
        "### Pre-processing: outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "R_GJOXZoiGD7"
      },
      "outputs": [],
      "source": [
        "# Select only numeric columns from the DataFrame\n",
        "df_numeric = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate Z-scores\n",
        "z_scores = np.abs(zscore(df_numeric))\n",
        "threshold = 3 # threshold for considering a value as an outlier\n",
        "\n",
        "# Replace outliers with the median of the column\n",
        "df_cleaned = df_numeric.mask(z_scores > threshold, df_numeric.median(), axis=1)\n",
        "df[df_numeric.columns] = df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5VezzeLQdn7"
      },
      "source": [
        "### Training, validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWCZ7r6LQhJE",
        "outputId": "691b3b3e-760d-4a5c-9e93-f0267c0c7b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "                     Prices  Generation forecast  System load forecast\n",
            "Date                                                                  \n",
            "2011-01-09 00:00:00   32.54              63065.0               63000.0\n",
            "2011-01-09 01:00:00   21.55              62715.0               58800.0\n",
            "2011-01-09 02:00:00   15.71              61952.0               58500.0\n",
            "2011-01-09 03:00:00   10.58              59262.0               54300.0\n",
            "2011-01-09 04:00:00   10.32              56883.0               51900.0\n",
            "...                     ...                  ...                   ...\n",
            "2015-03-31 19:00:00   49.69              69195.0               58902.0\n",
            "2015-03-31 20:00:00   53.62              69539.0               58748.0\n",
            "2015-03-31 21:00:00   48.91              68972.0               59440.0\n",
            "2015-03-31 22:00:00   47.02              67632.0               56156.0\n",
            "2015-03-31 23:00:00   41.50              67361.0               59102.0\n",
            "\n",
            "[37032 rows x 3 columns]\n",
            "\n",
            "Validation set:\n",
            "                     Prices  Generation forecast  System load forecast\n",
            "Date                                                                  \n",
            "2015-04-01 00:00:00   37.00              64923.0               57447.0\n",
            "2015-04-01 01:00:00   29.70              61736.0               53630.0\n",
            "2015-04-01 02:00:00   25.01              60492.0               53725.0\n",
            "2015-04-01 03:00:00   22.51              59274.0               50950.0\n",
            "2015-04-01 04:00:00   22.00              60110.0               49061.0\n",
            "...                     ...                  ...                   ...\n",
            "2016-02-14 19:00:00   30.38              70114.0               67826.0\n",
            "2016-02-14 20:00:00   26.98              67172.0               67012.0\n",
            "2016-02-14 21:00:00   20.21              65201.0               64476.0\n",
            "2016-02-14 22:00:00   20.33              64519.0               62340.0\n",
            "2016-02-14 23:00:00   17.96              64240.0               66460.0\n",
            "\n",
            "[7680 rows x 3 columns]\n",
            "\n",
            "Test set:\n",
            "                     Prices  Generation forecast  System load forecast\n",
            "Date                                                                  \n",
            "2016-02-15 00:00:00   16.57              61194.0               64860.0\n",
            "2016-02-15 01:00:00   16.00              60536.0               61290.0\n",
            "2016-02-15 02:00:00   14.66              61089.0               62147.0\n",
            "2016-02-15 03:00:00   13.14              59256.0               58614.0\n",
            "2016-02-15 04:00:00   12.68              58614.0               56683.0\n",
            "...                     ...                  ...                   ...\n",
            "2016-12-31 19:00:00   40.84              70329.0               73957.0\n",
            "2016-12-31 20:00:00   40.10              69121.0               72544.0\n",
            "2016-12-31 21:00:00   36.00              66647.0               69451.0\n",
            "2016-12-31 22:00:00   35.00              65886.0               67823.0\n",
            "2016-12-31 23:00:00   34.94              66846.0               72876.0\n",
            "\n",
            "[7704 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define the split dates\n",
        "start_date = '2011-01-09'\n",
        "val_start = '2015-04-01'\n",
        "test_start = '2016-02-15'\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Filter the dataset based on the date ranges\n",
        "train_df = df[(df['Date'] >= start_date) & (df['Date'] < val_start)]\n",
        "val_df = df[(df['Date'] >= val_start) & (df['Date'] < test_start)]\n",
        "test_df = df[(df['Date'] >= test_start)]\n",
        "\n",
        "train_df.set_index('Date', inplace=True)\n",
        "val_df.set_index('Date', inplace=True)\n",
        "test_df.set_index('Date', inplace=True)\n",
        "\n",
        "\n",
        "# Display the results\n",
        "print(\"Training set:\")\n",
        "print(train_df)\n",
        "\n",
        "print(\"\\nValidation set:\")\n",
        "print(val_df)\n",
        "\n",
        "print(\"\\nTest set:\")\n",
        "print(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "900jp2ldSC6w"
      },
      "source": [
        "# sMAPE\n",
        "Accuracy sMAPE = symmetric mean absolute percentage error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "409E8M2CdvSK"
      },
      "outputs": [],
      "source": [
        "def smape(y_true, y_pred):\n",
        "    numerator = tf.abs(y_pred - y_true)\n",
        "    denominator = (tf.abs(y_true) + tf.abs(y_pred)) / 2.0\n",
        "    return tf.reduce_mean(numerator / (denominator)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTDzGCdE9qcM"
      },
      "source": [
        "#Deep Learning models:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDFTU4WsioOi"
      },
      "source": [
        "##DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxu0GrWSiWSC"
      },
      "outputs": [],
      "source": [
        "n1DNN = 239 # first hidden layer neurons\n",
        "n2DNN = 162 # second hidden layer neurons\n",
        "activationFunctionDNN = 'relu'\n",
        "n_hours = 24\n",
        "hours = range(n_hours)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySylWdbZD8b7"
      },
      "source": [
        "### X - input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLdJV0w6UBAI"
      },
      "source": [
        "I consider as input features:\n",
        "*   the day of the week of *D* (0 monday,...)\n",
        "*   the price of the previous day *D-1* for each hour (24)\n",
        "*   the price of the 2 previous day *D-2* for each hour (24)\n",
        "*   the price of the previous week *D-7* for each hour (24)\n",
        "*   the generation forecast of the day *D* (24)\n",
        "*   the load forecast of the day *D* (24)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3PEPdC_Tx53",
        "outputId": "8ddae493-3eed-4556-ecae-7c3f0b9b5cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n"
          ]
        }
      ],
      "source": [
        "n_features = 1+ 24 + 24 + 24 + 24 + 24\n",
        "print(n_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tloGJjv3D9MM"
      },
      "outputs": [],
      "source": [
        "# Define columns (date is the index)\n",
        "columns = ['Day'] + [f'Price_D-1_h{hour}' for hour in hours] + \\\n",
        "          [f'Price_D-2_h{hour}' for hour in hours] + \\\n",
        "          [f'Price_D-7_h{hour}' for hour in hours] + \\\n",
        "          [f'Generation_D_h{hour}' for hour in hours] + \\\n",
        "          [f'Load_D_h{hour}' for hour in hours]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UzqOswHK-mw"
      },
      "outputs": [],
      "source": [
        "train_df.index = pd.to_datetime(train_df.index)\n",
        "val_df.index = pd.to_datetime(val_df.index)\n",
        "test_df.index = pd.to_datetime(test_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3mD3a0bWCj1"
      },
      "outputs": [],
      "source": [
        "train_df.index = train_df.index.round('S')\n",
        "test_df.index = test_df.index.round('S')\n",
        "val_df.index = val_df.index.round('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak8oG0-gAp2R"
      },
      "outputs": [],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] + pd.Timedelta(weeks=1) :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "# I create dataframe where the index is the time where a prediction is made and the columns is the horizons of the prediction\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "Xtrain = np.zeros([indexTrain.shape[0], n_features])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "Xval = np.zeros([indexVal.shape[0], n_features])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "Xtest = np.zeros([indexTest.shape[0], n_features])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures = 0\n",
        "\n",
        "# Adding the day of the week as a feature if needed\n",
        "# For training, I assume the day of the week is a continuous variable.\n",
        "# So monday at 00 is 1. Monday at 1h is 1.04, Tuesday at 2h is 2.08, etc.\n",
        "Xtrain[:, 0] = indexTrain.index.dayofweek + indexTrain.index.hour / 24\n",
        "Xval[:, 0] = indexVal.index.dayofweek + indexVal.index.hour / 24\n",
        "Xtest[:, 0] = indexTest.index.dayofweek\n",
        "indexFeatures += 1\n",
        "\n",
        "# price D-1\n",
        "for past_day in [1, 2, 7]:\n",
        "  for hour in range(24): # For each possible horizon\n",
        "        # I define the corresponding past time indexs\n",
        "        pastIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)  - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "\n",
        "        # price D-1\n",
        "        Xtrain[:, indexFeatures] = train_df.loc[pastIndexTrain, 'Prices']\n",
        "        Xtest[:, indexFeatures] = test_df.loc[pastIndexTest, 'Prices']\n",
        "        Xval[:, indexFeatures] = val_df.loc[pastIndexVal, 'Prices']\n",
        "        indexFeatures += 1\n",
        "\n",
        "\n",
        "# Adding generation inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    # define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'Generation forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'Generation forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'Generation forecast']\n",
        "    indexFeatures += 1\n",
        "\n",
        "\n",
        "# adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    # define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNqdvXvjvB-Z"
      },
      "source": [
        "### Y - target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhqKD9XVFA8E"
      },
      "outputs": [],
      "source": [
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqsKoxpmqD9N"
      },
      "source": [
        "### Data Normalization\n",
        "Data preprocessing step: the data is normalized to the intervals [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jZ5Qiv0ZpPN"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
        "Xval_scaled = scaler.transform(Xval)\n",
        "Xtest_scaled = scaler.transform(Xtest)\n",
        "\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_6ercZlhRjf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "6fEPFtj1mx3-",
        "outputId": "9ba87108-2063-4e2f-e7fd-b817f2b05068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m239\u001b[0m)                 │          \u001b[38;5;34m29,158\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m162\u001b[0m)                 │          \u001b[38;5;34m38,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m3,912\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">239</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,158</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,912</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,950\u001b[0m (281.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,950</span> (281.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,950\u001b[0m (281.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,950</span> (281.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(n1DNN, activation=activationFunctionDNN, input_shape=(n_features,)),\n",
        "    Dense(n2DNN, activation=activationFunctionDNN),\n",
        "    Dense(n_hours)\n",
        "])\n",
        "# Compile the model with Mean Absolute Error as the Loss function\n",
        "opt = Adam(learning_rate = 1e-5)\n",
        "model.compile(optimizer=opt, loss='mean_absolute_error')  #, metrics=[smape])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8kC2akhXJB"
      },
      "source": [
        "### Training DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT_QeDF1hWtJ"
      },
      "outputs": [],
      "source": [
        "# Early stopping configuration\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DMvI7txszM_K",
        "outputId": "7c689aef-1459-49ac-a82e-4a64a6ba4ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.3027 - val_loss: 0.3341\n",
            "Epoch 2/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2920 - val_loss: 0.3249\n",
            "Epoch 3/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2822 - val_loss: 0.3163\n",
            "Epoch 4/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2731 - val_loss: 0.3083\n",
            "Epoch 5/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2646 - val_loss: 0.3007\n",
            "Epoch 6/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2567 - val_loss: 0.2934\n",
            "Epoch 7/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2493 - val_loss: 0.2864\n",
            "Epoch 8/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2422 - val_loss: 0.2796\n",
            "Epoch 9/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2355 - val_loss: 0.2731\n",
            "Epoch 10/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2292 - val_loss: 0.2667\n",
            "Epoch 11/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2233 - val_loss: 0.2606\n",
            "Epoch 12/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2176 - val_loss: 0.2546\n",
            "Epoch 13/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2123 - val_loss: 0.2489\n",
            "Epoch 14/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2073 - val_loss: 0.2433\n",
            "Epoch 15/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2026 - val_loss: 0.2379\n",
            "Epoch 16/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1982 - val_loss: 0.2326\n",
            "Epoch 17/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1940 - val_loss: 0.2276\n",
            "Epoch 18/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1900 - val_loss: 0.2228\n",
            "Epoch 19/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1864 - val_loss: 0.2182\n",
            "Epoch 20/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1830 - val_loss: 0.2138\n",
            "Epoch 21/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1798 - val_loss: 0.2096\n",
            "Epoch 22/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1768 - val_loss: 0.2057\n",
            "Epoch 23/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1740 - val_loss: 0.2018\n",
            "Epoch 24/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1713 - val_loss: 0.1982\n",
            "Epoch 25/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1688 - val_loss: 0.1948\n",
            "Epoch 26/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1665 - val_loss: 0.1915\n",
            "Epoch 27/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1643 - val_loss: 0.1885\n",
            "Epoch 28/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1622 - val_loss: 0.1856\n",
            "Epoch 29/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1603 - val_loss: 0.1829\n",
            "Epoch 30/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1585 - val_loss: 0.1804\n",
            "Epoch 31/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1568 - val_loss: 0.1781\n",
            "Epoch 32/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1552 - val_loss: 0.1760\n",
            "Epoch 33/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1537 - val_loss: 0.1742\n",
            "Epoch 34/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1523 - val_loss: 0.1726\n",
            "Epoch 35/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1510 - val_loss: 0.1711\n",
            "Epoch 36/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1498 - val_loss: 0.1698\n",
            "Epoch 37/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1487 - val_loss: 0.1686\n",
            "Epoch 38/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1476 - val_loss: 0.1675\n",
            "Epoch 39/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1467 - val_loss: 0.1665\n",
            "Epoch 40/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1457 - val_loss: 0.1657\n",
            "Epoch 41/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1448 - val_loss: 0.1649\n",
            "Epoch 42/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1439 - val_loss: 0.1642\n",
            "Epoch 43/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1431 - val_loss: 0.1636\n",
            "Epoch 44/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1423 - val_loss: 0.1629\n",
            "Epoch 45/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1415 - val_loss: 0.1623\n",
            "Epoch 46/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1408 - val_loss: 0.1617\n",
            "Epoch 47/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1401 - val_loss: 0.1611\n",
            "Epoch 48/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1394 - val_loss: 0.1606\n",
            "Epoch 49/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1387 - val_loss: 0.1601\n",
            "Epoch 50/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1381 - val_loss: 0.1596\n",
            "Epoch 51/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1375 - val_loss: 0.1592\n",
            "Epoch 52/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1369 - val_loss: 0.1587\n",
            "Epoch 53/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1363 - val_loss: 0.1582\n",
            "Epoch 54/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1357 - val_loss: 0.1578\n",
            "Epoch 55/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1352 - val_loss: 0.1574\n",
            "Epoch 56/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1347 - val_loss: 0.1570\n",
            "Epoch 57/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1342 - val_loss: 0.1567\n",
            "Epoch 58/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1337 - val_loss: 0.1563\n",
            "Epoch 59/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1332 - val_loss: 0.1560\n",
            "Epoch 60/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1328 - val_loss: 0.1556\n",
            "Epoch 61/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1323 - val_loss: 0.1553\n",
            "Epoch 62/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1319 - val_loss: 0.1550\n",
            "Epoch 63/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1315 - val_loss: 0.1547\n",
            "Epoch 64/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1311 - val_loss: 0.1545\n",
            "Epoch 65/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1307 - val_loss: 0.1542\n",
            "Epoch 66/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1303 - val_loss: 0.1540\n",
            "Epoch 67/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1300 - val_loss: 0.1537\n",
            "Epoch 68/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1296 - val_loss: 0.1535\n",
            "Epoch 69/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1293 - val_loss: 0.1532\n",
            "Epoch 70/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1290 - val_loss: 0.1530\n",
            "Epoch 71/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1286 - val_loss: 0.1528\n",
            "Epoch 72/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1283 - val_loss: 0.1526\n",
            "Epoch 73/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1280 - val_loss: 0.1525\n",
            "Epoch 74/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1277 - val_loss: 0.1523\n",
            "Epoch 75/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1274 - val_loss: 0.1521\n",
            "Epoch 76/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1271 - val_loss: 0.1520\n",
            "Epoch 77/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1268 - val_loss: 0.1518\n",
            "Epoch 78/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1265 - val_loss: 0.1516\n",
            "Epoch 79/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1263 - val_loss: 0.1515\n",
            "Epoch 80/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1260 - val_loss: 0.1513\n",
            "Epoch 81/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1257 - val_loss: 0.1512\n",
            "Epoch 82/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1255 - val_loss: 0.1511\n",
            "Epoch 83/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1252 - val_loss: 0.1509\n",
            "Epoch 84/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1250 - val_loss: 0.1508\n",
            "Epoch 85/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1247 - val_loss: 0.1507\n",
            "Epoch 86/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1245 - val_loss: 0.1505\n",
            "Epoch 87/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1242 - val_loss: 0.1504\n",
            "Epoch 88/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1240 - val_loss: 0.1503\n",
            "Epoch 89/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1238 - val_loss: 0.1502\n",
            "Epoch 90/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1235 - val_loss: 0.1501\n",
            "Epoch 91/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1233 - val_loss: 0.1499\n",
            "Epoch 92/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1231 - val_loss: 0.1498\n",
            "Epoch 93/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1229 - val_loss: 0.1497\n",
            "Epoch 94/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1227 - val_loss: 0.1496\n",
            "Epoch 95/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1225 - val_loss: 0.1495\n",
            "Epoch 96/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1222 - val_loss: 0.1495\n",
            "Epoch 97/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1220 - val_loss: 0.1494\n",
            "Epoch 98/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1218 - val_loss: 0.1493\n",
            "Epoch 99/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1216 - val_loss: 0.1492\n",
            "Epoch 100/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1214 - val_loss: 0.1492\n",
            "Epoch 101/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1212 - val_loss: 0.1491\n",
            "Epoch 102/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1210 - val_loss: 0.1490\n",
            "Epoch 103/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1209 - val_loss: 0.1489\n",
            "Epoch 104/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1207 - val_loss: 0.1488\n",
            "Epoch 105/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1205 - val_loss: 0.1488\n",
            "Epoch 106/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1203 - val_loss: 0.1487\n",
            "Epoch 107/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1201 - val_loss: 0.1486\n",
            "Epoch 108/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1199 - val_loss: 0.1486\n",
            "Epoch 109/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1198 - val_loss: 0.1485\n",
            "Epoch 110/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1196 - val_loss: 0.1484\n",
            "Epoch 111/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1194 - val_loss: 0.1484\n",
            "Epoch 112/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1193 - val_loss: 0.1483\n",
            "Epoch 113/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1191 - val_loss: 0.1482\n",
            "Epoch 114/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1189 - val_loss: 0.1482\n",
            "Epoch 115/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1188 - val_loss: 0.1481\n",
            "Epoch 116/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1186 - val_loss: 0.1481\n",
            "Epoch 117/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1185 - val_loss: 0.1480\n",
            "Epoch 118/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1183 - val_loss: 0.1479\n",
            "Epoch 119/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1181 - val_loss: 0.1479\n",
            "Epoch 120/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1180 - val_loss: 0.1478\n",
            "Epoch 121/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1178 - val_loss: 0.1478\n",
            "Epoch 122/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1177 - val_loss: 0.1478\n",
            "Epoch 123/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1176 - val_loss: 0.1477\n",
            "Epoch 124/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1174 - val_loss: 0.1477\n",
            "Epoch 125/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1173 - val_loss: 0.1476\n",
            "Epoch 126/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1171 - val_loss: 0.1476\n",
            "Epoch 127/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1170 - val_loss: 0.1475\n",
            "Epoch 128/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1168 - val_loss: 0.1475\n",
            "Epoch 129/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1167 - val_loss: 0.1475\n",
            "Epoch 130/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1166 - val_loss: 0.1474\n",
            "Epoch 131/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1164 - val_loss: 0.1474\n",
            "Epoch 132/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1163 - val_loss: 0.1474\n",
            "Epoch 133/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1162 - val_loss: 0.1473\n",
            "Epoch 134/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1160 - val_loss: 0.1473\n",
            "Epoch 135/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1159 - val_loss: 0.1473\n",
            "Epoch 136/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1158 - val_loss: 0.1472\n",
            "Epoch 137/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1156 - val_loss: 0.1472\n",
            "Epoch 138/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1155 - val_loss: 0.1471\n",
            "Epoch 139/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1154 - val_loss: 0.1471\n",
            "Epoch 140/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1153 - val_loss: 0.1471\n",
            "Epoch 141/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1151 - val_loss: 0.1470\n",
            "Epoch 142/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1150 - val_loss: 0.1470\n",
            "Epoch 143/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1149 - val_loss: 0.1469\n",
            "Epoch 144/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1148 - val_loss: 0.1469\n",
            "Epoch 145/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1147 - val_loss: 0.1468\n",
            "Epoch 146/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1145 - val_loss: 0.1468\n",
            "Epoch 147/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1144 - val_loss: 0.1468\n",
            "Epoch 148/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1143 - val_loss: 0.1467\n",
            "Epoch 149/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1142 - val_loss: 0.1467\n",
            "Epoch 150/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1141 - val_loss: 0.1467\n",
            "Epoch 151/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1140 - val_loss: 0.1466\n",
            "Epoch 152/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1139 - val_loss: 0.1466\n",
            "Epoch 153/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1138 - val_loss: 0.1466\n",
            "Epoch 154/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1137 - val_loss: 0.1465\n",
            "Epoch 155/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1135 - val_loss: 0.1465\n",
            "Epoch 156/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1134 - val_loss: 0.1465\n",
            "Epoch 157/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1133 - val_loss: 0.1464\n",
            "Epoch 158/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1132 - val_loss: 0.1464\n",
            "Epoch 159/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1131 - val_loss: 0.1464\n",
            "Epoch 160/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1130 - val_loss: 0.1463\n",
            "Epoch 161/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1129 - val_loss: 0.1463\n",
            "Epoch 162/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1128 - val_loss: 0.1463\n",
            "Epoch 163/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1127 - val_loss: 0.1463\n",
            "Epoch 164/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1126 - val_loss: 0.1463\n",
            "Epoch 165/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1125 - val_loss: 0.1462\n",
            "Epoch 166/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1124 - val_loss: 0.1462\n",
            "Epoch 167/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1123 - val_loss: 0.1462\n",
            "Epoch 168/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1123 - val_loss: 0.1462\n",
            "Epoch 169/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1122 - val_loss: 0.1461\n",
            "Epoch 170/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1121 - val_loss: 0.1461\n",
            "Epoch 171/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1120 - val_loss: 0.1461\n",
            "Epoch 172/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1119 - val_loss: 0.1461\n",
            "Epoch 173/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1118 - val_loss: 0.1460\n",
            "Epoch 174/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1117 - val_loss: 0.1460\n",
            "Epoch 175/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1116 - val_loss: 0.1460\n",
            "Epoch 176/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1115 - val_loss: 0.1460\n",
            "Epoch 177/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1114 - val_loss: 0.1459\n",
            "Epoch 178/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1113 - val_loss: 0.1459\n",
            "Epoch 179/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1112 - val_loss: 0.1459\n",
            "Epoch 180/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1112 - val_loss: 0.1459\n",
            "Epoch 181/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - val_loss: 0.1459\n",
            "Epoch 182/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1110 - val_loss: 0.1459\n",
            "Epoch 183/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1109 - val_loss: 0.1458\n",
            "Epoch 184/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1108 - val_loss: 0.1458\n",
            "Epoch 185/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1107 - val_loss: 0.1458\n",
            "Epoch 186/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1107 - val_loss: 0.1458\n",
            "Epoch 187/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1106 - val_loss: 0.1458\n",
            "Epoch 188/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1105 - val_loss: 0.1457\n",
            "Epoch 189/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1104 - val_loss: 0.1457\n",
            "Epoch 190/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1103 - val_loss: 0.1457\n",
            "Epoch 191/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1102 - val_loss: 0.1457\n",
            "Epoch 192/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1102 - val_loss: 0.1456\n",
            "Epoch 193/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1101 - val_loss: 0.1456\n",
            "Epoch 194/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1100 - val_loss: 0.1456\n",
            "Epoch 195/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1099 - val_loss: 0.1455\n",
            "Epoch 196/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1099 - val_loss: 0.1455\n",
            "Epoch 197/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1098 - val_loss: 0.1455\n",
            "Epoch 198/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1097 - val_loss: 0.1455\n",
            "Epoch 199/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1096 - val_loss: 0.1454\n",
            "Epoch 200/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1095 - val_loss: 0.1454\n",
            "Epoch 201/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1095 - val_loss: 0.1454\n",
            "Epoch 202/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1094 - val_loss: 0.1454\n",
            "Epoch 203/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1093 - val_loss: 0.1453\n",
            "Epoch 204/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1093 - val_loss: 0.1453\n",
            "Epoch 205/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1092 - val_loss: 0.1453\n",
            "Epoch 206/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1091 - val_loss: 0.1453\n",
            "Epoch 207/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1090 - val_loss: 0.1453\n",
            "Epoch 208/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1090 - val_loss: 0.1453\n",
            "Epoch 209/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1089 - val_loss: 0.1452\n",
            "Epoch 210/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1088 - val_loss: 0.1452\n",
            "Epoch 211/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1087 - val_loss: 0.1452\n",
            "Epoch 212/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1087 - val_loss: 0.1452\n",
            "Epoch 213/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1086 - val_loss: 0.1452\n",
            "Epoch 214/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1085 - val_loss: 0.1451\n",
            "Epoch 215/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1085 - val_loss: 0.1451\n",
            "Epoch 216/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1084 - val_loss: 0.1451\n",
            "Epoch 217/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1083 - val_loss: 0.1451\n",
            "Epoch 218/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1083 - val_loss: 0.1451\n",
            "Epoch 219/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1082 - val_loss: 0.1451\n",
            "Epoch 220/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1081 - val_loss: 0.1451\n",
            "Epoch 221/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1080 - val_loss: 0.1450\n",
            "Epoch 222/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1080 - val_loss: 0.1450\n",
            "Epoch 223/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1079 - val_loss: 0.1450\n",
            "Epoch 224/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1078 - val_loss: 0.1450\n",
            "Epoch 225/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1078 - val_loss: 0.1450\n",
            "Epoch 226/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1077 - val_loss: 0.1449\n",
            "Epoch 227/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1077 - val_loss: 0.1449\n",
            "Epoch 228/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1076 - val_loss: 0.1449\n",
            "Epoch 229/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1075 - val_loss: 0.1449\n",
            "Epoch 230/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1075 - val_loss: 0.1449\n",
            "Epoch 231/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1074 - val_loss: 0.1448\n",
            "Epoch 232/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1073 - val_loss: 0.1448\n",
            "Epoch 233/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1073 - val_loss: 0.1448\n",
            "Epoch 234/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1072 - val_loss: 0.1448\n",
            "Epoch 235/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1071 - val_loss: 0.1448\n",
            "Epoch 236/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1071 - val_loss: 0.1448\n",
            "Epoch 237/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1070 - val_loss: 0.1448\n",
            "Epoch 238/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1070 - val_loss: 0.1447\n",
            "Epoch 239/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1069 - val_loss: 0.1447\n",
            "Epoch 240/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1068 - val_loss: 0.1447\n",
            "Epoch 241/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1068 - val_loss: 0.1447\n",
            "Epoch 242/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.1447\n",
            "Epoch 243/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.1447\n",
            "Epoch 244/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1066 - val_loss: 0.1447\n",
            "Epoch 245/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1065 - val_loss: 0.1446\n",
            "Epoch 246/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1065 - val_loss: 0.1446\n",
            "Epoch 247/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1064 - val_loss: 0.1446\n",
            "Epoch 248/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1064 - val_loss: 0.1446\n",
            "Epoch 249/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1063 - val_loss: 0.1446\n",
            "Epoch 250/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1062 - val_loss: 0.1446\n",
            "Epoch 251/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1062 - val_loss: 0.1445\n",
            "Epoch 252/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1061 - val_loss: 0.1445\n",
            "Epoch 253/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1061 - val_loss: 0.1445\n",
            "Epoch 254/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1060 - val_loss: 0.1445\n",
            "Epoch 255/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1060 - val_loss: 0.1445\n",
            "Epoch 256/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1059 - val_loss: 0.1445\n",
            "Epoch 257/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1058 - val_loss: 0.1445\n",
            "Epoch 258/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1058 - val_loss: 0.1444\n",
            "Epoch 259/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1057 - val_loss: 0.1444\n",
            "Epoch 260/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1057 - val_loss: 0.1444\n",
            "Epoch 261/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1056 - val_loss: 0.1444\n",
            "Epoch 262/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1056 - val_loss: 0.1444\n",
            "Epoch 263/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1055 - val_loss: 0.1444\n",
            "Epoch 264/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1055 - val_loss: 0.1444\n",
            "Epoch 265/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1054 - val_loss: 0.1444\n",
            "Epoch 266/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1053 - val_loss: 0.1443\n",
            "Epoch 267/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1053 - val_loss: 0.1443\n",
            "Epoch 268/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1052 - val_loss: 0.1443\n",
            "Epoch 269/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1052 - val_loss: 0.1443\n",
            "Epoch 270/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1051 - val_loss: 0.1443\n",
            "Epoch 271/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1051 - val_loss: 0.1443\n",
            "Epoch 272/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1050 - val_loss: 0.1443\n",
            "Epoch 273/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1050 - val_loss: 0.1443\n",
            "Epoch 274/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1049 - val_loss: 0.1442\n",
            "Epoch 275/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1049 - val_loss: 0.1442\n",
            "Epoch 276/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1048 - val_loss: 0.1442\n",
            "Epoch 277/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1048 - val_loss: 0.1442\n",
            "Epoch 278/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1047 - val_loss: 0.1442\n",
            "Epoch 279/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1047 - val_loss: 0.1442\n",
            "Epoch 280/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1046 - val_loss: 0.1442\n",
            "Epoch 281/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1046 - val_loss: 0.1442\n",
            "Epoch 282/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1045 - val_loss: 0.1442\n",
            "Epoch 283/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1045 - val_loss: 0.1441\n",
            "Epoch 284/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1044 - val_loss: 0.1441\n",
            "Epoch 285/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1044 - val_loss: 0.1441\n",
            "Epoch 286/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1043 - val_loss: 0.1441\n",
            "Epoch 287/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1043 - val_loss: 0.1441\n",
            "Epoch 288/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1042 - val_loss: 0.1441\n",
            "Epoch 289/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1042 - val_loss: 0.1441\n",
            "Epoch 290/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1041 - val_loss: 0.1441\n",
            "Epoch 291/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1041 - val_loss: 0.1440\n",
            "Epoch 292/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1040 - val_loss: 0.1440\n",
            "Epoch 293/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1040 - val_loss: 0.1440\n",
            "Epoch 294/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1039 - val_loss: 0.1440\n",
            "Epoch 295/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1039 - val_loss: 0.1440\n",
            "Epoch 296/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1038 - val_loss: 0.1440\n",
            "Epoch 297/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1038 - val_loss: 0.1440\n",
            "Epoch 298/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1037 - val_loss: 0.1440\n",
            "Epoch 299/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1037 - val_loss: 0.1440\n",
            "Epoch 300/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1036 - val_loss: 0.1440\n",
            "Epoch 301/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1036 - val_loss: 0.1440\n",
            "Epoch 302/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1035 - val_loss: 0.1440\n",
            "Epoch 303/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1035 - val_loss: 0.1440\n",
            "Epoch 304/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1034 - val_loss: 0.1440\n",
            "Epoch 305/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1034 - val_loss: 0.1440\n",
            "Epoch 306/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1033 - val_loss: 0.1439\n",
            "Epoch 307/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1033 - val_loss: 0.1439\n",
            "Epoch 308/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1033 - val_loss: 0.1439\n",
            "Epoch 309/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1032 - val_loss: 0.1439\n",
            "Epoch 310/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1032 - val_loss: 0.1439\n",
            "Epoch 311/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1031 - val_loss: 0.1439\n",
            "Epoch 312/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1031 - val_loss: 0.1439\n",
            "Epoch 313/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1030 - val_loss: 0.1439\n",
            "Epoch 314/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1030 - val_loss: 0.1439\n",
            "Epoch 315/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1029 - val_loss: 0.1439\n",
            "Epoch 316/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1029 - val_loss: 0.1439\n",
            "Epoch 317/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1028 - val_loss: 0.1439\n",
            "Epoch 318/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1028 - val_loss: 0.1438\n",
            "Epoch 319/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1027 - val_loss: 0.1438\n",
            "Epoch 320/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1027 - val_loss: 0.1438\n",
            "Epoch 321/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1027 - val_loss: 0.1438\n",
            "Epoch 322/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1026 - val_loss: 0.1438\n",
            "Epoch 323/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1026 - val_loss: 0.1438\n",
            "Epoch 324/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1025 - val_loss: 0.1438\n",
            "Epoch 325/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1025 - val_loss: 0.1438\n",
            "Epoch 326/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1024 - val_loss: 0.1438\n",
            "Epoch 327/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1024 - val_loss: 0.1438\n",
            "Epoch 328/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1023 - val_loss: 0.1437\n",
            "Epoch 329/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1023 - val_loss: 0.1438\n",
            "Epoch 330/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1023 - val_loss: 0.1438\n",
            "Epoch 331/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1022 - val_loss: 0.1438\n",
            "Epoch 332/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1022 - val_loss: 0.1437\n",
            "Epoch 333/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1021 - val_loss: 0.1437\n",
            "Epoch 334/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1021 - val_loss: 0.1437\n",
            "Epoch 335/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1020 - val_loss: 0.1437\n",
            "Epoch 336/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1020 - val_loss: 0.1437\n",
            "Epoch 337/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1019 - val_loss: 0.1437\n",
            "Epoch 338/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1019 - val_loss: 0.1437\n",
            "Epoch 339/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1019 - val_loss: 0.1437\n",
            "Epoch 340/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1018 - val_loss: 0.1437\n",
            "Epoch 341/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1018 - val_loss: 0.1437\n",
            "Epoch 342/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1017 - val_loss: 0.1437\n",
            "Epoch 343/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1017 - val_loss: 0.1437\n",
            "Epoch 344/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1016 - val_loss: 0.1437\n",
            "Epoch 345/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1016 - val_loss: 0.1437\n",
            "Epoch 346/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1016 - val_loss: 0.1437\n",
            "Epoch 347/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1015 - val_loss: 0.1436\n",
            "Epoch 348/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1015 - val_loss: 0.1437\n",
            "Epoch 349/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1014 - val_loss: 0.1436\n",
            "Epoch 350/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1014 - val_loss: 0.1437\n",
            "Epoch 351/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1013 - val_loss: 0.1436\n",
            "Epoch 352/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1013 - val_loss: 0.1436\n",
            "Epoch 353/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1013 - val_loss: 0.1436\n",
            "Epoch 354/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1012 - val_loss: 0.1436\n",
            "Epoch 355/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1012 - val_loss: 0.1436\n",
            "Epoch 356/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1011 - val_loss: 0.1436\n",
            "Epoch 357/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1011 - val_loss: 0.1436\n",
            "Epoch 358/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1011 - val_loss: 0.1436\n",
            "Epoch 359/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1010 - val_loss: 0.1436\n",
            "Epoch 360/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1010 - val_loss: 0.1436\n",
            "Epoch 361/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1009 - val_loss: 0.1436\n",
            "Epoch 362/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1009 - val_loss: 0.1436\n",
            "Epoch 363/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1009 - val_loss: 0.1436\n",
            "Epoch 364/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1008 - val_loss: 0.1436\n",
            "Epoch 365/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1008 - val_loss: 0.1436\n",
            "Epoch 366/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1007 - val_loss: 0.1435\n",
            "Epoch 367/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1007 - val_loss: 0.1436\n",
            "Epoch 368/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1007 - val_loss: 0.1436\n",
            "Epoch 369/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1006 - val_loss: 0.1435\n",
            "Epoch 370/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1006 - val_loss: 0.1435\n",
            "Epoch 371/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1005 - val_loss: 0.1435\n",
            "Epoch 372/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1005 - val_loss: 0.1435\n",
            "Epoch 373/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1005 - val_loss: 0.1435\n",
            "Epoch 374/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1004 - val_loss: 0.1435\n",
            "Epoch 375/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1004 - val_loss: 0.1435\n",
            "Epoch 376/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1004 - val_loss: 0.1435\n",
            "Epoch 377/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1003 - val_loss: 0.1435\n",
            "Epoch 378/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1003 - val_loss: 0.1435\n",
            "Epoch 379/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1002 - val_loss: 0.1435\n",
            "Epoch 380/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1002 - val_loss: 0.1435\n",
            "Epoch 381/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1002 - val_loss: 0.1435\n",
            "Epoch 382/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1001 - val_loss: 0.1435\n",
            "Epoch 383/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1001 - val_loss: 0.1435\n",
            "Epoch 384/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1000 - val_loss: 0.1435\n",
            "Epoch 385/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1000 - val_loss: 0.1435\n",
            "Epoch 386/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1000 - val_loss: 0.1435\n",
            "Epoch 387/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0999 - val_loss: 0.1435\n",
            "Epoch 388/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0999 - val_loss: 0.1435\n",
            "Epoch 389/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0999 - val_loss: 0.1435\n",
            "Epoch 390/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0998 - val_loss: 0.1435\n",
            "Epoch 391/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0998 - val_loss: 0.1435\n",
            "Epoch 392/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0997 - val_loss: 0.1434\n",
            "Epoch 393/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0997 - val_loss: 0.1434\n",
            "Epoch 394/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0997 - val_loss: 0.1434\n",
            "Epoch 395/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0996 - val_loss: 0.1434\n",
            "Epoch 396/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0996 - val_loss: 0.1434\n",
            "Epoch 397/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0996 - val_loss: 0.1434\n",
            "Epoch 398/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0995 - val_loss: 0.1434\n",
            "Epoch 399/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0995 - val_loss: 0.1434\n",
            "Epoch 400/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0994 - val_loss: 0.1434\n",
            "Epoch 401/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0994 - val_loss: 0.1434\n",
            "Epoch 402/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0994 - val_loss: 0.1434\n",
            "Epoch 403/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0993 - val_loss: 0.1434\n",
            "Epoch 404/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0993 - val_loss: 0.1434\n",
            "Epoch 405/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0993 - val_loss: 0.1434\n",
            "Epoch 406/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0992 - val_loss: 0.1434\n",
            "Epoch 407/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0992 - val_loss: 0.1434\n",
            "Epoch 408/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0992 - val_loss: 0.1434\n",
            "Epoch 409/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0991 - val_loss: 0.1434\n",
            "Epoch 410/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0991 - val_loss: 0.1434\n",
            "Epoch 411/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0990 - val_loss: 0.1434\n",
            "Epoch 412/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0990 - val_loss: 0.1433\n",
            "Epoch 413/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0990 - val_loss: 0.1433\n",
            "Epoch 414/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0989 - val_loss: 0.1433\n",
            "Epoch 415/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0989 - val_loss: 0.1433\n",
            "Epoch 416/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0989 - val_loss: 0.1433\n",
            "Epoch 417/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0988 - val_loss: 0.1433\n",
            "Epoch 418/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0988 - val_loss: 0.1433\n",
            "Epoch 419/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0988 - val_loss: 0.1433\n",
            "Epoch 420/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0987 - val_loss: 0.1433\n",
            "Epoch 421/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0987 - val_loss: 0.1433\n",
            "Epoch 422/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0987 - val_loss: 0.1433\n",
            "Epoch 423/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0986 - val_loss: 0.1433\n",
            "Epoch 424/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0986 - val_loss: 0.1433\n",
            "Epoch 425/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0985 - val_loss: 0.1433\n",
            "Epoch 426/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0985 - val_loss: 0.1433\n",
            "Epoch 427/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0985 - val_loss: 0.1433\n",
            "Epoch 428/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0984 - val_loss: 0.1432\n",
            "Epoch 429/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0984 - val_loss: 0.1432\n",
            "Epoch 430/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0984 - val_loss: 0.1432\n",
            "Epoch 431/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0983 - val_loss: 0.1433\n",
            "Epoch 432/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0983 - val_loss: 0.1433\n",
            "Epoch 433/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0983 - val_loss: 0.1432\n",
            "Epoch 434/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0982 - val_loss: 0.1433\n",
            "Epoch 435/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0982 - val_loss: 0.1432\n",
            "Epoch 436/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0982 - val_loss: 0.1432\n",
            "Epoch 437/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0981 - val_loss: 0.1432\n",
            "Epoch 438/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0981 - val_loss: 0.1432\n",
            "Epoch 439/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0981 - val_loss: 0.1432\n",
            "Epoch 440/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0980 - val_loss: 0.1432\n",
            "Epoch 441/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0980 - val_loss: 0.1432\n",
            "Epoch 442/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0980 - val_loss: 0.1432\n",
            "Epoch 443/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0979 - val_loss: 0.1432\n",
            "Epoch 444/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0979 - val_loss: 0.1432\n",
            "Epoch 445/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0979 - val_loss: 0.1432\n",
            "Epoch 446/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0978 - val_loss: 0.1432\n",
            "Epoch 447/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0978 - val_loss: 0.1432\n",
            "Epoch 448/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0978 - val_loss: 0.1432\n",
            "Epoch 449/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0977 - val_loss: 0.1432\n",
            "Epoch 450/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0977 - val_loss: 0.1432\n",
            "Epoch 451/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0977 - val_loss: 0.1432\n",
            "Epoch 452/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0976 - val_loss: 0.1432\n",
            "Epoch 453/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0976 - val_loss: 0.1432\n",
            "Epoch 454/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0975 - val_loss: 0.1432\n",
            "Epoch 455/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0975 - val_loss: 0.1432\n",
            "Epoch 456/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0975 - val_loss: 0.1431\n",
            "Epoch 457/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0975 - val_loss: 0.1431\n",
            "Epoch 458/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0974 - val_loss: 0.1431\n",
            "Epoch 459/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0974 - val_loss: 0.1431\n",
            "Epoch 460/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0974 - val_loss: 0.1431\n",
            "Epoch 461/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0973 - val_loss: 0.1431\n",
            "Epoch 462/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0973 - val_loss: 0.1431\n",
            "Epoch 463/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0973 - val_loss: 0.1432\n",
            "Epoch 464/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0972 - val_loss: 0.1432\n",
            "Epoch 465/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0972 - val_loss: 0.1431\n",
            "Epoch 466/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0972 - val_loss: 0.1431\n",
            "Epoch 467/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0971 - val_loss: 0.1431\n",
            "Epoch 468/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0971 - val_loss: 0.1431\n",
            "Epoch 469/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0971 - val_loss: 0.1431\n",
            "Epoch 470/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0970 - val_loss: 0.1431\n",
            "Epoch 471/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0970 - val_loss: 0.1431\n",
            "Epoch 472/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0970 - val_loss: 0.1431\n",
            "Epoch 473/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0969 - val_loss: 0.1431\n",
            "Epoch 474/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0969 - val_loss: 0.1431\n",
            "Epoch 475/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0969 - val_loss: 0.1431\n",
            "Epoch 476/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0968 - val_loss: 0.1431\n",
            "Epoch 477/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0968 - val_loss: 0.1431\n",
            "Epoch 478/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0968 - val_loss: 0.1431\n",
            "Epoch 479/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0967 - val_loss: 0.1431\n",
            "Epoch 480/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0967 - val_loss: 0.1430\n",
            "Epoch 481/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0967 - val_loss: 0.1431\n",
            "Epoch 482/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0967 - val_loss: 0.1431\n",
            "Epoch 483/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0966 - val_loss: 0.1431\n",
            "Epoch 484/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0966 - val_loss: 0.1431\n",
            "Epoch 485/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0966 - val_loss: 0.1431\n",
            "Epoch 486/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0965 - val_loss: 0.1431\n",
            "Epoch 487/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0965 - val_loss: 0.1430\n",
            "Epoch 488/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0965 - val_loss: 0.1430\n",
            "Epoch 489/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0964 - val_loss: 0.1430\n",
            "Epoch 490/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0964 - val_loss: 0.1430\n",
            "Epoch 491/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0964 - val_loss: 0.1430\n",
            "Epoch 492/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1430\n",
            "Epoch 493/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1430\n",
            "Epoch 494/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1430\n",
            "Epoch 495/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1430\n",
            "Epoch 496/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0962 - val_loss: 0.1430\n",
            "Epoch 497/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0962 - val_loss: 0.1430\n",
            "Epoch 498/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0962 - val_loss: 0.1430\n",
            "Epoch 499/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.1430\n",
            "Epoch 500/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.1430\n",
            "Epoch 501/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.1430\n",
            "Epoch 502/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0960 - val_loss: 0.1430\n",
            "Epoch 503/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0960 - val_loss: 0.1430\n",
            "Epoch 504/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0960 - val_loss: 0.1430\n",
            "Epoch 505/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0960 - val_loss: 0.1430\n",
            "Epoch 506/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0959 - val_loss: 0.1430\n",
            "Epoch 507/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0959 - val_loss: 0.1430\n",
            "Epoch 508/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0959 - val_loss: 0.1430\n",
            "Epoch 509/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0958 - val_loss: 0.1430\n",
            "Epoch 510/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0958 - val_loss: 0.1430\n",
            "Epoch 511/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0958 - val_loss: 0.1430\n",
            "Epoch 512/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0957 - val_loss: 0.1430\n",
            "Epoch 513/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0957 - val_loss: 0.1430\n",
            "Epoch 514/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0957 - val_loss: 0.1430\n",
            "Epoch 515/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0956 - val_loss: 0.1430\n",
            "Epoch 516/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0956 - val_loss: 0.1430\n",
            "Epoch 517/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0956 - val_loss: 0.1430\n",
            "Epoch 518/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0956 - val_loss: 0.1430\n",
            "Epoch 519/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0955 - val_loss: 0.1430\n",
            "Epoch 520/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0955 - val_loss: 0.1430\n",
            "Epoch 521/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0955 - val_loss: 0.1430\n",
            "Epoch 522/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0954 - val_loss: 0.1430\n",
            "Epoch 523/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0954 - val_loss: 0.1430\n",
            "Epoch 524/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0954 - val_loss: 0.1430\n",
            "Epoch 525/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0954 - val_loss: 0.1430\n",
            "Epoch 526/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0953 - val_loss: 0.1429\n",
            "Epoch 527/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0953 - val_loss: 0.1429\n",
            "Epoch 528/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0953 - val_loss: 0.1430\n",
            "Epoch 529/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0952 - val_loss: 0.1430\n",
            "Epoch 530/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0952 - val_loss: 0.1430\n",
            "Epoch 531/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0952 - val_loss: 0.1430\n",
            "Epoch 532/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0952 - val_loss: 0.1430\n",
            "Epoch 533/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0951 - val_loss: 0.1429\n",
            "Epoch 534/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0951 - val_loss: 0.1429\n",
            "Epoch 535/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0951 - val_loss: 0.1429\n",
            "Epoch 536/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0950 - val_loss: 0.1429\n",
            "Epoch 537/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.1429\n",
            "Epoch 538/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.1429\n",
            "Epoch 539/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0950 - val_loss: 0.1429\n",
            "Epoch 540/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0949 - val_loss: 0.1429\n",
            "Epoch 541/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0949 - val_loss: 0.1429\n",
            "Epoch 542/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0949 - val_loss: 0.1429\n",
            "Epoch 543/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0948 - val_loss: 0.1429\n",
            "Epoch 544/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0948 - val_loss: 0.1429\n",
            "Epoch 545/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0948 - val_loss: 0.1429\n",
            "Epoch 546/1000\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0948 - val_loss: 0.1429\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(Xtrain_scaled, Ytrain,\n",
        "                    epochs=1000,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(Xval_scaled, Yval),\n",
        "                    shuffle = True,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRL7firwfCr2"
      },
      "source": [
        "The loss and smape refer to training set, while val_loss and val_smape refer to validation set.\n",
        "\n",
        "It stops before, due to the early stopping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMN6Oo-RfBJm"
      },
      "source": [
        "### Prediction and sMAPE:\n",
        "Performance evaluation of DNN model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yrSKIHVxnCg",
        "outputId": "4cb56c92-3859-4e5f-96af-806695900a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Valori Attesi  Predizioni\n",
            "0            7.72   13.831306\n",
            "1            8.35    8.466706\n",
            "2            7.15   11.236300\n",
            "3            4.97    3.315855\n",
            "4            5.39    4.164815\n",
            "5            8.38    8.306069\n",
            "6           18.05   22.706499\n",
            "7           26.38   38.279140\n",
            "8           27.92   38.789413\n",
            "9           31.97   41.816132\n",
            "10          32.96   38.793087\n",
            "11          29.76   39.968140\n",
            "12          27.53   46.327732\n",
            "13          24.52   39.292965\n",
            "14          23.98   38.132641\n",
            "15          23.91   34.156353\n",
            "16          23.92   38.273258\n",
            "17          27.93   41.376175\n",
            "18          40.13   54.990059\n",
            "19          39.45   51.598274\n",
            "sMAPE: 16.28%\n"
          ]
        }
      ],
      "source": [
        "Yp = model.predict(Xtest_scaled, verbose=0).squeeze()\n",
        "Yp = y_scaler.inverse_transform(Yp).squeeze()\n",
        "\n",
        "# To print some predicted values\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhOnP6AZitME"
      },
      "source": [
        "##LSTM-DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "7uQxNKTYiusD"
      },
      "outputs": [],
      "source": [
        "activationFunctionDNN = 'relu'\n",
        "activationFunctionLSTM = 'tanh'\n",
        "nDNN = 184\n",
        "nLSTM = 83\n",
        "sequenceLength = 336  #hours for 2 weeks\n",
        "n_hours = 24\n",
        "hours = range(n_hours)\n",
        "\n",
        "timesteps = sequenceLength  # 2 weeks of hourly data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wNzJF6b0Ie2"
      },
      "source": [
        "###X_F - day-ahead input\n",
        "Data: are divided into:\n",
        "*   Future information (X_F)\n",
        "*   A collection of input sequence, each one representing past information (X_S)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "ppK38nDG1aSy"
      },
      "outputs": [],
      "source": [
        "columns_X_F = ['Day'] +  \\\n",
        "          [f'Generation_D_h{hour}' for hour in hours] + \\\n",
        "          [f'Load_D_h{hour}' for hour in hours]\n",
        "\n",
        "n_features_F = len(columns_X_F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "_LPzTeAp1f11"
      },
      "outputs": [],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] :].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] :].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "# I create dataframe where the index is the time where a prediction is made and the columns is the horizons of the prediction\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "X_F_train = np.zeros([indexTrain.shape[0], n_features_F])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "X_F_val = np.zeros([indexVal.shape[0], n_features_F])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "X_F_test = np.zeros([indexTest.shape[0], n_features_F])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures_F = 0\n",
        "\n",
        "\n",
        "# Adding the day of the week as a feature\n",
        "X_F_train[:, 0] = indexTrain.index.dayofweek\n",
        "X_F_val[:, 0] = indexVal.index.dayofweek\n",
        "X_F_test[:, 0] = indexTest.index.dayofweek\n",
        "indexFeatures_F += 1\n",
        "\n",
        "\n",
        "# Adding generation inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    X_F_train[:, indexFeatures_F] = train_df.loc[futureIndexTrain, 'Generation forecast']\n",
        "    X_F_val[:, indexFeatures_F] = val_df.loc[futureIndexVal, 'Generation forecast']\n",
        "    X_F_test[:, indexFeatures_F] = test_df.loc[futureIndexTest, 'Generation forecast']\n",
        "    indexFeatures_F += 1\n",
        "\n",
        "\n",
        "#adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    X_F_train[:, indexFeatures_F] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    X_F_val[:, indexFeatures_F] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    X_F_test[:, indexFeatures_F] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures_F += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFSna5CD4ykH",
        "outputId": "01bcf9ca-592a-4d52-f7de-448cc3a1b0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 49)\n",
            "(319, 49)\n",
            "(320, 49)\n"
          ]
        }
      ],
      "source": [
        "print(X_F_train.shape) # from 10/01/2011\n",
        "print(X_F_val.shape)\n",
        "print(X_F_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9oeWIHq5hwk"
      },
      "source": [
        "### Y - target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "qwtEL2WM5pJh"
      },
      "outputs": [],
      "source": [
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_B-1tJX7N_7",
        "outputId": "c5e1d572-85d8-483c-e3b1-ca77cae741cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 24)\n",
            "(319, 24)\n",
            "(320, 24)\n"
          ]
        }
      ],
      "source": [
        "print(Ytrain.shape)\n",
        "print(Yval.shape)\n",
        "print(Ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMPsuul97WDC"
      },
      "source": [
        "### X_S - past informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn8qdSZUqfC9",
        "outputId": "9190b0cd-ef4a-4135-a8ee-62597de76fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1529, 336, 1)\n",
            "(306, 336, 1)\n",
            "(307, 336, 1)\n"
          ]
        }
      ],
      "source": [
        "#past information (collection of past values) = sequential inputs --> LSTM\n",
        "#group by timesteps\n",
        "def create_sequences(data, steps):\n",
        "    X = []\n",
        "    for i in range(steps, len(data), n_hours):\n",
        "      X.append(data.iloc[i-steps:i].values)\n",
        "    return np.array(X)\n",
        "\n",
        "# Creazione di X_S per il training, validation e test set\n",
        "X_S_train = create_sequences(train_df[['Prices']], timesteps) #start from 23/01/211 to 31/12/2014\n",
        "X_S_val = create_sequences(val_df[['Prices']], timesteps)\n",
        "X_S_test = create_sequences(test_df[['Prices']], timesteps)\n",
        "\n",
        "print(X_S_train.shape)\n",
        "print(X_S_val.shape)\n",
        "print(X_S_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfojB7H48GpX"
      },
      "source": [
        "The size of X_S, X_F and Y have to match:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F6dlgabHMHM",
        "outputId": "0458d9d1-bfb3-4cb6-bd30-2de16547023e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1529, 49)\n",
            "(306, 49)\n",
            "(307, 49)\n",
            "(1529, 24)\n",
            "(306, 24)\n",
            "(307, 24)\n"
          ]
        }
      ],
      "source": [
        "X_F_train = X_F_train[13:]   # Remove the first 13 days\n",
        "X_F_val = X_F_val[13:]\n",
        "X_F_test = X_F_test[13:]\n",
        "Ytrain = Ytrain[13:]   # Remove the first 13 days\n",
        "Yval = Yval[13:]\n",
        "Ytest = Ytest[13:]\n",
        "print(X_F_train.shape)\n",
        "print(X_F_val.shape)\n",
        "print(X_F_test.shape)\n",
        "print(Ytrain.shape)\n",
        "print(Yval.shape)\n",
        "print(Ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd8sAUv49whf",
        "outputId": "167d80d3-4d8a-4102-e710-ad850ce5fcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "49\n"
          ]
        }
      ],
      "source": [
        "x_seq_num_features = X_S_train.shape[2]\n",
        "x_non_seq_num_features = X_F_train.shape[1]\n",
        "print(x_seq_num_features)\n",
        "print(x_non_seq_num_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ndpewo2_Bs0"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "IWhPxtrF_Ath"
      },
      "outputs": [],
      "source": [
        "# Scale X_F\n",
        "scaler_F = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_F_train = scaler_F.fit_transform(X_F_train)\n",
        "X_F_val = scaler_F.transform(X_F_val)\n",
        "X_F_test = scaler_F.transform(X_F_test)\n",
        "\n",
        "# Scale X_S\n",
        "scale_S = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_S_train = scale_S.fit_transform(X_S_train.reshape(-1, x_seq_num_features)).reshape(X_S_train.shape)\n",
        "X_S_val = scale_S.transform(X_S_val.reshape(-1, x_seq_num_features)).reshape(X_S_val.shape)\n",
        "X_S_test = scale_S.transform(X_S_test.reshape(-1, x_seq_num_features)).reshape(X_S_test.shape)\n",
        "\n",
        "# Scale the target values\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slaScZxv_oAd"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "K13edkfx2QzA",
        "outputId": "ff34e190-4b99-4d1e-fd54-68542b4fca67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m336\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ non_sequential_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)             │         \u001b[38;5;34m28,220\u001b[0m │ sequential_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ DNN (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m184\u001b[0m)            │          \u001b[38;5;34m9,200\u001b[0m │ non_sequential_input[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concat (\u001b[38;5;33mConcatenate\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m267\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], DNN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │          \u001b[38;5;34m6,432\u001b[0m │ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ non_sequential_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">28,220</span> │ sequential_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ DNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,200</span> │ non_sequential_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">267</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], DNN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432</span> │ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,852\u001b[0m (171.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,852</span> (171.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,852\u001b[0m (171.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,852</span> (171.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#sequential input for LSTM\n",
        "seq_input = Input(shape=(timesteps, x_seq_num_features), name = 'sequential_input')\n",
        "lstm_out = LSTM(units=nLSTM, activation=activationFunctionLSTM, return_sequences=False, name = 'lstm')(seq_input)\n",
        "\n",
        "# Non-sequential input for DNN\n",
        "non_seq_input = Input(shape=(x_non_seq_num_features,), name='non_sequential_input')  # Number of non-sequential features\n",
        "dnn_out = Dense(units=nDNN, activation=activationFunctionDNN, name='DNN')(non_seq_input)\n",
        "\n",
        "# Concatenate the outputs of LSTM and DNN\n",
        "concat = Concatenate(name = 'concat')([lstm_out, dnn_out])\n",
        "\n",
        "# Output layer\n",
        "out = Dense(units=n_hours, activation = 'linear', name = 'output')(concat)\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs=[seq_input, non_seq_input], outputs=out)\n",
        "\n",
        "# Compile the model\n",
        "#opt = Adam(learning_rate = 1e-4)\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDUyHZqv_jVI"
      },
      "source": [
        "### Training LSTM-DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "qO7tA_cIxcO2"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_schedule = ReduceLROnPlateau(monitor='val_loss',  factor=0.6, patience=12, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z7CpNZaEu__3",
        "outputId": "62e60a36-babd-480a-f942-5696935fe2bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 512ms/step - loss: 0.2564 - val_loss: 0.2037 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 661ms/step - loss: 0.1734 - val_loss: 0.1721 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 487ms/step - loss: 0.1415 - val_loss: 0.1645 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.1322 - val_loss: 0.1577 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 583ms/step - loss: 0.1279 - val_loss: 0.1525 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 667ms/step - loss: 0.1247 - val_loss: 0.1530 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - loss: 0.1228 - val_loss: 0.1516 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 666ms/step - loss: 0.1217 - val_loss: 0.1505 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 515ms/step - loss: 0.1204 - val_loss: 0.1493 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.1195 - val_loss: 0.1483 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 877ms/step - loss: 0.1184 - val_loss: 0.1478 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 657ms/step - loss: 0.1175 - val_loss: 0.1467 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 491ms/step - loss: 0.1170 - val_loss: 0.1466 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - loss: 0.1162 - val_loss: 0.1454 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 817ms/step - loss: 0.1156 - val_loss: 0.1456 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 488ms/step - loss: 0.1148 - val_loss: 0.1447 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 663ms/step - loss: 0.1142 - val_loss: 0.1457 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 489ms/step - loss: 0.1132 - val_loss: 0.1460 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 666ms/step - loss: 0.1124 - val_loss: 0.1454 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 487ms/step - loss: 0.1123 - val_loss: 0.1435 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 640ms/step - loss: 0.1118 - val_loss: 0.1421 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 491ms/step - loss: 0.1109 - val_loss: 0.1450 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - loss: 0.1104 - val_loss: 0.1417 - learning_rate: 0.0010\n",
            "Epoch 24/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 666ms/step - loss: 0.1101 - val_loss: 0.1435 - learning_rate: 0.0010\n",
            "Epoch 25/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - loss: 0.1096 - val_loss: 0.1431 - learning_rate: 0.0010\n",
            "Epoch 26/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - loss: 0.1089 - val_loss: 0.1431 - learning_rate: 0.0010\n",
            "Epoch 27/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 660ms/step - loss: 0.1089 - val_loss: 0.1428 - learning_rate: 0.0010\n",
            "Epoch 28/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 492ms/step - loss: 0.1082 - val_loss: 0.1420 - learning_rate: 0.0010\n",
            "Epoch 29/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 584ms/step - loss: 0.1082 - val_loss: 0.1428 - learning_rate: 0.0010\n",
            "Epoch 30/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 663ms/step - loss: 0.1081 - val_loss: 0.1425 - learning_rate: 0.0010\n",
            "Epoch 31/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 490ms/step - loss: 0.1073 - val_loss: 0.1416 - learning_rate: 0.0010\n",
            "Epoch 32/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 575ms/step - loss: 0.1071 - val_loss: 0.1413 - learning_rate: 0.0010\n",
            "Epoch 33/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 501ms/step - loss: 0.1068 - val_loss: 0.1418 - learning_rate: 0.0010\n",
            "Epoch 34/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - loss: 0.1061 - val_loss: 0.1413 - learning_rate: 0.0010\n",
            "Epoch 35/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 666ms/step - loss: 0.1057 - val_loss: 0.1414 - learning_rate: 0.0010\n",
            "Epoch 36/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - loss: 0.1054 - val_loss: 0.1415 - learning_rate: 0.0010\n",
            "Epoch 37/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 498ms/step - loss: 0.1052 - val_loss: 0.1413 - learning_rate: 0.0010\n",
            "Epoch 38/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 491ms/step - loss: 0.1049 - val_loss: 0.1412 - learning_rate: 0.0010\n",
            "Epoch 39/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 669ms/step - loss: 0.1046 - val_loss: 0.1411 - learning_rate: 0.0010\n",
            "Epoch 40/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 489ms/step - loss: 0.1044 - val_loss: 0.1410 - learning_rate: 0.0010\n",
            "Epoch 41/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 607ms/step - loss: 0.1039 - val_loss: 0.1409 - learning_rate: 0.0010\n",
            "Epoch 42/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 667ms/step - loss: 0.1037 - val_loss: 0.1407 - learning_rate: 0.0010\n",
            "Epoch 43/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - loss: 0.1034 - val_loss: 0.1409 - learning_rate: 0.0010\n",
            "Epoch 44/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - loss: 0.1031 - val_loss: 0.1409 - learning_rate: 0.0010\n",
            "Epoch 45/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - loss: 0.1029 - val_loss: 0.1409 - learning_rate: 0.0010\n",
            "Epoch 46/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 809ms/step - loss: 0.1027 - val_loss: 0.1404 - learning_rate: 0.0010\n",
            "Epoch 47/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 491ms/step - loss: 0.1024 - val_loss: 0.1403 - learning_rate: 0.0010\n",
            "Epoch 48/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 642ms/step - loss: 0.1023 - val_loss: 0.1402 - learning_rate: 0.0010\n",
            "Epoch 49/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 490ms/step - loss: 0.1022 - val_loss: 0.1402 - learning_rate: 0.0010\n",
            "Epoch 50/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 652ms/step - loss: 0.1023 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 51/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 560ms/step - loss: 0.1019 - val_loss: 0.1400 - learning_rate: 0.0010\n",
            "Epoch 52/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 487ms/step - loss: 0.1016 - val_loss: 0.1393 - learning_rate: 0.0010\n",
            "Epoch 53/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - loss: 0.1013 - val_loss: 0.1404 - learning_rate: 0.0010\n",
            "Epoch 54/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - loss: 0.1013 - val_loss: 0.1396 - learning_rate: 0.0010\n",
            "Epoch 55/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 520ms/step - loss: 0.1011 - val_loss: 0.1401 - learning_rate: 0.0010\n",
            "Epoch 56/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.1009 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 57/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.1006 - val_loss: 0.1387 - learning_rate: 0.0010\n",
            "Epoch 58/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 531ms/step - loss: 0.1005 - val_loss: 0.1389 - learning_rate: 0.0010\n",
            "Epoch 59/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 519ms/step - loss: 0.1003 - val_loss: 0.1391 - learning_rate: 0.0010\n",
            "Epoch 60/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - loss: 0.1001 - val_loss: 0.1392 - learning_rate: 0.0010\n",
            "Epoch 61/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.1000 - val_loss: 0.1389 - learning_rate: 0.0010\n",
            "Epoch 62/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 524ms/step - loss: 0.0999 - val_loss: 0.1394 - learning_rate: 0.0010\n",
            "Epoch 63/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 663ms/step - loss: 0.0999 - val_loss: 0.1390 - learning_rate: 0.0010\n",
            "Epoch 64/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 501ms/step - loss: 0.0997 - val_loss: 0.1393 - learning_rate: 0.0010\n",
            "Epoch 65/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 612ms/step - loss: 0.0997 - val_loss: 0.1383 - learning_rate: 0.0010\n",
            "Epoch 66/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 486ms/step - loss: 0.0995 - val_loss: 0.1389 - learning_rate: 0.0010\n",
            "Epoch 67/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 649ms/step - loss: 0.0996 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 68/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 573ms/step - loss: 0.0992 - val_loss: 0.1388 - learning_rate: 0.0010\n",
            "Epoch 69/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 490ms/step - loss: 0.0989 - val_loss: 0.1387 - learning_rate: 0.0010\n",
            "Epoch 70/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - loss: 0.0990 - val_loss: 0.1394 - learning_rate: 0.0010\n",
            "Epoch 71/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 529ms/step - loss: 0.0992 - val_loss: 0.1385 - learning_rate: 0.0010\n",
            "Epoch 72/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 665ms/step - loss: 0.0987 - val_loss: 0.1386 - learning_rate: 0.0010\n",
            "Epoch 73/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 503ms/step - loss: 0.0985 - val_loss: 0.1382 - learning_rate: 0.0010\n",
            "Epoch 74/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 619ms/step - loss: 0.0984 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 75/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 635ms/step - loss: 0.0986 - val_loss: 0.1389 - learning_rate: 0.0010\n",
            "Epoch 76/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 492ms/step - loss: 0.0983 - val_loss: 0.1398 - learning_rate: 0.0010\n",
            "Epoch 77/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 593ms/step - loss: 0.0987 - val_loss: 0.1378 - learning_rate: 0.0010\n",
            "Epoch 78/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 708ms/step - loss: 0.0980 - val_loss: 0.1382 - learning_rate: 0.0010\n",
            "Epoch 79/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 496ms/step - loss: 0.0978 - val_loss: 0.1380 - learning_rate: 0.0010\n",
            "Epoch 80/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - loss: 0.0977 - val_loss: 0.1382 - learning_rate: 0.0010\n",
            "Epoch 81/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 663ms/step - loss: 0.0976 - val_loss: 0.1386 - learning_rate: 0.0010\n",
            "Epoch 82/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 495ms/step - loss: 0.0975 - val_loss: 0.1376 - learning_rate: 0.0010\n",
            "Epoch 83/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - loss: 0.0972 - val_loss: 0.1380 - learning_rate: 0.0010\n",
            "Epoch 84/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - loss: 0.0970 - val_loss: 0.1383 - learning_rate: 0.0010\n",
            "Epoch 85/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 551ms/step - loss: 0.0969 - val_loss: 0.1379 - learning_rate: 0.0010\n",
            "Epoch 86/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 667ms/step - loss: 0.0968 - val_loss: 0.1374 - learning_rate: 0.0010\n",
            "Epoch 87/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 490ms/step - loss: 0.0969 - val_loss: 0.1382 - learning_rate: 0.0010\n",
            "Epoch 88/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 485ms/step - loss: 0.0970 - val_loss: 0.1374 - learning_rate: 0.0010\n",
            "Epoch 89/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 636ms/step - loss: 0.0969 - val_loss: 0.1378 - learning_rate: 0.0010\n",
            "Epoch 90/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 598ms/step - loss: 0.0967 - val_loss: 0.1378 - learning_rate: 0.0010\n",
            "Epoch 91/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 490ms/step - loss: 0.0967 - val_loss: 0.1377 - learning_rate: 0.0010\n",
            "Epoch 92/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - loss: 0.0971 - val_loss: 0.1398 - learning_rate: 0.0010\n",
            "Epoch 93/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 525ms/step - loss: 0.0973 - val_loss: 0.1376 - learning_rate: 0.0010\n",
            "Epoch 94/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 658ms/step - loss: 0.0966 - val_loss: 0.1375 - learning_rate: 0.0010\n",
            "Epoch 95/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504ms/step - loss: 0.0962 - val_loss: 0.1396 - learning_rate: 0.0010\n",
            "Epoch 96/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - loss: 0.0962 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 97/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 484ms/step - loss: 0.0961 - val_loss: 0.1369 - learning_rate: 0.0010\n",
            "Epoch 98/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 541ms/step - loss: 0.0957 - val_loss: 0.1379 - learning_rate: 0.0010\n",
            "Epoch 99/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0956 - val_loss: 0.1364 - learning_rate: 0.0010\n",
            "Epoch 100/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 486ms/step - loss: 0.0956 - val_loss: 0.1406 - learning_rate: 0.0010\n",
            "Epoch 101/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - loss: 0.0959 - val_loss: 0.1381 - learning_rate: 0.0010\n",
            "Epoch 102/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 669ms/step - loss: 0.0953 - val_loss: 0.1389 - learning_rate: 0.0010\n",
            "Epoch 103/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - loss: 0.0953 - val_loss: 0.1383 - learning_rate: 0.0010\n",
            "Epoch 104/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 492ms/step - loss: 0.0953 - val_loss: 0.1375 - learning_rate: 0.0010\n",
            "Epoch 105/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 670ms/step - loss: 0.0950 - val_loss: 0.1374 - learning_rate: 0.0010\n",
            "Epoch 106/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 492ms/step - loss: 0.0951 - val_loss: 0.1374 - learning_rate: 0.0010\n",
            "Epoch 107/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 858ms/step - loss: 0.0950 - val_loss: 0.1373 - learning_rate: 0.0010\n",
            "Epoch 108/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 496ms/step - loss: 0.0949 - val_loss: 0.1390 - learning_rate: 0.0010\n",
            "Epoch 109/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - loss: 0.0949 - val_loss: 0.1415 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#training the model\n",
        "history = model.fit([X_S_train, X_F_train], # sequential and non-sequential inputs\n",
        "                    [Ytrain],\n",
        "                    validation_data=([X_S_val, X_F_val], Yval),\n",
        "                    epochs=1000,\n",
        "                    batch_size=128,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[early_stopping, lr_schedule]\n",
        ")\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVVnrOvCFTGR"
      },
      "source": [
        "### Prediction and sMAPE\n",
        "Performance evaluation of the hybrid LSTM-DNN model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoV9v6Q5vDBa",
        "outputId": "b4b23356-80d4-4a6a-e03f-2bae05a0a805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Valori Attesi  Predizioni\n",
            "0           22.86   19.698660\n",
            "1           18.84   19.001488\n",
            "2           17.60   17.762600\n",
            "3           17.42   12.600945\n",
            "4           17.01   11.039365\n",
            "5           20.00   18.196604\n",
            "6           28.23   34.959118\n",
            "7           35.72   48.653522\n",
            "8           34.00   51.674606\n",
            "9           31.49   50.114826\n",
            "10          30.63   49.472092\n",
            "11          30.12   45.788429\n",
            "12          27.69   43.456726\n",
            "13          24.50   45.673431\n",
            "14          22.76   38.502262\n",
            "15          22.78   35.770264\n",
            "16          23.40   33.818298\n",
            "17          26.58   40.386745\n",
            "18          34.03   56.527328\n",
            "19          41.54   61.430523\n",
            "sMAPE: 18.59%\n"
          ]
        }
      ],
      "source": [
        "Yp = model.predict([X_S_test, X_F_test], verbose=0).squeeze()\n",
        "Yp = y_scaler.inverse_transform(Yp).squeeze()\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geEXOMurivCu"
      },
      "source": [
        "##GRU-DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "FV3erE9RizCI"
      },
      "outputs": [],
      "source": [
        "activationFunctionDNN = 'relu'\n",
        "activationFunctionGRU = 'tanh'\n",
        "dropoutGRUDNN = 0.32\n",
        "nDNN = 166\n",
        "nGRU = 132\n",
        "sequenceLength = 504  # 3 weeks of hourly data\n",
        "n_hours = 24\n",
        "hours = range(n_hours)\n",
        "timesteps = sequenceLength  # 3 weeks of hourly data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phG-BrSO63Fg"
      },
      "source": [
        "###X_F - day-ahead input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "vgny7-FF7RMC"
      },
      "outputs": [],
      "source": [
        "columns_X_F = ['Day'] +  \\\n",
        "          [f'Generation_D_h{hour}' for hour in hours] + \\\n",
        "          [f'Load_D_h{hour}' for hour in hours]\n",
        "\n",
        "n_features_F = len(columns_X_F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "3vS-KQXq62Zo"
      },
      "outputs": [],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] :].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] :].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "X_F_train = np.zeros([indexTrain.shape[0], n_features_F])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "X_F_val = np.zeros([indexVal.shape[0], n_features_F])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "X_F_test = np.zeros([indexTest.shape[0], n_features_F])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures_F = 0\n",
        "\n",
        "\n",
        "# Adding the day of the week as a feature\n",
        "X_F_train[:, 0] = indexTrain.index.dayofweek\n",
        "X_F_val[:, 0] = indexVal.index.dayofweek\n",
        "X_F_test[:, 0] = indexTest.index.dayofweek\n",
        "indexFeatures_F += 1\n",
        "\n",
        "\n",
        "# Adding generation inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    X_F_train[:, indexFeatures_F] = train_df.loc[futureIndexTrain, 'Generation forecast']\n",
        "    X_F_val[:, indexFeatures_F] = val_df.loc[futureIndexVal, 'Generation forecast']\n",
        "    X_F_test[:, indexFeatures_F] = test_df.loc[futureIndexTest, 'Generation forecast']\n",
        "    indexFeatures_F += 1\n",
        "\n",
        "\n",
        "#adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    X_F_train[:, indexFeatures_F] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    X_F_val[:, indexFeatures_F] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    X_F_test[:, indexFeatures_F] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures_F += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48QmM_cq7aMf"
      },
      "source": [
        "### Y - target:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "CI8NJV4p7chf"
      },
      "outputs": [],
      "source": [
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "# Redefining indexTest to return only the dates at which a prediction is made\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJhg2pPD7erk",
        "outputId": "487e2fad-c0cf-4505-8200-3681c9a90226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1542, 24)\n",
            "(319, 24)\n",
            "(320, 24)\n"
          ]
        }
      ],
      "source": [
        "print(Ytrain.shape)\n",
        "print(Yval.shape)\n",
        "print(Ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMItzjzW7j-q"
      },
      "source": [
        "### X_S - past informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99vB8yka7hp-",
        "outputId": "03ef7d3e-ecda-4aef-f997-43c01b638f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1522, 504, 1)\n",
            "(299, 504, 1)\n",
            "(300, 504, 1)\n"
          ]
        }
      ],
      "source": [
        "#past information (collection of past values) = sequential inputs --> GRU\n",
        "#group by timesteps\n",
        "def create_sequences(data, steps):\n",
        "    X = []\n",
        "    for i in range(steps, len(data), n_hours):\n",
        "      X.append(data.iloc[i-steps:i].values)\n",
        "    return np.array(X)\n",
        "\n",
        "# Creazione di X_S per il training, validation e test set\n",
        "X_S_train = create_sequences(train_df[['Prices']], timesteps) #start from 23/01/2011\n",
        "X_S_val = create_sequences(val_df[['Prices']], timesteps)\n",
        "X_S_test = create_sequences(test_df[['Prices']], timesteps)\n",
        "\n",
        "print(X_S_train.shape)\n",
        "print(X_S_val.shape)\n",
        "print(X_S_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxFJIeOn75b_"
      },
      "source": [
        "The size and samples of X_S, X_F and Y have to match:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYYPP1l37o_n",
        "outputId": "bc020c8d-0804-4125-a32a-82f30df638e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1522, 49)\n",
            "(299, 49)\n",
            "(300, 49)\n",
            "(1522, 24)\n",
            "(299, 24)\n",
            "(300, 24)\n"
          ]
        }
      ],
      "source": [
        "X_F_train = X_F_train[20:]   # Remove the first 20 days\n",
        "X_F_val = X_F_val[20:]\n",
        "X_F_test = X_F_test[20:]\n",
        "Ytrain = Ytrain[20:]   # Remove the first 20 days\n",
        "Yval = Yval[20:]\n",
        "Ytest = Ytest[20:]\n",
        "print(X_F_train.shape)\n",
        "print(X_F_val.shape)\n",
        "print(X_F_test.shape)\n",
        "print(Ytrain.shape)\n",
        "print(Yval.shape)\n",
        "print(Ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1YjD1q68feQ",
        "outputId": "1403483d-6cb9-4e5d-f36d-28041fcb6726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "49\n"
          ]
        }
      ],
      "source": [
        "x_seq_num_features = X_S_train.shape[2]\n",
        "x_non_seq_num_features = X_F_train.shape[1]\n",
        "print(x_seq_num_features)\n",
        "print(x_non_seq_num_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGm8eKy58qzV"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "m6yJ7BNq8seM"
      },
      "outputs": [],
      "source": [
        "# Scale X_F\n",
        "scaler_F = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_F_train = scaler_F.fit_transform(X_F_train)\n",
        "X_F_val = scaler_F.transform(X_F_val)\n",
        "X_F_test = scaler_F.transform(X_F_test)\n",
        "\n",
        "# Scale X_S\n",
        "scale_S = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_S_train = scale_S.fit_transform(X_S_train.reshape(-1, x_seq_num_features)).reshape(X_S_train.shape)\n",
        "X_S_val = scale_S.transform(X_S_val.reshape(-1, x_seq_num_features)).reshape(X_S_val.shape)\n",
        "X_S_test = scale_S.transform(X_S_test.reshape(-1, x_seq_num_features)).reshape(X_S_test.shape)\n",
        "\n",
        "# Scale the target values\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsoSU8rU7HaN"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "XdI4_GUB6REH",
        "outputId": "1858c3ad-64c5-4f8f-eb6f-83dec87c0f25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m504\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │         \u001b[38;5;34m53,460\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ non_sequential_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ DNN (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)            │          \u001b[38;5;34m8,300\u001b[0m │ non_sequential_input[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concat (\u001b[38;5;33mConcatenate\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m298\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ DNN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │          \u001b[38;5;34m7,176\u001b[0m │ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">504</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">53,460</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ non_sequential_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ DNN (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,300</span> │ non_sequential_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ DNN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">7,176</span> │ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,936\u001b[0m (269.28 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,936</span> (269.28 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,936\u001b[0m (269.28 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,936</span> (269.28 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sequential input for GRU\n",
        "seq_input = Input(shape=(timesteps, x_seq_num_features))  # Number of sequential features\n",
        "gru_out = GRU(units=nGRU, activation=activationFunctionGRU)(seq_input)\n",
        "gru_out = Dropout(dropoutGRUDNN)(gru_out)  # Apply dropout as specified\n",
        "\n",
        "# Non-sequential input for DNN\n",
        "non_seq_input = Input(shape=(x_non_seq_num_features,), name='non_sequential_input')  # Number of non-sequential features\n",
        "dnn_out = Dense(units=nDNN, activation=activationFunctionDNN, name='DNN')(non_seq_input)\n",
        "\n",
        "# Concatenate the outputs of GRU and DNN\n",
        "concat = Concatenate(name = 'concat')([gru_out, dnn_out])\n",
        "\n",
        "# Output layer\n",
        "output = Dense(units=24, name = 'output')(concat)\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs=[seq_input, non_seq_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error' ) #, metrics=[smape])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsRIuItQkhJg"
      },
      "source": [
        "### Training GRU-DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "a9nmp7X-3HX4"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_schedule = ReduceLROnPlateau(monitor='val_loss',  factor=0.6, patience=12, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOxOeW6J6tPV",
        "outputId": "2602844e-7b56-4153-ba3c-818573c7a6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.2629 - val_loss: 0.2156 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1722 - val_loss: 0.1734 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - loss: 0.1441 - val_loss: 0.1592 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - loss: 0.1353 - val_loss: 0.1551 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1319 - val_loss: 0.1512 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1295 - val_loss: 0.1502 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 0.1281 - val_loss: 0.1494 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1258 - val_loss: 0.1481 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 0.1249 - val_loss: 0.1473 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1235 - val_loss: 0.1474 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 0.1234 - val_loss: 0.1469 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - loss: 0.1228 - val_loss: 0.1474 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1216 - val_loss: 0.1472 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - loss: 0.1212 - val_loss: 0.1473 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 0.1207 - val_loss: 0.1476 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1204 - val_loss: 0.1479 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1202 - val_loss: 0.1473 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1201 - val_loss: 0.1475 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.1191 - val_loss: 0.1467 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1184 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.1180 - val_loss: 0.1465 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1181 - val_loss: 0.1462 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.1178 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 24/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 0.1169 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 25/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1169 - val_loss: 0.1461 - learning_rate: 0.0010\n",
            "Epoch 26/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - loss: 0.1169 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 27/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1167 - val_loss: 0.1461 - learning_rate: 0.0010\n",
            "Epoch 28/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1162 - val_loss: 0.1462 - learning_rate: 0.0010\n",
            "Epoch 29/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.1156 - val_loss: 0.1466 - learning_rate: 0.0010\n",
            "Epoch 30/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1158 - val_loss: 0.1460 - learning_rate: 0.0010\n",
            "Epoch 31/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.1152 - val_loss: 0.1453 - learning_rate: 0.0010\n",
            "Epoch 32/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 0.1152 - val_loss: 0.1460 - learning_rate: 0.0010\n",
            "Epoch 33/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - loss: 0.1144 - val_loss: 0.1455 - learning_rate: 0.0010\n",
            "Epoch 34/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - loss: 0.1145 - val_loss: 0.1459 - learning_rate: 0.0010\n",
            "Epoch 35/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.1146 - val_loss: 0.1452 - learning_rate: 0.0010\n",
            "Epoch 36/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - loss: 0.1136 - val_loss: 0.1453 - learning_rate: 0.0010\n",
            "Epoch 37/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - loss: 0.1138 - val_loss: 0.1458 - learning_rate: 0.0010\n",
            "Epoch 38/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - loss: 0.1137 - val_loss: 0.1461 - learning_rate: 0.0010\n",
            "Epoch 39/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.1136 - val_loss: 0.1458 - learning_rate: 0.0010\n",
            "Epoch 40/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.1126 - val_loss: 0.1459 - learning_rate: 0.0010\n",
            "Epoch 41/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1130 - val_loss: 0.1463 - learning_rate: 0.0010\n",
            "Epoch 42/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - loss: 0.1130 - val_loss: 0.1459 - learning_rate: 0.0010\n",
            "Epoch 43/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.1126 - val_loss: 0.1453 - learning_rate: 0.0010\n",
            "Epoch 44/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.1127 - val_loss: 0.1459 - learning_rate: 0.0010\n",
            "Epoch 45/1000\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.1126 - val_loss: 0.1457 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "history = model.fit(\n",
        "    [X_S_train, X_F_train], Ytrain,  # Provide both sequential and non-sequential inputs\n",
        "    validation_data=([X_S_val, X_F_val], Yval),\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping, lr_schedule]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "s5pnGgE5_wbs",
        "outputId": "5368deb4-b202-4dc2-f885-52258e17b8ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc3f2L8UP4Ov"
      },
      "source": [
        "### Prediction and sMAPE\n",
        "Performance evaluation of the hybrid GRU-DNN model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA3xB81N6wWG",
        "outputId": "8b374acb-9c65-468e-a2c9-75c554c5f20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Valori Attesi  Predizioni\n",
            "0           25.45   22.652798\n",
            "1           23.30   23.574898\n",
            "2           22.23   20.915020\n",
            "3           20.02   20.001358\n",
            "4           20.44   21.003889\n",
            "5           21.87   26.193485\n",
            "6           34.08   38.436028\n",
            "7           39.50   52.100128\n",
            "8           45.59   53.273495\n",
            "9           43.16   51.730225\n",
            "10          40.25   49.708694\n",
            "11          38.08   48.208595\n",
            "12          32.84   49.719475\n",
            "13          29.29   45.227325\n",
            "14          27.72   43.763199\n",
            "15          27.10   38.342243\n",
            "16          30.07   38.961445\n",
            "17          34.47   45.380978\n",
            "18          48.29   60.840595\n",
            "19          49.30   60.974266\n",
            "sMAPE: 19.73%\n"
          ]
        }
      ],
      "source": [
        "#Evaluating the model\n",
        "Yp = model.predict([X_S_test, X_F_test], verbose=0).squeeze()\n",
        "Yp = y_scaler.inverse_transform(Yp).squeeze()\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_o2XjI0izYw"
      },
      "source": [
        "##CNN model (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57CDR4Hwi7AV"
      },
      "outputs": [],
      "source": [
        "activationFunctionCNN = 'relu'\n",
        "dropoutCNN = 0.31\n",
        "poolingFrequency = 1\n",
        "poolingType = 'max'\n",
        "filterSizePast = 3\n",
        "filterSizeDA = 3\n",
        "numberOfConvolutionsPast = 3\n",
        "numberOfConvolutionsDA = 3\n",
        "initialFeatureMapsPast = 64\n",
        "initialFeatureMapsDA = 64\n",
        "channelLength = 1 #1 weeks\n",
        "n_hours = 24\n",
        "\n",
        "hours = range(n_hours)\n",
        "timesteps = 168 #1 week / hours\n",
        "firstConvolutionalLayer = 64 #num of feature maps\n",
        "secondConvolutionalLayer = 128\n",
        "thirdConvolutionalLayer = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3gTsBpLW83H"
      },
      "source": [
        "The input data are divided into two parts:\n",
        "*   X_S is a collection of input sequences, each one is a vector representing some sequential past information (as in the previous hybrid models)\n",
        "*   X_F_col is a collection of input vectors, where each vector represent some future information of the 24 hours of the day ahead\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOvc1Yfqf1yC"
      },
      "source": [
        "### Y - target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdYB6EiCf4Ks"
      },
      "outputs": [],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] :].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] :].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "# Redefining indexTest to return only the dates at which a prediction is made\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7mxkn2blKx1",
        "outputId": "689da661-d505-4556-a4c1-27312522dd1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1542, 24)\n",
            "(319, 24)\n",
            "(320, 24)\n"
          ]
        }
      ],
      "source": [
        "print(Ytrain.shape)\n",
        "print(Yval.shape)\n",
        "print(Ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdaKtHd0f4iH"
      },
      "source": [
        "###X_S - past informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCIMWudf6Q3",
        "outputId": "9debbf29-fc41-4327-e0c8-409e6c4b9d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1536, 168, 1)\n",
            "(313, 168, 1)\n",
            "(314, 168, 1)\n"
          ]
        }
      ],
      "source": [
        "#past information (collection of past values)\n",
        "def create_sequences(data, steps):\n",
        "    X = []\n",
        "    for i in range(steps, len(data), n_hours):\n",
        "      X.append(data.iloc[i-steps:i].values)\n",
        "    return np.array(X)\n",
        "\n",
        "# Creazione di X_S per il training, validation e test set\n",
        "X_S_train = create_sequences(train_df[['Prices']], timesteps) #start after a week: from 16/01/2011\n",
        "X_S_val = create_sequences(val_df[['Prices']], timesteps)\n",
        "X_S_test = create_sequences(test_df[['Prices']], timesteps)\n",
        "\n",
        "print(X_S_train.shape)\n",
        "print(X_S_val.shape)\n",
        "print(X_S_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiTz2H-nn2RV"
      },
      "source": [
        "###X_F - day-ahead input\n",
        "Features:\n",
        "*   day of the week,\n",
        "*   24 generation forecast,\n",
        "*   24 load forecast of the day D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYYQDK5_LnWM",
        "outputId": "69702aa4-6412-4169-da16-4b5b5e11f7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1543, 24, 3)\n",
            "(320, 24, 3)\n",
            "(321, 24, 3)\n"
          ]
        }
      ],
      "source": [
        "def create_sequences_F(data):\n",
        "    # Extract day of the week and add as a new column\n",
        "    day_of_week = pd.to_datetime(data.index).dayofweek.to_numpy()\n",
        "\n",
        "    # Initialize list to hold sequences\n",
        "    X = []\n",
        "    for i in range(0, len(data), n_hours):\n",
        "        day_of_week_window = day_of_week[i:i + n_hours]\n",
        "        w = data.iloc[i:i+ 24]\n",
        "        generation = w['Generation forecast'].values\n",
        "        load = w['System load forecast'].values\n",
        "        X.append(np.stack([day_of_week_window, generation, load], axis=-1))\n",
        "\n",
        "    X = np.array(X)  # Shape: (number_of_sequences, n_hours, 3)\n",
        "    return X\n",
        "\n",
        "X_F_train = create_sequences_F(train_df[[ 'Generation forecast', 'System load forecast']])\n",
        "X_F_val = create_sequences_F(val_df[[ 'Generation forecast', 'System load forecast']])\n",
        "X_F_test = create_sequences_F(test_df[[ 'Generation forecast', 'System load forecast']])\n",
        "\n",
        "print(X_F_train.shape) #from 09/01/2011\n",
        "print(X_F_val.shape)\n",
        "print(X_F_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_w7oj9Votlx"
      },
      "source": [
        "Data have to be consistent: size and samples have to match\n",
        "\n",
        "Train start from 16/01/2011"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLzfCOWFoxtb",
        "outputId": "4b3af01d-6452-4499-9799-7d8c3194c7d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1536, 24)\n",
            "(1536, 24, 3)\n",
            "(1536, 168, 1)\n"
          ]
        }
      ],
      "source": [
        "#same num of samples\n",
        "Ytrain = Ytrain[6:]   # Remove the first 6 days\n",
        "Yval = Yval[6:]\n",
        "Ytest = Ytest[6:]\n",
        "X_F_train = X_F_train[7:]\n",
        "X_F_val = X_F_val[7:]\n",
        "X_F_test = X_F_test[7:]\n",
        "\n",
        "print(Ytrain.shape)\n",
        "print(X_F_train.shape)\n",
        "print(X_S_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6R8xeHef-3O"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UWnFPurf-bO"
      },
      "outputs": [],
      "source": [
        "# Scale X_F\n",
        "scaler_F = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_F_train = scaler_F.fit_transform(X_F_train.reshape(-1, X_F_train.shape[2])).reshape(X_F_train.shape)\n",
        "X_F_val = scaler_F.transform(X_F_val.reshape(-1, X_F_val.shape[2])).reshape(X_F_val.shape)\n",
        "X_F_test = scaler_F.transform(X_F_test.reshape(-1, X_F_test.shape[2])).reshape(X_F_test.shape)\n",
        "\n",
        "# Scale X_S\n",
        "scale_S = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_S_train = scale_S.fit_transform(X_S_train.reshape(-1, X_S_train.shape[2])).reshape(X_S_train.shape)\n",
        "X_S_val = scale_S.transform(X_S_val.reshape(-1, X_S_val.shape[2])).reshape(X_S_val.shape)\n",
        "X_S_test = scale_S.transform(X_S_test.reshape(-1, X_S_test.shape[2])).reshape(X_S_test.shape)\n",
        "\n",
        "# Scale the target values\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFiX_XDRf60W"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwoFf_0BgCND",
        "outputId": "f3c8c069-7280-401b-f57f-2b982a1f0c6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ max_pooling1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4864</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_CNN           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">122,904</span> │ concatenate_CNN[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │            \u001b[38;5;34m256\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m640\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m256\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m24,704\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m24,704\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m512\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │            \u001b[38;5;34m512\u001b[0m │ max_pooling1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m98,560\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m98,560\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling1d_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │          \u001b[38;5;34m1,024\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m1,024\u001b[0m │ max_pooling1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4864\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_CNN           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5120\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │        \u001b[38;5;34m122,904\u001b[0m │ concatenate_CNN[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">373,912</span> (1.43 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m373,912\u001b[0m (1.43 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">372,120</span> (1.42 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m372,120\u001b[0m (1.42 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# CNN for past data\n",
        "inputs = Input(shape=(X_S_train.shape[1], X_S_train.shape[2])) #(timesteps, num_features)\n",
        "x = inputs\n",
        "\n",
        "num_feature_maps = firstConvolutionalLayer\n",
        "for i in range(numberOfConvolutionsPast):\n",
        "    x = Conv1D(filters=num_feature_maps, kernel_size=filterSizePast, activation=activationFunctionCNN)(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x) #poolingFrequency = 1 => after every convolutional layer I apply pooling max\n",
        "    x = BatchNormalization()(x) #apply batch normalization\n",
        "    x = Dropout(dropoutCNN)(x)  # Add dropout after max pooling and batch normalization\n",
        "    num_feature_maps *= 2  # Double the number of feature maps (64. 128, 256)\n",
        "\n",
        "x = Flatten()(x)\n",
        "past_cnn = Model(inputs, x, name='Past_CNN')\n",
        "\n",
        "\n",
        "\n",
        "# CNN for day-ahead data\n",
        "inputs_DA = Input(shape=(X_F_train.shape[1], X_F_train.shape[2])) #(24h, num_features)\n",
        "xDA = inputs_DA\n",
        "\n",
        "num_feature_maps = firstConvolutionalLayer\n",
        "for i in range(numberOfConvolutionsDA):\n",
        "    xDA = Conv1D(filters=num_feature_maps, kernel_size=filterSizeDA, activation=activationFunctionCNN)(xDA)\n",
        "    xDA = MaxPooling1D(pool_size=2)(xDA)\n",
        "    xDA = BatchNormalization()(xDA)\n",
        "    xDA = Dropout(dropoutCNN)(xDA)  # Add dropout after max pooling and batch normalization\n",
        "    num_feature_maps *= 2\n",
        "\n",
        "xDA = Flatten()(xDA)\n",
        "day_ahead_cnn = Model(inputs_DA, xDA, name='DayAhead_CNN')\n",
        "\n",
        "\n",
        "\n",
        "# Combine both CNNs\n",
        "combined = Concatenate(name='concatenate_CNN')([past_cnn.output, day_ahead_cnn.output])\n",
        "\n",
        "# Fully connected layer after concatenation: Output layer (for day-ahead price prediction)\n",
        "output = Dense(units = 24, activation='linear')(combined)  # Assuming you want to predict 24-hour prices\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=[past_cnn.input, day_ahead_cnn.input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "opt = Adam(learning_rate = 1e-3)\n",
        "model.compile(optimizer=opt, loss='mean_absolute_error')\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzgiuIQ3hxwn"
      },
      "source": [
        "### Training CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKGUUKJm3Obe"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_schedule = ReduceLROnPlateau(monitor='val_loss',  factor=0.6, patience=8, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYXN07ThzL6",
        "outputId": "d60a82d8-10d1-4571-847c-43e3e36b05ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 270ms/step - loss: 1.2219 - val_loss: 0.2801 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.9953 - val_loss: 0.2738 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.8672 - val_loss: 0.2967 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.7568 - val_loss: 0.3097 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - loss: 0.6927 - val_loss: 0.2661 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.6475 - val_loss: 0.2683 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - loss: 0.6104 - val_loss: 0.2744 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 0.5590 - val_loss: 0.2822 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.5405 - val_loss: 0.2573 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.4978 - val_loss: 0.2703 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - loss: 0.4605 - val_loss: 0.2685 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 0.4439 - val_loss: 0.2719 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - loss: 0.4021 - val_loss: 0.2548 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.3708 - val_loss: 0.2441 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 0.3209 - val_loss: 0.3043 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - loss: 0.3204 - val_loss: 0.3034 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 168ms/step - loss: 0.3027 - val_loss: 0.2725 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.3202 - val_loss: 0.3021 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 0.3297 - val_loss: 0.2679 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.3017 - val_loss: 0.2722 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - loss: 0.2886 - val_loss: 0.2713 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.2960 - val_loss: 0.2491 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - loss: 0.2680 - val_loss: 0.2493 - learning_rate: 6.0000e-04\n",
            "Epoch 24/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.2389 - val_loss: 0.2360 - learning_rate: 6.0000e-04\n",
            "Epoch 25/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - loss: 0.2304 - val_loss: 0.2388 - learning_rate: 6.0000e-04\n",
            "Epoch 26/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.2171 - val_loss: 0.2413 - learning_rate: 6.0000e-04\n",
            "Epoch 27/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 0.1882 - val_loss: 0.2334 - learning_rate: 6.0000e-04\n",
            "Epoch 28/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.1400 - val_loss: 0.2293 - learning_rate: 6.0000e-04\n",
            "Epoch 29/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.1346 - val_loss: 0.2211 - learning_rate: 6.0000e-04\n",
            "Epoch 30/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 0.1321 - val_loss: 0.2137 - learning_rate: 6.0000e-04\n",
            "Epoch 31/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.1345 - val_loss: 0.2070 - learning_rate: 6.0000e-04\n",
            "Epoch 32/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - loss: 0.1314 - val_loss: 0.2075 - learning_rate: 6.0000e-04\n",
            "Epoch 33/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 167ms/step - loss: 0.1323 - val_loss: 0.2008 - learning_rate: 6.0000e-04\n",
            "Epoch 34/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 0.1309 - val_loss: 0.1957 - learning_rate: 6.0000e-04\n",
            "Epoch 35/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 0.1311 - val_loss: 0.1943 - learning_rate: 6.0000e-04\n",
            "Epoch 36/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - loss: 0.1291 - val_loss: 0.1881 - learning_rate: 6.0000e-04\n",
            "Epoch 37/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 0.1295 - val_loss: 0.1863 - learning_rate: 6.0000e-04\n",
            "Epoch 38/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - loss: 0.1309 - val_loss: 0.1789 - learning_rate: 6.0000e-04\n",
            "Epoch 39/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 151ms/step - loss: 0.1295 - val_loss: 0.1762 - learning_rate: 6.0000e-04\n",
            "Epoch 40/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 159ms/step - loss: 0.1292 - val_loss: 0.1722 - learning_rate: 6.0000e-04\n",
            "Epoch 41/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 213ms/step - loss: 0.1309 - val_loss: 0.1731 - learning_rate: 6.0000e-04\n",
            "Epoch 42/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.1298 - val_loss: 0.1716 - learning_rate: 6.0000e-04\n",
            "Epoch 43/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.1289 - val_loss: 0.1699 - learning_rate: 6.0000e-04\n",
            "Epoch 44/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 0.1286 - val_loss: 0.1627 - learning_rate: 6.0000e-04\n",
            "Epoch 45/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step - loss: 0.1275 - val_loss: 0.1615 - learning_rate: 6.0000e-04\n",
            "Epoch 46/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - loss: 0.1282 - val_loss: 0.1594 - learning_rate: 6.0000e-04\n",
            "Epoch 47/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 0.1282 - val_loss: 0.1604 - learning_rate: 6.0000e-04\n",
            "Epoch 48/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 0.1278 - val_loss: 0.1576 - learning_rate: 6.0000e-04\n",
            "Epoch 49/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - loss: 0.1277 - val_loss: 0.1579 - learning_rate: 6.0000e-04\n",
            "Epoch 50/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - loss: 0.1270 - val_loss: 0.1589 - learning_rate: 6.0000e-04\n",
            "Epoch 51/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - loss: 0.1276 - val_loss: 0.1530 - learning_rate: 6.0000e-04\n",
            "Epoch 52/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 293ms/step - loss: 0.1275 - val_loss: 0.1523 - learning_rate: 6.0000e-04\n",
            "Epoch 53/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step - loss: 0.1260 - val_loss: 0.1506 - learning_rate: 6.0000e-04\n",
            "Epoch 54/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.1266 - val_loss: 0.1510 - learning_rate: 6.0000e-04\n",
            "Epoch 55/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step - loss: 0.1257 - val_loss: 0.1536 - learning_rate: 6.0000e-04\n",
            "Epoch 56/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 250ms/step - loss: 0.1259 - val_loss: 0.1527 - learning_rate: 6.0000e-04\n",
            "Epoch 57/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.1262 - val_loss: 0.1500 - learning_rate: 6.0000e-04\n",
            "Epoch 58/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step - loss: 0.1249 - val_loss: 0.1497 - learning_rate: 6.0000e-04\n",
            "Epoch 59/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - loss: 0.1240 - val_loss: 0.1469 - learning_rate: 6.0000e-04\n",
            "Epoch 60/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step - loss: 0.1263 - val_loss: 0.1539 - learning_rate: 6.0000e-04\n",
            "Epoch 61/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - loss: 0.1243 - val_loss: 0.1561 - learning_rate: 6.0000e-04\n",
            "Epoch 62/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.1245 - val_loss: 0.1541 - learning_rate: 6.0000e-04\n",
            "Epoch 63/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.1249 - val_loss: 0.1523 - learning_rate: 6.0000e-04\n",
            "Epoch 64/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - loss: 0.1242 - val_loss: 0.1489 - learning_rate: 6.0000e-04\n",
            "Epoch 65/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.1246 - val_loss: 0.1479 - learning_rate: 6.0000e-04\n",
            "Epoch 66/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - loss: 0.1224 - val_loss: 0.1482 - learning_rate: 6.0000e-04\n",
            "Epoch 67/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 0.1233 - val_loss: 0.1478 - learning_rate: 6.0000e-04\n",
            "Epoch 68/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 0.1227 - val_loss: 0.1474 - learning_rate: 3.6000e-04\n",
            "Epoch 69/1000\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.1201 - val_loss: 0.1496 - learning_rate: 3.6000e-04\n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "history = model.fit(\n",
        "    [X_S_train, X_F_train], Ytrain,  # Provide both sequential and non-sequential inputs\n",
        "    validation_data=([X_S_val, X_F_val], Yval),\n",
        "    epochs=1000,\n",
        "    batch_size=96,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping, lr_schedule]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cA2oPVZ2h_mP",
        "outputId": "edd7a9d0-1652-43ca-f1bb-815f93ee5631"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqHXAgCIlAzd"
      },
      "source": [
        "### Prediction and sMAPE\n",
        "Performance evaluation of the CNN model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1egqysQpMNG",
        "outputId": "e6d9f323-4fc7-473d-bb5f-274ab657640e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Valori Attesi  Predizioni\n",
            "0            7.72   21.814680\n",
            "1            8.35   20.536585\n",
            "2            7.15   15.762272\n",
            "3            4.97   15.650638\n",
            "4            5.39   15.272997\n",
            "5            8.38   20.940384\n",
            "6           18.05   30.140247\n",
            "7           26.38   42.278038\n",
            "8           27.92   45.159946\n",
            "9           31.97   43.945072\n",
            "10          32.96   41.982899\n",
            "11          29.76   40.436787\n",
            "12          27.53   42.953770\n",
            "13          24.52   41.267273\n",
            "14          23.98   38.106983\n",
            "15          23.91   34.791237\n",
            "16          23.92   35.592606\n",
            "17          27.93   40.369312\n",
            "18          40.13   47.278778\n",
            "19          39.45   48.901955\n",
            "sMAPE: 21.06%\n"
          ]
        }
      ],
      "source": [
        "#Evaluating the model\n",
        "Yp = model.predict([X_S_test, X_F_test], verbose=0).squeeze()\n",
        "Yp = y_scaler.inverse_transform(Yp).squeeze()\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "080vyFnxNkCE"
      },
      "source": [
        "# BENCHMARK models\n",
        "*   Statistical methods without exogenous inputs and with exogenous inputs\n",
        "*   Artificial intelligence models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "UC_8Bs7As-92"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(file_path, parse_dates=['Date'], dayfirst=True)# Load the dataset\n",
        "# Convert the 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Filter the dataset based on the date ranges\n",
        "train_df = df[(df['Date'] >= start_date) & (df['Date'] < val_start)]\n",
        "val_df = df[(df['Date'] >= val_start) & (df['Date'] < test_start)]\n",
        "test_df = df[(df['Date'] >= test_start)]\n",
        "\n",
        "train_df.set_index('Date', inplace=True)\n",
        "val_df.set_index('Date', inplace=True)\n",
        "test_df.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR5tPOVOiHV9"
      },
      "source": [
        "##Statistical methods\n",
        "Statistical methods with or without exogenous inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLQe3qyuiOJ8"
      },
      "source": [
        "### Box-Cox tranformation\n",
        "Data Preprocessing for statistical models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrpwjm9DNjbh",
        "outputId": "14711eee-bf56-4ebf-96b7-2853b2c5058b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed train_df:\n",
            "          Prices  Generation forecast  System load forecast\n",
            "0      10.566572             3.978823              9.417208\n",
            "1       8.049175             3.978394              9.367505\n",
            "2       6.471088             3.977449              9.363816\n",
            "3       4.847847             3.973998              9.310020\n",
            "4       4.757044             3.970781              9.277320\n",
            "...          ...                  ...                   ...\n",
            "37027  13.823231             3.985891              9.368755\n",
            "37028  14.493823             3.986264              9.366867\n",
            "37029  13.687343             3.985647              9.375310\n",
            "37030  13.353988             3.984164              9.334303\n",
            "37031  12.344266             3.983859              9.371199\n",
            "\n",
            "[37032 rows x 3 columns]\n",
            "\n",
            "Lambda values for Box-Cox transformation of train df:\n",
            "{'Prices': 0.5516917770598967, 'Generation forecast': -0.2319745795214032, 'System load forecast': -0.029767198208658238}\n",
            "\n",
            "Transformed val_df:\n",
            "        Prices  Generation forecast  System load forecast\n",
            "0     4.891591             8.660867              4.143427\n",
            "1     4.506207             8.630753              4.137183\n",
            "2     4.214144             8.618554              4.137345\n",
            "3     4.039117             8.606353              4.132465\n",
            "4     4.001421             8.614756              4.128954\n",
            "...        ...                  ...                   ...\n",
            "7675  4.545278             8.706751              4.158128\n",
            "7676  4.341994             8.681201              4.157077\n",
            "7677  3.863028             8.663420              4.153701\n",
            "7678  3.872621             8.657136              4.150729\n",
            "7679  3.673656             8.654545              4.156355\n",
            "\n",
            "[7680 rows x 3 columns]\n",
            "\n",
            "Lambda values for Box-Cox transformation of val df:\n",
            "{'Prices': 0.16041071221123054, 'Generation forecast': -0.046464280039536766, 'System load forecast': -0.2195918745831414}\n",
            "\n",
            "Transformed test_df:\n",
            "        Prices  Generation forecast  System load forecast\n",
            "0     3.690763             4.166615             12.626652\n",
            "1     3.631830             4.165639             12.553576\n",
            "2     3.486250             4.166460             12.571491\n",
            "3     3.307377             4.163705             12.496020\n",
            "4     3.249929             4.162716             12.452870\n",
            "...        ...                  ...                   ...\n",
            "7699  5.350218             4.178961             12.796436\n",
            "7700  5.313730             4.177444             12.771450\n",
            "7701  5.101021             4.174233             12.715055\n",
            "7702  5.046166             4.173217             12.684378\n",
            "7703  5.042835             4.174497             12.777363\n",
            "\n",
            "[7704 rows x 3 columns]\n",
            "\n",
            "Lambda values for Box-Cox transformation of test df:\n",
            "{'Prices': 0.18669612644367314, 'Generation forecast': -0.21838135799102354, 'System load forecast': 0.023094367352319695}\n"
          ]
        }
      ],
      "source": [
        "constant = 5.5\n",
        "train_df_positive = np.maximum(train_df, 0.01)\n",
        "val_df_positive = np.maximum(val_df, 0.01)#val_df + constant\n",
        "test_df_positive = np.maximum(test_df, 0.01)\n",
        "\n",
        "# Function to apply Box-Cox transformation\n",
        "def apply_boxcox(column):\n",
        "    transformed, lambda_best_fit = boxcox(column)\n",
        "    return pd.Series(transformed, name=column.name), lambda_best_fit\n",
        "\n",
        "# Apply Box-Cox to each column\n",
        "transformed_results_train = train_df_positive.apply(lambda col: apply_boxcox(col) if pd.api.types.is_numeric_dtype(col) else (col, None))\n",
        "transformed_results_val = val_df_positive.apply(lambda col: apply_boxcox(col) if pd.api.types.is_numeric_dtype(col) else (col, None))\n",
        "transformed_results_test = test_df_positive.apply(lambda col: apply_boxcox(col) if pd.api.types.is_numeric_dtype(col) else (col, None))\n",
        "\n",
        "# Extract transformed data and lambda values\n",
        "train_df_boxcox = pd.DataFrame({col: result[0] for col, result in transformed_results_train.items() if result[1] is not None})\n",
        "lambdas_train = {col: result[1] for col, result in transformed_results_train.items() if result[1] is not None}\n",
        "val_df_boxcox = pd.DataFrame({col: result[0] for col, result in transformed_results_val.items() if result[1] is not None})\n",
        "lambdas_val = {col: result[1] for col, result in transformed_results_val.items() if result[1] is not None}\n",
        "test_df_boxcox = pd.DataFrame({col: result[0] for col, result in transformed_results_test.items() if result[1] is not None})\n",
        "lambdas_test = {col: result[1] for col, result in transformed_results_test.items() if result[1] is not None}\n",
        "\n",
        "# Display the transformed DataFrame and lambda values\n",
        "print(\"Transformed train_df:\")\n",
        "print(train_df_boxcox)\n",
        "print(\"\\nLambda values for Box-Cox transformation of train df:\")\n",
        "print(lambdas_train)\n",
        "print(\"\\nTransformed val_df:\")\n",
        "print(val_df_boxcox)\n",
        "print(\"\\nLambda values for Box-Cox transformation of val df:\")\n",
        "print(lambdas_val)\n",
        "print(\"\\nTransformed test_df:\")\n",
        "print(test_df_boxcox)\n",
        "print(\"\\nLambda values for Box-Cox transformation of test df:\")\n",
        "print(lambdas_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "xvmA2cgmflcE"
      },
      "outputs": [],
      "source": [
        "def smape_stat(y_true, y_pred):\n",
        "    numerator = np.abs(y_pred - y_true)\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    return np.mean(numerator / denominator) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4r7AeNlou5z"
      },
      "source": [
        "### fARX\n",
        "It's a statistical method with exogenous inputs.\n",
        "\n",
        "Consider: the past prices in Belgium (on days 𝑑−1, 𝑑−2, 𝑑−3 and 𝑑−7), the\n",
        "day-ahead load forecast in Belgium."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "Cf1O9A80hl4i"
      },
      "outputs": [],
      "source": [
        "n_features = 24 * len([1, 2, 3, 7]) + 1*24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "lvh9Q4r-gnB4"
      },
      "outputs": [],
      "source": [
        "train_df.index = pd.to_datetime(train_df.index)\n",
        "val_df.index = pd.to_datetime(val_df.index)\n",
        "test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "train_df.index = train_df.index.round('S')\n",
        "test_df.index = test_df.index.round('S')\n",
        "val_df.index = val_df.index.round('S')\n",
        "\n",
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] + pd.Timedelta(weeks=1) :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "# We create dataframe\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "Xtrain = np.zeros([indexTrain.shape[0], n_features])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "Xval = np.zeros([indexVal.shape[0], n_features])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "Xtest = np.zeros([indexTest.shape[0], n_features])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures = 0\n",
        "\n",
        "# price D-1, D-2, D-3, D-7\n",
        "for past_day in [1, 2, 3, 7]:\n",
        "  for hour in range(24): # For each possible horizon\n",
        "        # We define the corresponding past time indexs\n",
        "        pastIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)  - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "\n",
        "        # price D-1\n",
        "        Xtrain[:, indexFeatures] = train_df.loc[pastIndexTrain, 'Prices']\n",
        "        Xtest[:, indexFeatures] = test_df.loc[pastIndexTest, 'Prices']\n",
        "        Xval[:, indexFeatures] = val_df.loc[pastIndexVal, 'Prices']\n",
        "        indexFeatures += 1\n",
        "\n",
        "\n",
        "#adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures += 1\n",
        "\n",
        "\n",
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "# Redefining indexTest to return only the dates at which a prediction is made\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "4PL-3uSEtl0-"
      },
      "outputs": [],
      "source": [
        "#fit the model (train)\n",
        "tol = 1e-6\n",
        "max_iter = 1000\n",
        "nmod = 24  # Number of models (one for each hour)\n",
        "\n",
        "# Convert numpy arrays to DataFrames or Series\n",
        "Xtrain_df = pd.DataFrame(Xtrain)\n",
        "Ytrain_df = pd.DataFrame(Ytrain)\n",
        "Xtest_df = pd.DataFrame(Xtest)\n",
        "Ytest_df = pd.DataFrame(Ytest)\n",
        "\n",
        "# Initialize 24 LinearRegression models (one for each hour)\n",
        "models = [LinearRegression() for _ in range(nmod)]\n",
        "\n",
        "# Train models for each hour\n",
        "for hour in range(nmod):\n",
        "    X_hour = Xtrain_df.iloc[hour::24, :]  # Select features for this specific hour\n",
        "    y_hour = Ytrain_df.iloc[hour::24, hour]     # Select target for this specific hour\n",
        "\n",
        "    models[hour].fit(X_hour, y_hour)  # Fit the model for this hour\n",
        "\n",
        "# Predict on the test set for each hour\n",
        "predictions = []\n",
        "for hour in range(nmod):\n",
        "    X_hour = Xtest_df.iloc[hour::24, :]\n",
        "    pred_hour = models[hour].predict(X_hour)\n",
        "    predictions.append(pred_hour)\n",
        "\n",
        "\n",
        "# Concatenate predictions into a single array\n",
        "y_pred = np.concatenate(predictions)\n",
        "\n",
        "# Ensure y_test is correctly aligned for the 24-hour predictions\n",
        "y_test_aligned = Ytest_df.values.flatten()[:len(y_pred)]  # Match the length of y_test with predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrames for easier display\n",
        "df_test = pd.DataFrame({'True Values': y_test_aligned, 'Predicted Values': y_pred})\n",
        "\n",
        "# Print example rows\n",
        "print(\"Examples of true vs predicted values:\")\n",
        "print(df_test.head(20))\n",
        "\n",
        "# Calculate sMAPE\n",
        "smape_value = smape_stat(y_test_aligned, y_pred)\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjMm13UW8EAA",
        "outputId": "a2567636-a7a1-4aa3-c665-cbb515147440"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of true vs predicted values:\n",
            "    True Values  Predicted Values\n",
            "0          7.72         13.657873\n",
            "1          8.35         13.157124\n",
            "2          7.15         19.008146\n",
            "3          4.97         22.563189\n",
            "4          5.39         28.925412\n",
            "5          8.38         33.540998\n",
            "6         18.05         43.428658\n",
            "7         26.38         33.123770\n",
            "8         27.92         28.964292\n",
            "9         31.97         27.599567\n",
            "10        32.96         43.989733\n",
            "11        29.76         61.369143\n",
            "12        27.53         74.211712\n",
            "13        24.52         31.240705\n",
            "14        23.98         27.898125\n",
            "15        23.91         25.557716\n",
            "16        23.92         19.016983\n",
            "17        27.93         13.246970\n",
            "18        40.13         19.833341\n",
            "19        39.45         21.819920\n",
            "sMAPE: 57.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lghV6MRAxeqj"
      },
      "source": [
        "##MACHINE Learning methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNp1AFaZ8V_U"
      },
      "source": [
        "### Multilayer perceptron (MLP)\n",
        "It's a standard neural netword with a single hidden layer with 117 neurons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0cwHNnL9crM"
      },
      "source": [
        "#### Pre-processing data\n",
        "Its the same of DNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWHPpSzY9iG0",
        "outputId": "c34f541d-12a2-4e3a-e340-73f4fa9417fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "121\n"
          ]
        }
      ],
      "source": [
        "n_features = 1+ 24 + 24 + 24 + 48\n",
        "print(n_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUAkeosj9mMt"
      },
      "outputs": [],
      "source": [
        "# Define columns #date is the index!\n",
        "columns = ['Day'] + [f'Price_D-1_h{hour}' for hour in hours] + \\\n",
        "          [f'Price_D-2_h{hour}' for hour in hours] + \\\n",
        "          [f'Price_D-7_h{hour}' for hour in hours] + \\\n",
        "          [f'Generation_D_h{hour}' for hour in hours] + \\\n",
        "          [f'Load_D_h{hour}' for hour in hours]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I65B9ux89p5h"
      },
      "outputs": [],
      "source": [
        "train_df.index = pd.to_datetime(train_df.index)\n",
        "val_df.index = pd.to_datetime(val_df.index)\n",
        "test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "train_df.index = train_df.index.round('S')\n",
        "test_df.index = test_df.index.round('S')\n",
        "val_df.index = val_df.index.round('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQuRhDpX9xVy",
        "outputId": "05453702-3bce-4b5e-dd8e-b6d09b5439ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatetimeIndex(['2011-01-16 00:00:00', '2011-01-16 01:00:00',\n",
            "               '2011-01-16 02:00:00', '2011-01-16 03:00:00',\n",
            "               '2011-01-16 04:00:00', '2011-01-16 05:00:00',\n",
            "               '2011-01-16 06:00:00', '2011-01-16 07:00:00',\n",
            "               '2011-01-16 08:00:00', '2011-01-16 09:00:00',\n",
            "               ...\n",
            "               '2015-03-31 14:00:00', '2015-03-31 15:00:00',\n",
            "               '2015-03-31 16:00:00', '2015-03-31 17:00:00',\n",
            "               '2015-03-31 18:00:00', '2015-03-31 19:00:00',\n",
            "               '2015-03-31 20:00:00', '2015-03-31 21:00:00',\n",
            "               '2015-03-31 22:00:00', '2015-03-31 23:00:00'],\n",
            "              dtype='datetime64[ns]', name='Date', length=36864, freq=None)\n"
          ]
        }
      ],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] + pd.Timedelta(weeks=1) :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "\n",
        "print(indexTrain)\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "Xtrain = np.zeros([indexTrain.shape[0], n_features])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "Xval = np.zeros([indexVal.shape[0], n_features])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "Xtest = np.zeros([indexTest.shape[0], n_features])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures = 0\n",
        "\n",
        "Xtrain[:, 0] = indexTrain.index.dayofweek + indexTrain.index.hour / 24\n",
        "Xval[:, 0] = indexVal.index.dayofweek + indexVal.index.hour / 24\n",
        "Xtest[:, 0] = indexTest.index.dayofweek\n",
        "indexFeatures += 1\n",
        "\n",
        "# price D-1, D-2, D-7\n",
        "for past_day in [1, 2, 7]:\n",
        "  for hour in range(24): # For each possible horizon\n",
        "        # We define the corresponding past time indexs\n",
        "        pastIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)  - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "\n",
        "        # price D-1\n",
        "        Xtrain[:, indexFeatures] = train_df.loc[pastIndexTrain, 'Prices']\n",
        "        Xtest[:, indexFeatures] = test_df.loc[pastIndexTest, 'Prices']\n",
        "        Xval[:, indexFeatures] = val_df.loc[pastIndexVal, 'Prices']\n",
        "        indexFeatures += 1\n",
        "\n",
        "\n",
        "# Adding generation inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'Generation forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'Generation forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'Generation forecast']\n",
        "    indexFeatures += 1\n",
        "\n",
        "\n",
        "#adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    past_day = 1\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s-azXtN93e2"
      },
      "outputs": [],
      "source": [
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "# Redefining indexTest to return only the dates at which a prediction is made\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN48FM9Dilg2",
        "outputId": "8c95fabc-8ffb-4097-81bd-80fd1b304437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21.32 18.54 14.99 ... 49.32 51.31 46.14]\n",
            " [22.73 16.75 17.1  ... 51.24 50.89 48.92]\n",
            " [37.65 37.28 34.94 ... 50.01 49.74 45.89]\n",
            " ...\n",
            " [28.06 24.2  23.07 ... 34.94 30.42 28.37]\n",
            " [19.15 23.   22.56 ... 49.33 47.04 43.  ]\n",
            " [38.74 26.27 22.68 ... 48.91 47.02 41.5 ]]\n"
          ]
        }
      ],
      "source": [
        "print(Ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRXRLZ4bz7be"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "Xtrain = scaler.fit_transform(Xtrain)\n",
        "Xval = scaler.transform(Xval)\n",
        "Xtest = scaler.transform(Xtest)\n",
        "\n",
        "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJeVsGsYLrgr",
        "outputId": "dd582a5a-0b88-4040-c4c2-c40a76494070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.         0.14302191 0.23694954 ... 0.46666667 0.43313373 0.42454728]\n",
            " [0.         0.06322743 0.13480413 ... 0.59122807 0.5508982  0.54124748]\n",
            " [0.16666667 0.07061969 0.11925649 ... 0.63333333 0.59481038 0.57746479]\n",
            " ...\n",
            " [1.         0.21143966 0.35082081 ... 0.34984211 0.29429142 0.29162978]\n",
            " [0.         0.09856349 0.18396595 ... 0.41196491 0.35598802 0.33979879]\n",
            " [0.16666667 0.05185069 0.17354295 ... 0.42       0.35840319 0.3461167 ]]\n"
          ]
        }
      ],
      "source": [
        "print(Xtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjZriBc-EbR"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XCip25H_9pX"
      },
      "outputs": [],
      "source": [
        "# Early stopping configuration and learning rate\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "wETRUVvI-GCq",
        "outputId": "d64a0396-3f24-4116-de60-5e9076dbef72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,274</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,832</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m)                 │          \u001b[38;5;34m14,274\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m2,832\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,106</span> (66.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,106\u001b[0m (66.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,106</span> (66.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,106\u001b[0m (66.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(117, activation='relu', input_shape=(n_features,), kernel_regularizer=regularizers.l1(0.00032)),  # Hidden layer with 117 neurons\n",
        "    Dense(24)  # Output layer (regression problem; change for classification)\n",
        "])\n",
        "\n",
        "# Compile the model with Mean Absolute Error as the Loss function\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')  #, metrics=[smape])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training"
      ],
      "metadata": {
        "id": "I8nByjGSHZbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q55XXCfn-X3J",
        "outputId": "02660dfc-6c85-4bd1-c684-c9c49b4d99cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.6601 - val_loss: 0.4525\n",
            "Epoch 2/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4341 - val_loss: 0.4111\n",
            "Epoch 3/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3897 - val_loss: 0.3789\n",
            "Epoch 4/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3565 - val_loss: 0.3553\n",
            "Epoch 5/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3322 - val_loss: 0.3342\n",
            "Epoch 6/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3110 - val_loss: 0.3144\n",
            "Epoch 7/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2921 - val_loss: 0.2966\n",
            "Epoch 8/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2754 - val_loss: 0.2812\n",
            "Epoch 9/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2608 - val_loss: 0.2672\n",
            "Epoch 10/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2476 - val_loss: 0.2544\n",
            "Epoch 11/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2358 - val_loss: 0.2436\n",
            "Epoch 12/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2256 - val_loss: 0.2340\n",
            "Epoch 13/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2167 - val_loss: 0.2256\n",
            "Epoch 14/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2087 - val_loss: 0.2185\n",
            "Epoch 15/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2013 - val_loss: 0.2115\n",
            "Epoch 16/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1944 - val_loss: 0.2046\n",
            "Epoch 17/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1878 - val_loss: 0.1983\n",
            "Epoch 18/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1816 - val_loss: 0.1921\n",
            "Epoch 19/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1759 - val_loss: 0.1865\n",
            "Epoch 20/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1703 - val_loss: 0.1807\n",
            "Epoch 21/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1651 - val_loss: 0.1758\n",
            "Epoch 22/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1601 - val_loss: 0.1709\n",
            "Epoch 23/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1553 - val_loss: 0.1664\n",
            "Epoch 24/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1508 - val_loss: 0.1618\n",
            "Epoch 25/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1463 - val_loss: 0.1573\n",
            "Epoch 26/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1423 - val_loss: 0.1535\n",
            "Epoch 27/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1384 - val_loss: 0.1500\n",
            "Epoch 28/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1347 - val_loss: 0.1459\n",
            "Epoch 29/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1309 - val_loss: 0.1424\n",
            "Epoch 30/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1274 - val_loss: 0.1390\n",
            "Epoch 31/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1238 - val_loss: 0.1355\n",
            "Epoch 32/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1207 - val_loss: 0.1332\n",
            "Epoch 33/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1178 - val_loss: 0.1301\n",
            "Epoch 34/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1149 - val_loss: 0.1277\n",
            "Epoch 35/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1121 - val_loss: 0.1244\n",
            "Epoch 36/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1095 - val_loss: 0.1219\n",
            "Epoch 37/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1069 - val_loss: 0.1193\n",
            "Epoch 38/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1042 - val_loss: 0.1170\n",
            "Epoch 39/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1021 - val_loss: 0.1146\n",
            "Epoch 40/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1000 - val_loss: 0.1117\n",
            "Epoch 41/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0977 - val_loss: 0.1101\n",
            "Epoch 42/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0959 - val_loss: 0.1081\n",
            "Epoch 43/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0940 - val_loss: 0.1062\n",
            "Epoch 44/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0922 - val_loss: 0.1046\n",
            "Epoch 45/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0904 - val_loss: 0.1030\n",
            "Epoch 46/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0890 - val_loss: 0.1011\n",
            "Epoch 47/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0873 - val_loss: 0.0994\n",
            "Epoch 48/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - val_loss: 0.0979\n",
            "Epoch 49/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0839 - val_loss: 0.0967\n",
            "Epoch 50/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0825 - val_loss: 0.0947\n",
            "Epoch 51/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0809 - val_loss: 0.0936\n",
            "Epoch 52/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0797 - val_loss: 0.0923\n",
            "Epoch 53/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0786 - val_loss: 0.0913\n",
            "Epoch 54/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0770 - val_loss: 0.0905\n",
            "Epoch 55/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0760 - val_loss: 0.0893\n",
            "Epoch 56/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0748 - val_loss: 0.0879\n",
            "Epoch 57/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0739 - val_loss: 0.0872\n",
            "Epoch 58/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0727 - val_loss: 0.0863\n",
            "Epoch 59/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0720 - val_loss: 0.0846\n",
            "Epoch 60/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0705 - val_loss: 0.0833\n",
            "Epoch 61/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0694 - val_loss: 0.0823\n",
            "Epoch 62/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0688 - val_loss: 0.0818\n",
            "Epoch 63/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0681 - val_loss: 0.0813\n",
            "Epoch 64/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0671 - val_loss: 0.0803\n",
            "Epoch 65/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0664 - val_loss: 0.0791\n",
            "Epoch 66/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0656 - val_loss: 0.0783\n",
            "Epoch 67/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0646 - val_loss: 0.0775\n",
            "Epoch 68/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0639 - val_loss: 0.0771\n",
            "Epoch 69/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0634 - val_loss: 0.0759\n",
            "Epoch 70/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0622 - val_loss: 0.0751\n",
            "Epoch 71/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0615 - val_loss: 0.0757\n",
            "Epoch 72/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0612 - val_loss: 0.0750\n",
            "Epoch 73/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0604 - val_loss: 0.0742\n",
            "Epoch 74/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.0736\n",
            "Epoch 75/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0594 - val_loss: 0.0731\n",
            "Epoch 76/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0583 - val_loss: 0.0719\n",
            "Epoch 77/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0578 - val_loss: 0.0720\n",
            "Epoch 78/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0573 - val_loss: 0.0716\n",
            "Epoch 79/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0570 - val_loss: 0.0708\n",
            "Epoch 80/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0565 - val_loss: 0.0704\n",
            "Epoch 81/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0562 - val_loss: 0.0689\n",
            "Epoch 82/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0550 - val_loss: 0.0690\n",
            "Epoch 83/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0547 - val_loss: 0.0691\n",
            "Epoch 84/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0544 - val_loss: 0.0679\n",
            "Epoch 85/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0538 - val_loss: 0.0676\n",
            "Epoch 86/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0535 - val_loss: 0.0671\n",
            "Epoch 87/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0531 - val_loss: 0.0670\n",
            "Epoch 88/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0527 - val_loss: 0.0672\n",
            "Epoch 89/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0526 - val_loss: 0.0661\n",
            "Epoch 90/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0522 - val_loss: 0.0655\n",
            "Epoch 91/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0515 - val_loss: 0.0657\n",
            "Epoch 92/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0514 - val_loss: 0.0651\n",
            "Epoch 93/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0509 - val_loss: 0.0648\n",
            "Epoch 94/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0503 - val_loss: 0.0642\n",
            "Epoch 95/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0500 - val_loss: 0.0646\n",
            "Epoch 96/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0500 - val_loss: 0.0641\n",
            "Epoch 97/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0497 - val_loss: 0.0643\n",
            "Epoch 98/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0499 - val_loss: 0.0626\n",
            "Epoch 99/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0487 - val_loss: 0.0627\n",
            "Epoch 100/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0484 - val_loss: 0.0628\n",
            "Epoch 101/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0484 - val_loss: 0.0626\n",
            "Epoch 102/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0484 - val_loss: 0.0618\n",
            "Epoch 103/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0480 - val_loss: 0.0613\n",
            "Epoch 104/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0474 - val_loss: 0.0619\n",
            "Epoch 105/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0472 - val_loss: 0.0616\n",
            "Epoch 106/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0471 - val_loss: 0.0614\n",
            "Epoch 107/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0471 - val_loss: 0.0611\n",
            "Epoch 108/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0466 - val_loss: 0.0607\n",
            "Epoch 109/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0463 - val_loss: 0.0615\n",
            "Epoch 110/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0467 - val_loss: 0.0608\n",
            "Epoch 111/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0463 - val_loss: 0.0608\n",
            "Epoch 112/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0461 - val_loss: 0.0603\n",
            "Epoch 113/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - val_loss: 0.0600\n",
            "Epoch 114/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0454 - val_loss: 0.0601\n",
            "Epoch 115/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.0604\n",
            "Epoch 116/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.0592\n",
            "Epoch 117/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0451 - val_loss: 0.0592\n",
            "Epoch 118/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0445 - val_loss: 0.0587\n",
            "Epoch 119/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0443 - val_loss: 0.0592\n",
            "Epoch 120/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0444 - val_loss: 0.0589\n",
            "Epoch 121/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0443 - val_loss: 0.0587\n",
            "Epoch 122/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0441 - val_loss: 0.0586\n",
            "Epoch 123/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0440 - val_loss: 0.0582\n",
            "Epoch 124/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0439 - val_loss: 0.0579\n",
            "Epoch 125/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0577\n",
            "Epoch 126/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0435 - val_loss: 0.0581\n",
            "Epoch 127/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0434 - val_loss: 0.0579\n",
            "Epoch 128/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0431 - val_loss: 0.0582\n",
            "Epoch 129/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0432 - val_loss: 0.0580\n",
            "Epoch 130/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0431 - val_loss: 0.0575\n",
            "Epoch 131/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0430 - val_loss: 0.0579\n",
            "Epoch 132/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0430 - val_loss: 0.0574\n",
            "Epoch 133/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0427 - val_loss: 0.0572\n",
            "Epoch 134/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0427 - val_loss: 0.0575\n",
            "Epoch 135/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0425 - val_loss: 0.0577\n",
            "Epoch 136/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0427 - val_loss: 0.0566\n",
            "Epoch 137/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0423 - val_loss: 0.0572\n",
            "Epoch 138/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0424 - val_loss: 0.0582\n",
            "Epoch 139/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0426 - val_loss: 0.0576\n",
            "Epoch 140/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0423 - val_loss: 0.0567\n",
            "Epoch 141/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0419 - val_loss: 0.0575\n",
            "Epoch 142/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0424 - val_loss: 0.0567\n",
            "Epoch 143/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0420 - val_loss: 0.0561\n",
            "Epoch 144/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.0563\n",
            "Epoch 145/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0415 - val_loss: 0.0562\n",
            "Epoch 146/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0414 - val_loss: 0.0570\n",
            "Epoch 147/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0414 - val_loss: 0.0568\n",
            "Epoch 148/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0415 - val_loss: 0.0557\n",
            "Epoch 149/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0412 - val_loss: 0.0561\n",
            "Epoch 150/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0412 - val_loss: 0.0565\n",
            "Epoch 151/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0412 - val_loss: 0.0570\n",
            "Epoch 152/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0413 - val_loss: 0.0572\n",
            "Epoch 153/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0413 - val_loss: 0.0558\n",
            "Epoch 154/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0407 - val_loss: 0.0555\n",
            "Epoch 155/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0406 - val_loss: 0.0563\n",
            "Epoch 156/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0407 - val_loss: 0.0563\n",
            "Epoch 157/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0407 - val_loss: 0.0561\n",
            "Epoch 158/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0406 - val_loss: 0.0557\n",
            "Epoch 159/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0405 - val_loss: 0.0563\n",
            "Epoch 160/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0407 - val_loss: 0.0561\n",
            "Epoch 161/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0404 - val_loss: 0.0554\n",
            "Epoch 162/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0402 - val_loss: 0.0551\n",
            "Epoch 163/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0401 - val_loss: 0.0558\n",
            "Epoch 164/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0404 - val_loss: 0.0552\n",
            "Epoch 165/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0400 - val_loss: 0.0550\n",
            "Epoch 166/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0399 - val_loss: 0.0548\n",
            "Epoch 167/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0398 - val_loss: 0.0553\n",
            "Epoch 168/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0399 - val_loss: 0.0552\n",
            "Epoch 169/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.0552\n",
            "Epoch 170/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0398 - val_loss: 0.0554\n",
            "Epoch 171/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0398 - val_loss: 0.0552\n",
            "Epoch 172/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0398 - val_loss: 0.0555\n",
            "Epoch 173/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.0555\n",
            "Epoch 174/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0399 - val_loss: 0.0548\n",
            "Epoch 175/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0396 - val_loss: 0.0541\n",
            "Epoch 176/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0396 - val_loss: 0.0540\n",
            "Epoch 177/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0393 - val_loss: 0.0545\n",
            "Epoch 178/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0393 - val_loss: 0.0550\n",
            "Epoch 179/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0394 - val_loss: 0.0551\n",
            "Epoch 180/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0393 - val_loss: 0.0549\n",
            "Epoch 181/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0395 - val_loss: 0.0552\n",
            "Epoch 182/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0396 - val_loss: 0.0548\n",
            "Epoch 183/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0393 - val_loss: 0.0548\n",
            "Epoch 184/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0394 - val_loss: 0.0546\n",
            "Epoch 185/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0392 - val_loss: 0.0546\n",
            "Epoch 186/500\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0392 - val_loss: 0.0541\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeGklEQVR4nO3deXwU9f3H8dfsJtnc9w2BcMl9yClaFRUFD0TFioiCSLWeVdH+LLXetWA9q1CvCth6IdarWkVAsCoIyiUoICBHgByEkPvend8fkyxEIATYZJLN+/n47SPZmdnZz2Sl+/59v9/5fg3TNE1ERERE/ITD7gJEREREfEnhRkRERPyKwo2IiIj4FYUbERER8SsKNyIiIuJXFG5ERETEryjciIiIiF9RuBERERG/onAjIiIifkXhRkSaPcMwePDBB4/5ddu3b8cwDObMmVPvcUuWLMEwDJYsWXJc9YlI86JwIyINMmfOHAzDwDAMvvrqq0P2m6ZJWloahmFw0UUX2VChiIhF4UZEjklwcDBvvPHGIdu/+OILdu3ahcvlsqEqEZEDFG5E5JhccMEFzJs3j+rq6jrb33jjDQYMGEBycrJNlYmIWBRuROSYjBs3jn379rFgwQLvtsrKSt555x2uuuqqw76mpKSEu+66i7S0NFwuF127duWJJ57ANM06x1VUVHDnnXeSkJBAREQEF198Mbt27TrsOXfv3s11111HUlISLpeLnj17MmvWLN9dKDBv3jwGDBhASEgI8fHxXH311ezevbvOMVlZWUyaNIm2bdvicrlISUlh9OjRbN++3XvMd999x4gRI4iPjyckJIQOHTpw3XXX+bRWETkgwO4CRKRlSU9PZ+jQobz55pucf/75AHzyyScUFBRw5ZVX8uyzz9Y53jRNLr74YhYvXszkyZPp168f8+fP5/e//z27d+/m6aef9h77m9/8htdee42rrrqKU089lc8//5wLL7zwkBqys7M55ZRTMAyDW2+9lYSEBD755BMmT55MYWEhd9xxxwlf55w5c5g0aRKDBg1i2rRpZGdn87e//Y2vv/6a1atXEx0dDcCYMWP44YcfuO2220hPTycnJ4cFCxawc+dO7/PzzjuPhIQE/vCHPxAdHc327dt59913T7hGETkCU0SkAWbPnm0C5rfffmvOmDHDjIiIMEtLS03TNM1f//rX5llnnWWapmm2b9/evPDCC72ve//9903A/POf/1znfJdffrlpGIa5ZcsW0zRNc82aNSZg3nzzzXWOu+qqq0zAfOCBB7zbJk+ebKakpJi5ubl1jr3yyivNqKgob13btm0zAXP27Nn1XtvixYtNwFy8eLFpmqZZWVlpJiYmmr169TLLysq8x3300UcmYN5///2maZrm/v37TcB8/PHHj3ju9957z/t3E5GmoW4pETlmV1xxBWVlZXz00UcUFRXx0UcfHbFL6r///S9Op5Pf/e53dbbfddddmKbJJ5984j0OOOS4X7bCmKbJv//9b0aNGoVpmuTm5nofI0aMoKCggFWrVp3Q9X333Xfk5ORw8803Exwc7N1+4YUX0q1bNz7++GMAQkJCCAoKYsmSJezfv/+w56pt4fnoo4+oqqo6obpEpGEUbkTkmCUkJDB8+HDeeOMN3n33XdxuN5dffvlhj92xYwepqalERETU2d69e3fv/tqfDoeDTp061Tmua9eudZ7v3buX/Px8XnrpJRISEuo8Jk2aBEBOTs4JXV9tTb98b4Bu3bp597tcLh577DE++eQTkpKSOOOMM/jrX/9KVlaW9/gzzzyTMWPG8NBDDxEfH8/o0aOZPXs2FRUVJ1SjiByZxtyIyHG56qqruP7668nKyuL888/3tlA0No/HA8DVV1/NxIkTD3tMnz59mqQWsFqWRo0axfvvv8/8+fO57777mDZtGp9//jknn3wyhmHwzjvv8M033/Cf//yH+fPnc9111/Hkk0/yzTffEB4e3mS1irQWarkRkeNy6aWX4nA4+Oabb47YJQXQvn179uzZQ1FRUZ3tGzdu9O6v/enxeNi6dWud4zZt2lTnee2dVG63m+HDhx/2kZiYeELXVlvTL9+7dlvt/lqdOnXirrvu4rPPPmP9+vVUVlby5JNP1jnmlFNO4dFHH+W7777j9ddf54cffuCtt946oTpF5PAUbkTkuISHh/P888/z4IMPMmrUqCMed8EFF+B2u5kxY0ad7U8//TSGYXjvuKr9+cu7rZ555pk6z51OJ2PGjOHf//4369evP+T99u7dezyXU8fAgQNJTEzkhRdeqNN99Mknn7BhwwbvHVylpaWUl5fXeW2nTp2IiIjwvm7//v2H3PLer18/AHVNiTQSdUuJyHE7UrfQwUaNGsVZZ53Fvffey/bt2+nbty+fffYZH3zwAXfccYd3jE2/fv0YN24cf//73ykoKODUU09l0aJFbNmy5ZBzTp8+ncWLFzNkyBCuv/56evToQV5eHqtWrWLhwoXk5eWd0HUFBgby2GOPMWnSJM4880zGjRvnvRU8PT2dO++8E4CffvqJc845hyuuuIIePXoQEBDAe++9R3Z2NldeeSUAr776Kn//+9+59NJL6dSpE0VFRbz88stERkZywQUXnFCdInJ4Cjci0qgcDgcffvgh999/P3PnzmX27Nmkp6fz+OOPc9ddd9U5dtasWSQkJPD666/z/vvvc/bZZ/Pxxx+TlpZW57ikpCRWrFjBww8/zLvvvsvf//534uLi6NmzJ4899phP6r722msJDQ1l+vTp3HPPPYSFhXHppZfy2GOPeccXpaWlMW7cOBYtWsS//vUvAgIC6NatG2+//TZjxowBrAHFK1as4K233iI7O5uoqCgGDx7M66+/TocOHXxSq4jUZZi/bC8VERERacE05kZERET8isKNiIiI+BWFGxEREfErCjciIiLiVxRuRERExK8o3IiIiIhfaXXz3Hg8Hvbs2UNERASGYdhdjoiIiDSAaZoUFRWRmpqKw1F/20yrCzd79uw5ZEIwERERaRkyMjJo27Ztvce0unATEREBWH+cyMhIm6sRERGRhigsLCQtLc37PV6fVhduaruiIiMjFW5ERERamIYMKdGAYhEREfErCjciIiLiVxRuRERExK+0ujE3IiLiP9xuN1VVVXaXIT4SFBR01Nu8G0LhRkREWhzTNMnKyiI/P9/uUsSHHA4HHTp0ICgo6ITOo3AjIiItTm2wSUxMJDQ0VJOy+oHaSXYzMzNp167dCX2mCjciItKiuN1ub7CJi4uzuxzxoYSEBPbs2UN1dTWBgYHHfR4NKBYRkRaldoxNaGiozZWIr9V2R7nd7hM6j8KNiIi0SOqK8j+++kwVbkRERMSvKNyIiIi0YOnp6TzzzDN2l9GsKNyIiIg0AcMw6n08+OCDx3Xeb7/9lhtuuMG3xbZwulvKRyqq3ewrrgQgNTrE5mpERKS5yczM9P4+d+5c7r//fjZt2uTdFh4e7v3dNE3cbjcBAUf/mk5ISPBtoX5ALTc+8v2uAk6d/jnj/7Hc7lJERKQZSk5O9j6ioqIwDMP7fOPGjURERPDJJ58wYMAAXC4XX331FVu3bmX06NEkJSURHh7OoEGDWLhwYZ3z/rJbyjAM/vGPf3DppZcSGhpKly5d+PDDD5v4au2lcOMjQU7rT1lZ7bG5EhGR1sc0TUorq215mKbps+v4wx/+wPTp09mwYQN9+vShuLiYCy64gEWLFrF69WpGjhzJqFGj2LlzZ73neeihh7jiiiv4/vvvueCCCxg/fjx5eXk+q7O5U7eUjwTWhhu3wo2ISFMrq3LT4/75trz3jw+PIDTIN1+nDz/8MOeee673eWxsLH379vU+f+SRR3jvvff48MMPufXWW494nmuvvZZx48YB8Je//IVnn32WFStWMHLkSJ/U2dyp5cZHggLUciMiIidm4MCBdZ4XFxdz99130717d6KjowkPD2fDhg1Hbbnp06eP9/ewsDAiIyPJyclplJqbI7Xc+IhL4UZExDYhgU5+fHiEbe/tK2FhYXWe33333SxYsIAnnniCzp07ExISwuWXX05lZWW95/nl0gWGYeDxtJ7vJ4UbH6ntlqpSt5SISJMzDMNnXUPNyddff821117LpZdeClgtOdu3b7e3qBZA3VI+UtstVe0x8Xh8N7hMRERary5duvDuu++yZs0a1q5dy1VXXdWqWmCOl8KNj9SGG9CgYhER8Y2nnnqKmJgYTj31VEaNGsWIESPo37+/3WU1e4bpy3vYWoDCwkKioqIoKCggMjLSZ+etqHbT9U+fAvD9g+cRGXz8S7WLiMiRlZeXs23bNjp06EBwcLDd5YgP1ffZHsv3t1pufKR2nhvQoGIRERE7Kdz4iGEYBDqtpdo1qFhERMQ+Cjc+pFmKRURE7Kdw40OayE9ERMR+Cjc+pCUYRERE7Kdw40NquREREbGfwo0PKdyIiIjYT+HGh4K8SzC0qqmDREREmhWFGx/ytty43TZXIiIi0nop3PhQoG4FFxGRRjRs2DDuuOMO7/P09HSeeeaZel9jGAbvv//+Cb+3r87TFBRufMg7z426pURE5BdGjRrFyJEjD7vvyy+/xDAMvv/++2M657fffssNN9zgi/K8HnzwQfr163fI9szMTM4//3yfvldjUbjxIQ0oFhGRI5k8eTILFixg165dh+ybPXs2AwcOpE+fPsd0zoSEBEJDQ31VYr2Sk5NxuVxN8l4nSuHGhwK9A4oVbkREpK6LLrqIhIQE5syZU2d7cXEx8+bN45JLLmHcuHG0adOG0NBQevfuzZtvvlnvOX/ZLbV582bOOOMMgoOD6dGjBwsWLDjkNffccw8nnXQSoaGhdOzYkfvuu4+qqioA5syZw0MPPcTatWsxDAPDMLz1/rJbat26dZx99tmEhIQQFxfHDTfcQHFxsXf/tddeyyWXXMITTzxBSkoKcXFx3HLLLd73akwBjf4OrYhLLTciIvYwTagqtee9A0PBMI56WEBAABMmTGDOnDnce++9GDWvmTdvHm63m6uvvpp58+Zxzz33EBkZyccff8w111xDp06dGDx48FHP7/F4uOyyy0hKSmL58uUUFBTUGZ9TKyIigjlz5pCamsq6deu4/vrriYiI4P/+7/8YO3Ys69ev59NPP2XhwoUAREVFHXKOkpISRowYwdChQ/n222/JycnhN7/5Dbfeemud8LZ48WJSUlJYvHgxW7ZsYezYsfTr14/rr7/+qNdzIhRufEjdUiIiNqkqhb+k2vPef9wDQWENOvS6667j8ccf54svvmDYsGGA1SU1ZswY2rdvz9133+099rbbbmP+/Pm8/fbbDQo3CxcuZOPGjcyfP5/UVOtv8Ze//OWQcTJ/+tOfvL+np6dz991389Zbb/F///d/hISEEB4eTkBAAMnJyUd8rzfeeIPy8nL++c9/EhZmXfuMGTMYNWoUjz32GElJSQDExMQwY8YMnE4n3bp148ILL2TRokWNHm7ULeVDtauCa/kFERE5nG7dunHqqacya9YsALZs2cKXX37J5MmTcbvdPPLII/Tu3ZvY2FjCw8OZP38+O3fubNC5N2zYQFpamjfYAAwdOvSQ4+bOnctpp51GcnIy4eHh/OlPf2rwexz8Xn379vUGG4DTTjsNj8fDpk2bvNt69uyJ0+n0Pk9JSSEnJ+eY3ut4qOXGh9RyIyJik8BQqwXFrvc+BpMnT+a2225j5syZzJ49m06dOnHmmWfy2GOP8be//Y1nnnmG3r17ExYWxh133EFlZaXPSl22bBnjx4/noYceYsSIEURFRfHWW2/x5JNP+uw9DhYYGFjnuWEYeDyN/x2pcONDQTXpVC03IiJNzDAa3DVktyuuuILbb7+dN954g3/+85/cdNNNGIbB119/zejRo7n66qsBawzNTz/9RI8ePRp03u7du5ORkUFmZiYpKSkAfPPNN3WOWbp0Ke3bt+fee+/1btuxY0edY4KCgnAfZTLa7t27M2fOHEpKSrytN19//TUOh4OuXbs2qN7GpG4pHwoMsLqlqtRyIyIiRxAeHs7YsWOZOnUqmZmZXHvttQB06dKFBQsWsHTpUjZs2MBvf/tbsrOzG3ze4cOHc9JJJzFx4kTWrl3Ll19+WSfE1L7Hzp07eeutt9i6dSvPPvss7733Xp1j0tPT2bZtG2vWrCE3N5eKiopD3mv8+PEEBwczceJE1q9fz+LFi7ntttu45pprvONt7KRw40Mu7yR+CjciInJkkydPZv/+/YwYMcI7RuZPf/oT/fv3Z8SIEQwbNozk5GQuueSSBp/T4XDw3nvvUVZWxuDBg/nNb37Do48+WueYiy++mDvvvJNbb72Vfv36sXTpUu677746x4wZM4aRI0dy1llnkZCQcNjb0UNDQ5k/fz55eXkMGjSIyy+/nHPOOYcZM2Yc+x+jERimabaq6XQLCwuJioqioKCAyMhIn577uUWbeXLBT1w5KI3pY45tIiYREWmY8vJytm3bRocOHQgODra7HPGh+j7bY/n+VsuNDx1YOFMtNyIiInZRuPEh3S0lIiJiP4UbH9LyCyIiIvZTuPEhtdyIiIjYT+HGh1wacyMi0mRa2f0wrYKvPlOFGx/ydktV6x+ciEhjqZ31trTUpoUypdHUzsZ88JINx0MzFPtQUE24qVDLjYhIo3E6nURHR3vXKAoNDfWusC0tl8fjYe/evYSGhhIQcGLxROHGhwI15kZEpEnUrljdFIswStNxOBy0a9fuhMOqwo0PBeluKRGRJmEYBikpKSQmJlJVVWV3OeIjQUFBOBwnPmJG4caHdLeUiEjTcjqdJzw+Q/yPBhT7UG3LjcKNiIiIfRRufKi25UbdUiIiIvZpFuFm5syZpKenExwczJAhQ1ixYsURj50zZw6GYdR5NJeF09QtJSIiYj/bw83cuXOZMmUKDzzwAKtWraJv376MGDGi3hHwkZGRZGZmeh87duxowoqPLNBpje7WJH4iIiL2sT3cPPXUU1x//fVMmjSJHj168MILLxAaGsqsWbOO+BrDMEhOTvY+kpKSmrDiIzt4VXDNnCkiImIPW8NNZWUlK1euZPjw4d5tDoeD4cOHs2zZsiO+rri4mPbt25OWlsbo0aP54YcfjnhsRUUFhYWFdR6NxVUzYt80odqjcCMiImIHW8NNbm4ubrf7kJaXpKQksrKyDvuarl27MmvWLD744ANee+01PB4Pp556Krt27Trs8dOmTSMqKsr7SEtL8/l11AoMODDpkAYVi4iI2MP2bqljNXToUCZMmEC/fv0488wzeffdd0lISODFF1887PFTp06loKDA+8jIyGi02mpvBQcNKhYREbGLrZP4xcfH43Q6yc7OrrM9OzvbO7X20QQGBnLyySezZcuWw+53uVy4XK4TrrUhnA4Dw7C6pRRuRERE7GFry01QUBADBgxg0aJF3m0ej4dFixYxdOjQBp3D7Xazbt06UlJSGqvMBjMM48BEfuqWEhERsYXtyy9MmTKFiRMnMnDgQAYPHswzzzxDSUkJkyZNAmDChAm0adOGadOmAfDwww9zyimn0LlzZ/Lz83n88cfZsWMHv/nNb+y8DK+gAAcV1R613IiIiNjE9nAzduxY9u7dy/33309WVhb9+vXj008/9Q4y3rlzZ51FtPbv38/1119PVlYWMTExDBgwgKVLl9KjRw+7LqEOtdyIiIjYyzBb2YQshYWFREVFUVBQQGRkpM/PP3TaIjILyvnPrb+id9son59fRESkNTqW7+8Wd7dUc3dgIj+3zZWIiIi0Tgo3PhboXRm8VTWIiYiINBsKNz6mMTciIiL2UrjxsUCtDC4iImIrhRsfc9W03Gj5BREREXso3PhYkFpuREREbKVw42OBTmvxTIUbEREReyjc+NiBW8EVbkREROygcONjQQFOQC03IiIidlG48TFvt5RabkRERGyhcONjrppuqSq13IiIiNhC4cbHNImfiIiIvRRufCxQ4UZERMRWCjc+pnluRERE7KVw42MHFs5UuBEREbGDwo2P1bbcaPkFEREReyjc+JhL3VIiIiK2UrjxMQ0oFhERsZfCjY8dGFBs2lyJiIhI66Rw42Oa50ZERMReCjc+FuhtuXHbXImIiEjrFGB3AX7DNKE8n8iKbACq3OqWEhERsYNabnzl5yXwWDoDv74e0N1SIiIidlG48ZXwJABc5bmA5rkRERGxi8KNr9SEm8CK/QRQrZYbERERmyjc+EpIDDisIUxxFFKhcCMiImILhRtfcTggLAGABCNf3VIiIiI2UbjxpfBEABKMAs1zIyIiYhOFG1+qGXeTYORrzI2IiIhNFG58qbblhgJ1S4mIiNhE4caXalpu4o0CqtwmHo8m8hMREWlqCje+dFC3FGh9KRERETso3PiS926pAkAT+YmIiNhB4caXaltuyAe0BIOIiIgdFG58qSbcJHpbbjTmRkREpKkp3PhSzd1S4UYZwVSo5UZERMQGCje+5IqAgBDAumOq0u22uSAREZHWR+HGlwzD23qTSD6V1eqWEhERaWoKN77mvR1cSzCIiIjYQeHG17zrS2kJBhERETso3PjaQYtnap4bERGRpqdw42sHzXWjlhsREZGmp3DjazUtN/FGAYXlVTYXIyIi0voo3PjaQQOKcworbC5GRESk9VG48bWDFs/cW6xwIyIi0tQUbnytdvFMCsgpKLO5GBERkdZH4cbXasbcuIwqSorybC5GRESk9VG48bXAEKoDIwDwFGbbXIyIiEjro3DTCNxhVusNJTn2FiIiItIKKdw0AkdkCgDhFTlUVGvxTBERkaakcNMIAmLSAGhj5LKvuNLmakRERFoXhZtGYES3A6CNsY+cIt0OLiIi0pSaRbiZOXMm6enpBAcHM2TIEFasWNGg17311lsYhsEll1zSuAUeq6i2gNVys1fhRkREpEnZHm7mzp3LlClTeOCBB1i1ahV9+/ZlxIgR5OTUPxh3+/bt3H333Zx++ulNVOkxiDrQLaVwIyIi0rRsDzdPPfUU119/PZMmTaJHjx688MILhIaGMmvWrCO+xu12M378eB566CE6duzYhNU2UE23VKqRS06hJvITERFpSraGm8rKSlauXMnw4cO92xwOB8OHD2fZsmVHfN3DDz9MYmIikydPPup7VFRUUFhYWOfR6CLbABBmVFCcv7fx309ERES8bA03ubm5uN1ukpKS6mxPSkoiKyvrsK/56quveOWVV3j55Zcb9B7Tpk0jKirK+0hLSzvhuo8qMJiyoDgAzPydjf9+IiIi4mV7t9SxKCoq4pprruHll18mPj6+Qa+ZOnUqBQUF3kdGRkYjV2mpCLdabwKKdjfJ+4mIiIglwM43j4+Px+l0kp1dd5mC7OxskpOTDzl+69atbN++nVGjRnm3eTweAAICAti0aROdOnWq8xqXy4XL5WqE6utnRqZB3veElO5p8vcWERFpzWxtuQkKCmLAgAEsWrTIu83j8bBo0SKGDh16yPHdunVj3bp1rFmzxvu4+OKLOeuss1izZk3TdDk1UECsVUtURRamadpcjYiISOtha8sNwJQpU5g4cSIDBw5k8ODBPPPMM5SUlDBp0iQAJkyYQJs2bZg2bRrBwcH06tWrzuujo6MBDtlut+D4dACS2UthWTVRoYH2FiQiItJK2B5uxo4dy969e7n//vvJysqiX79+fPrpp95Bxjt37sThaFFDgwAIjG0PQKqxj73F5Qo3IiIiTcQwW1mfSWFhIVFRURQUFBAZGdl4b5S1Dl74FblmJD9ds5pTOzdsALSIiIgc6li+v1tek0hLUbMEQ7xRSF5+vr21iIiItCIKN40lOJpyRygApXt32FyMiIhI66Fw01gMg0KXdTu7O79p5tYRERERhZtGVRaSCoCjQOFGRESkqSjcNCJ3zRpTQSWapVhERKSpKNw0ooCa28HDNEuxiIhIk1G4aUThSR0BiK3Kwu1pVXfci4iI2EbhphFFpfUEoLOxi5zCMpurERERaR0UbhqRM6ELHgyijRIy92hQsYiISFNQuGlMgSHkOK3bwYt3rbe5GBERkdZB4aaR5YV2AMCdvcnmSkRERFoHhZtGVhbVBYCg/T/ZXImIiEjroHDTyMyErgBEF/9scyUiIiKtg8JNIwtt0wOA5EqtLyUiItIUFG4aWWz7XgDEkU918T6bqxEREfF/CjeNLDEunt1mPAD7d+qOKRERkcamcNPIHA6DXQHtAChSuBEREWl0CjdNYF9I7e3gG2yuRERExP8p3DSBsqhOAATt32xzJSIiIv5P4aYpJHQDILJEt4OLiIg0NoWbJhCS2h2AmKocKC+0uRoRERH/pnDTBJKSksk2o60ne7UMg4iISGNSuGkCbWNC2eix7phyZ35vczUiIiL+TeGmCSSEu9hktAegLGOtzdWIiIj4N4WbJuBwGOSGnQSAO3OdzdWIiIj4N4WbJuJOsNaYCtm/ETwem6sRERHxXwo3TSS8bQ8qzECC3KWQr0U0RUREGovCTRPpnBTNT2Yb60m2lmEQERFpLAo3TaRLUrj3jikzS+NuREREGovCTRPpEB/GRqw7pip26XZwERGRxqJw00RcAU72h1t3TKlbSkREpPEo3DQhT1IvAIKLM7QMg4iISCNRuGlCbVPbsMeMtZ5k/2BvMSIiIn5K4aYJdUkKZ4PHGnejrikREZHGoXDThDonhrPB1B1TIiIijUnhpgl1SgjnRzMdgOrdWmNKRESkMSjcNKHgQCf7I7sB4Nz7I7irbK5IRETE/yjcNLGwpM4UmqE4PJWwd6Pd5YiIiPgdhZsm1jkpkh886daTTE3mJyIi4msKN02se0oEP5g1d0xlatyNiIiIryncNLEeKZGs93QAwFS4ERER8bnjCjcZGRns2rXL+3zFihXccccdvPTSSz4rzF91iA/jJ0dHAMys78HjtrkiERER/3Jc4eaqq65i8eLFAGRlZXHuueeyYsUK7r33Xh5++GGfFuhvApwOXEknUWYG4agqhbyf7S5JRETErxxXuFm/fj2DBw8G4O2336ZXr14sXbqU119/nTlz5viyPr/UrU2MdzI/jbsRERHxreMKN1VVVbhcLgAWLlzIxRdfDEC3bt3IzMz0XXV+6uBxN2SusbUWERERf3Nc4aZnz5688MILfPnllyxYsICRI0cCsGfPHuLi4nxaoD/qkRrJDzUzFet2cBEREd86rnDz2GOP8eKLLzJs2DDGjRtH3759Afjwww+93VVyZF2TD4QbT+ZaME17CxIREfEjAcfzomHDhpGbm0thYSExMTHe7TfccAOhoaE+K85fhbsCqIzpSkVxAK7yfGtQcVwnu8sSERHxC8fVclNWVkZFRYU32OzYsYNnnnmGTZs2kZiY6NMC/VWXNnHeRTTZvdLWWkRERPzJcYWb0aNH889//hOA/Px8hgwZwpNPPskll1zC888/79MC/VWPlEhWezpbT3Z9Z28xIiIifuS4ws2qVas4/fTTAXjnnXdISkpix44d/POf/+TZZ5/1aYH+qkfqweHmW3uLERER8SPHFW5KS0uJiIgA4LPPPuOyyy7D4XBwyimnsGPHDp8W6K96pkSy2rTCjZm1DqrKba5IRETEPxxXuOncuTPvv/8+GRkZzJ8/n/POOw+AnJwcIiMjj/l8M2fOJD09neDgYIYMGcKKFSuOeOy7777LwIEDiY6OJiwsjH79+vGvf/3reC7DVgkRLirD2rLXjMTwVEGWbgkXERHxheMKN/fffz9333036enpDB48mKFDhwJWK87JJ598TOeaO3cuU6ZM4YEHHmDVqlX07duXESNGkJOTc9jjY2Njuffee1m2bBnff/89kyZNYtKkScyfP/94LsU2hmHQJy2GNZ4u1gZ1TYmIiPiEYZrHN8lKVlYWmZmZ9O3bF4fDykgrVqwgMjKSbt26Nfg8Q4YMYdCgQcyYMQMAj8dDWloat912G3/4wx8adI7+/ftz4YUX8sgjjxz12MLCQqKioigoKDiuViZfmvH5ZkoXPc7/Bc6FnpfCr+fYWo+IiEhzdSzf38fVcgOQnJzMySefzJ49e7wrhA8ePPiYgk1lZSUrV65k+PDhBwpyOBg+fDjLli076utN02TRokVs2rSJM84447DHVFRUUFhYWOfRXPRpG+0dd6M7pkRERHzjuMKNx+Ph4YcfJioqivbt29O+fXuio6N55JFH8Hg8DT5Pbm4ubrebpKSkOtuTkpLIyso64usKCgoIDw8nKCiICy+8kOeee45zzz33sMdOmzaNqKgo7yMtLa3B9TW2Pm2j+N7TEY9pQEEGFB35mkVERKRhjivc3HvvvcyYMYPp06ezevVqVq9ezV/+8heee+457rvvPl/XeIiIiAjWrFnDt99+y6OPPsqUKVNYsmTJYY+dOnUqBQUF3kdGRkaj19dQ0aFBJMTFsclsa21Q642IiMgJO67lF1599VX+8Y9/eFcDB+jTpw9t2rTh5ptv5tFHH23QeeLj43E6nWRnZ9fZnp2dTXJy8hFf53A46NzZ6s7p168fGzZsYNq0aQwbNuyQY10ul3cF8+aob1o0q9d3prsjAzK+ge4X2V2SiIhIi3ZcLTd5eXmHHVvTrVs38vLyGnyeoKAgBgwYwKJFi7zbPB4PixYt8t6B1RAej4eKiooGH9+c9GkbzXJPd+vJ9q/tLUZERMQPHFe46du3r/fupoPNmDGDPn36HNO5pkyZwssvv8yrr77Khg0buOmmmygpKWHSpEkATJgwgalTp3qPnzZtGgsWLODnn39mw4YNPPnkk/zrX//i6quvPp5LsV2/tChvuDEz10B58xnwLCIi0hIdV7fUX//6Vy688EIWLlzobWFZtmwZGRkZ/Pe//z2mc40dO5a9e/dy//33k5WVRb9+/fj000+9g4x37tzpvdUcoKSkhJtvvpldu3YREhJCt27deO211xg7duzxXIrteqREsdcRzzZPEh0c2bDzGzjpPLvLEhERabGOe56bPXv2MHPmTDZu3AhA9+7dueGGG/jzn//MSy+95NMifak5zXNT64K/fck1e59kXMBiOPV3cN7R5+sRERFpTY7l+/u4w83hrF27lv79++N2u311Sp9rjuFm6rvrKP3uDf4W9HdI7Q83LLa7JBERkWalSSbxE98Z2D7mwKBijbsRERE5IQo3zcDgDrFkEcd2MxlMjzXuRkRERI6Lwk0z0DYmhOTIYJa6a28J/9LegkRERFqwY7pb6rLLLqt3f35+/onU0moZhsGgDrF8s64HV7FY4UZEROQEHFO4iYqKOur+CRMmnFBBrdXg9BieW9vDepK5FkrzIDTW3qJERERaoGMKN7Nnz26sOlq9gemx5BDDZrMtXdgF276AnpfaXZaIiEiLozE3zUTXpAgigwNY4q6Z4Xnr5/YWJCIi0kIp3DQTDofBwPRYvvT0tjZs+Rx8NwWRiIhIq6Fw04wMSo9lhacbVUYgFO6C3M12lyQiItLiKNw0I4M7xFCOi5VmzS3h6poSERE5Zgo3zUjvNtGEBTn5vKqntWHrInsLEhERaYEUbpqRoAAHp3SM43+evtaG7V9BdYW9RYmIiLQwCjfNzK+6xLPRTCPfEQNVpVqKQURE5Bgp3DQzp3eJBwwWV9fcNbX5M1vrERERaWkUbpqZTgnhJEcG81n1ydaGTZ/YW5CIiEgLo3DTzBiGwa+6xPOlpzduIwDytuqWcBERkWOgcNMMnd4lnmJCWeus6ZpS642IiEiDKdw0Q6d1jgfgg7KapRh++tTGakRERFoWhZtmKD7cRfeUSBZ5+lsbdn5jrRIuIiIiR6Vw00yd1TWBXWYCe4I6gOmGLQvtLklERKRFULhpps7pngjAR5X9rA2b/mtfMSIiIi2Iwk0z1S8thtiwID6uqLkl/Kf5UFFsb1EiIiItgMJNM+V0GAzrmsBasxN5rjbWbMVqvRERETkqhZtmbHj3JMDgQ8/p1obv59paj4iISEugcNOMnd4lnkCnwZziQdaGrYuhOMfeokRERJo5hZtmLCI4kCEd4thuppAT2cu6a2r9u3aXJSIi0qwp3DRz3rumUNeUiIhIQyjcNHPn9kgC4O97+2AaTtizCvb+ZHNVIiIizZfCTTPXNiaUfmnR5JpR7Io/zdq46lV7ixIREWnGFG5agIv6pADwRvXZ1oY1b0BVuY0ViYiINF8KNy3ABb2tcPNSVmfcEW2gLA82fGhzVSIiIs2Twk0LkBodwoD2MbhNB2sTLrY2fjfb3qJERESaKYWbFuLCmtabFwpPBcMJO5dCzkabqxIREWl+FG5aiNquqc92OSnreJ618btZNlYkIiLSPCnctBDJUcEM7hALwGehF1obV78GpXk2ViUiItL8KNy0IGMHpgHw5JY2mEm9oKoEvnvF5qpERESaF4WbFuSC3ilEuALYub+MzZ2vszYuf1G3hYuIiBxE4aYFCQlycnG/VMCasZioNCjZC2vftLkyERGR5kPhpoW5clA7AP77Qy6l/W+wNi59FjxuG6sSERFpPhRuWphebSLpkRJJpdvDO+Y5EBwNeT9bsxaLiIiIwk1LYxgGVw62BhbPWbkXz+l3WTsWPwqVJTZWJiIi0jwo3LRAl/VvS4QrgJ/3lvC/6Eshuh0UZcKyv9tdmoiIiO0UblqgcFcAYwdZrTf/WLYHzr7f2vH1M1C8177CREREmgGFmxZq4qnpOAz4aksuGxPOhZR+UFkMX0y3uzQRERFbKdy0UGmxoYzslQzA7K93wnl/tnZ8NxtyN9tYmYiIiL0Ublqwyb/qAMB7a3aTEz8IThoJphsWPmhvYSIiIjZSuGnB+reLoX+7aCqrPbz0xc8w/CEwHLDxI9ix1O7yREREbKFw04IZhsHvzukCwGvLd7A3pAOcfI2187P7wDRtrE5ERMQeCjct3JknJdA3LZryKg//+PJnOOuPEBgGu7+DH9+3uzwREZEmp3DTwhmGwe3ndAbgn8t2sM+IgVNvs3YufAiqK22sTkREpOkp3PiBs7om0rtNFGVVbl76389WuAlPgv3b4LtX7C5PRESkSTWLcDNz5kzS09MJDg5myJAhrFix4ojHvvzyy5x++unExMQQExPD8OHD6z2+NTAMgzvPtcbezFm6nazyABg21dr5xV+hLN++4kRERJqY7eFm7ty5TJkyhQceeIBVq1bRt29fRowYQU5OzmGPX7JkCePGjWPx4sUsW7aMtLQ0zjvvPHbv3t3ElTcvZ3VNZFB6DBXVHp79fLM1sDi+K5TlwRJN7CciIq2HYZr23lIzZMgQBg0axIwZMwDweDykpaVx22238Yc//OGor3e73cTExDBjxgwmTJhw1OMLCwuJioqioKCAyMjIE66/Ofl2ex6/fmEZTofBwiln0iH/G3jtMuv28BuWQEpfu0sUERE5Lsfy/W1ry01lZSUrV65k+PDh3m0Oh4Phw4ezbNmyBp2jtLSUqqoqYmNjD7u/oqKCwsLCOg9/NSg9lrO7JeL2mDz52SbofA70vAxMD/znDvC47S5RRESk0dkabnJzc3G73SQlJdXZnpSURFZWVoPOcc8995CamlonIB1s2rRpREVFeR9paWknXHdz9vsRXTEM+Oj7TNZk5MOIv4ArEvasgpWz7S5PRESk0dk+5uZETJ8+nbfeeov33nuP4ODgwx4zdepUCgoKvI+MjIwmrrJpdU+JZEz/tgD8+aMfMSOS4ez7rJ0LH4aibBurExERaXy2hpv4+HicTifZ2XW/cLOzs0lOTq73tU888QTTp0/ns88+o0+fPkc8zuVyERkZWefh7+4+ryshgU6+27GfT9ZnwaDJ1qrhFQXw2b12lyciItKobA03QUFBDBgwgEWLFnm3eTweFi1axNChQ4/4ur/+9a888sgjfPrppwwcOLApSm1RkqOCueGMjgBM+2QDFR5g1DPWwOJ182DrYlvrExERaUy2d0tNmTKFl19+mVdffZUNGzZw0003UVJSwqRJkwCYMGECU6dO9R7/2GOPcd999zFr1izS09PJysoiKyuL4uJiuy6hWfrtmR1JjHCRkVfGrK+2Q+rJMOh6a+fHd0FVua31iYiINBbbw83YsWN54oknuP/+++nXrx9r1qzh008/9Q4y3rlzJ5mZmd7jn3/+eSorK7n88stJSUnxPp544gm7LqFZCg0K4J6R3QB47vPNZBaUwdn3Qngy5G2FJdNsrlBERKRx2D7PTVPz53lufsnjMfn1i8tYuWM/o/qm8ty4k2Hjx/DWVVYX1aRPod0Qu8sUERE5qhYzz400LofD4OHRPXEY8J+1e1i2dR90uxD6jrPmvnn/RqgssbtMERERn1K48XM9U6MYP6Q9APd/sJ7Kag+MnA4RqZD3s7VyuIiIiB9RuGkF7j6vK/HhQWzOKebFL7ZCSDSMtpa7YMWL8PMSO8sTERHxKYWbViAqNJD7LuoBwHOfb2Hr3mJraYaBk60DPrgVygtsrFBERMR3FG5aiYv7pnLmSQlUuj388d11mKYJ5z4MMelQkAHz/2h3iSIiIj6hcNNKGIbBny/pRXCgg+Xb8nh9+U5whcMlzwMGrH4N1r1jd5kiIiInTOGmFUmLDeX3I6y5bx79eAPbc0ug/alw+hTrgA9uhaz1NlYoIiJy4hRuWplJp6ZzSsdYyqrc3DVvLW6PCWfdC53OhuoymHs1lOXbXaaIiMhxU7hpZRwOgyd+3ZdwVwArd+znpf/9DA4njHkFotrB/m3w7g3g8dhdqoiIyHFRuGmF2saEcv8o6+6ppxZsYkNmIYTGwth/QUAwbJ4P//urzVWKiIgcH4WbVurXA9oyvHsSVW6TO+euoaLaDan94KKnrQOWTINNn9pao4iIyPFQuGmlDMNg2mW9iQ0LYmNWEX9buNna0e+qA6uHv3sD7N1kX5EiIiLHQeGmFUuIcPGXS3sD8MIXW1m6NdfaMeIv0G4oVBTA67+GklwbqxQRETk2Cjet3Mheyfx6QFs8JvzuzTXkFJZDQBCMfd2a4C9/h7WKeFW53aWKiIg0iMKN8PDoXnRLjiC3uILb3lxNtdsDYXFw1TwIjoKM5fDBLWCadpcqIiJyVAo3QkiQk5nj+xMW5GT5tjyeWvCTtSPhJLjiX+AIgPXvwJLp9hYqIiLSAAo3AkCnhHAeu7wPAH9fspVFG7KtHR3PPHAH1RfT4fu3bapQRESkYRRuxOuiPqlMHNoegClvryUjr9Ta0X8CnHaH9fsHt8COZfYUKCIi0gAKN1LHHy/sTt+2URSUVXHrG6sor3JbO855ALqPAnelNcA472d7CxURETkChRupwxVgjb+JDg1k7a4C/vjuOkzTBIcDLn0JUk+Gsjx4/QoozbO7XBERkUMo3Mgh2saEMvOq/jgdBu+u3s3LX9a00gSFwri3ILIN7NsM/7xYAUdERJodhRs5rNM6x3P/Rdb6U9M+2cjCH2sGGEckw9XvQlgiZK1TwBERkWZH4UaOaMLQ9owb3A7ThFvfXMWqnfutHYnd4NqPDgScORdC4R57ixUREamhcCNHZBgGD4/uyVldEyiv8nDdnG/ZklNs7UzoagWc8GTI+RFeGQG5W+wtWEREBIUbOYpAp4OZ4/vTNy2a/NIqJs5aQXZhzVIMCV1h8mcQ2wkKdsKsEZCzwd6CRUSk1VO4kaMKDQpg9rWD6Bgfxu78MibOWkFBWZW1M6Y9XDcfUvpCaS78czTs22pvwSIi0qop3EiDxIYF8ep1g0mIcLExq4gb/vndgTlwwhPgmvchqRcUZ1sBJ3+nrfWKiEjrpXAjDZYWG8qcSYMIdwWwfFseU95eg9tTs5hmaKwVcOK6QEEGzBoJORttrVdERFonhRs5Jj1To3jpmgEEOg3+uy6Lh//zgzXJH1gtOBM/hPiToHC3NQZn53J7CxYRkVZH4UaO2amd43nqin4YBry6bAczPj/oLqnIVGsMTttBUJ5vdVFt+sS2WkVEpPVRuJHjMqpvqneSvycX/MTL/ztoranQWJjwAXQZAdVl8NZ4WP2aTZWKiEhro3Ajx23SaR24c/hJADz63w3M+mrbgZ1BYXDl69D3KjDd1mriXz4JtV1YIiIijUThRk7I7cO7cNvZnQF4+KMfefGLg24DdwbCJX+HX91pPV/0MHz6B/B4bKhURERaC4UbOWFTzj2Jm4d1Aqx1qB6fv/HAIGPDgOEPwohp1vPlL8Dcq6Fgtz3FioiI31O4kRNmGAb/N7Ib/zeyKwAzF2/l/g9+wOM5qAtq6M0w5hVwBMKmj2HGQFjyGFRX2lS1iIj4K4Ub8Zmbh3XmkUt6YRjwr292cNe8tVS5D+qC6n05XL8I2g2FqlJY8hd49SIoyravaBER8TsKN+JT15zSnmfG9sPpMHhv9W5uem3VgZmMwVqmYdInViuOKwoylsNLw2DXd7bVLCIi/kXhRnxudL82vHj1AIICHCzckM11c76luKL6wAGGUdOK87k1o3HRHnjlXPh0KlQU2Ve4iIj4BYUbaRTDeyTx6qTBhAU5Wbp1H+P/sZz80l+Mr4nvbHVT9bocTA9883eYOQR2rbSnaBER8QsKN9JohnaK443rTyE6NJC1Gflc8eIysgrK6x4UHAWXvwJX/xti0q1lG+ZcCBs+sqVmERFp+RRupFH1TYvm7d8OJSnSxU/ZxYx5finbcksOPbDzcLjxK+tndZl1u/iS6bqbSkREjpnCjTS6k5IieOfGU0mPC2V3fhmX/v1rFm04zB1SrggYNxcGXgeYsGQavHiGFt8UEZFjonAjTSItNpR3bjqVvm2jyC+tYvKr3/Hoxz9SWf2L2YqdAXDhU3DZPyA0HvZusFYX/2gKlBfYU7yIiLQoCjfSZOLDXbx941AmnZYOwMtfbuPXLy4jI6+07oGGAX1+Dbd+C/2uBkz47hWYMRh+/FDrU4mISL0M02xd3xSFhYVERUVRUFBAZGSk3eW0WvN/yOL389ZSWF5NRHAAj1/eh5G9Ug5/8Lb/wX/ugLyadau6XggXPA5RbZqsXhERsdexfH+r5UZsMaJnMv+9/XRObhdNUXk1N762igc+WE9FtfvQgzucATcthTN+D44Aa/mGmUNg+UvgOczxIiLSqqnlRmxV5fbwxPxNvPi/nwHo1SaSGeP6kx4fdvgXZP8I/7kddq2wnrcZCJe+APFdmqhiERGxg1pupMUIdDqYekF3Zl87iJjQQNbvLuSi577iP2v3HP4FST3guvlw4ZPgioTd31nLN6x/t0nrFhGR5kstN9JsZBaUcfuba1ixPQ+AKwa25b6LehARHHj4FxTugX9fDzu+sp73GQtDfgup/a1BySIi4jeO5ftb4UaalWq3h2cXbea5xVswTWgTHcITv+7L0E5xh3+BuxoW/xm+evrAtuTecPpd0H00ONQ4KSLiDxRu6qFw0zIs/3kfd7+zloy8MgAmnZbOPSO7ERzoPPwLMlbAipfhxw/AXWFtS+oNZ/0Rup6vlhwRkRZO4aYeCjctR3FFNY9+vIE3V+wEoGNCGE9d0Y9+adFHflFpHix/EZbNhMqaFcZT+1shp9M5askREWmhWtSA4pkzZ5Kenk5wcDBDhgxhxYoVRzz2hx9+YMyYMaSnp2MYBs8880zTFSpNLtwVwLTLejN70iASI1z8vLeEMc8v5cnPNh06s3Gt0Fg4ayrc8T386k4IDIU9q+D1y2HGQFg6wwpAIiLit2wNN3PnzmXKlCk88MADrFq1ir59+zJixAhycnIOe3xpaSkdO3Zk+vTpJCcnN3G1Ypezuiby2Z1ncHHfVNwek+c+38LFM77iy817j/yi0FgY/iDc/j0MvRWCIqxJAD+7F57sBu/dCLtXNtk1iIhI07G1W2rIkCEMGjSIGTNmAODxeEhLS+O2227jD3/4Q72vTU9P54477uCOO+44pvdUt1TL9vH3mfzp/XXsL60C4IyTEph6fje6pxzls6wohnXzrGUcstYd2N75XKulp82ARqxaREROVIvolqqsrGTlypUMHz78QDEOB8OHD2fZsmV2lSXN3IV9Uvj8rmFcd1oHAp0G//tpLxc8+yW/n7eWrILyI7/QFQ4DJ8Fvv4TJC63bxg0nbFkAL58Nsy+Ade9AdWXTXYyIiDQK28JNbm4ubrebpKSkOtuTkpLIysry2ftUVFRQWFhY5yEtW0xYEPeP6sHCKWdyYe8UTBPmrdzFWU8s4blFmymvqmdJBsOAtEFw2UvWwpx9r7JCzo6v4d+T4ekesPBB2L+jya5HRER8y/YBxY1t2rRpREVFeR9paWl2lyQ+0j4ujJnj+/Pvm06lf7toyqrcPLngJ8558gvmfL2Nkorq+k8Q1wkufR7uWAdn/gEiUqBkrzVnzt/6WC06Xz4J+Tub5oJERMQnbAs38fHxOJ1OsrOz62zPzs726WDhqVOnUlBQ4H1kZGT47NzSPAxoH8O/bzqVv13Zj5SoYHbnl/Hgf37klGmLeHz+RvJLj9LVFNWm5g6rdXDFv6DjMGv77pWw6GF4tj98NAUKMxv9WkRE5MTZFm6CgoIYMGAAixYt8m7zeDwsWrSIoUOH+ux9XC4XkZGRdR7ifwzDYHS/Nnx+1zAeuaQXHePDKCqvZubirZz+2GKeXvATeSVHCTnOQOhxMUz4AO7aBBc9A+mng6fKGoj8TC949WJY9nfYt7VJrktERI6drXdLzZ07l4kTJ/Liiy8yePBgnnnmGd5++202btxIUlISEyZMoE2bNkybNg2wBiH/+OOPAFxwwQWMHz+e8ePHEx4eTufOnRv0nrpbqnXweEwWbMjm6QU/sTHLmswvONDBmP5tue5XHeiUEN7wk23/Cj7/M+z8xUD3+JPgpBFw0khIOwWcAT68AhEROViLmqF4xowZPP7442RlZdGvXz+effZZhgwZAsCwYcNIT09nzpw5AGzfvp0OHTocco4zzzyTJUuWNOj9FG5aF4/H5L/rM3nhi62s331gMPnw7olMOq0DQzvG4XA0cGmGfVvhp/nw0yewYyl4DhrTExwFaUOsW8rbnQLtToWAIB9fjYhI69Wiwk1TU7hpnUzTZPm2PP7x5c8s3HBgksg20SGM7pfK1ae0JzU6pOEnLC+ALYussLP5Myj7xazHQeHW2J1eY6DrBRAY7JsLERFppRRu6qFwI1v3FjP76218sGYPReVW60ug0+DyAW258cxOtI8LO7YTetywZ7U1AHnXd/DzEig5aJZtVxR0PBOSekJSL2h/qjWDsoiINJjCTT0UbqRWeZWbRRty+Oey7SzfZrW8OAwY3a8Nt5zVic6JEcd3Yo8Hsr6HDR/C2rlQuOvQY5J6Q8/RMGAShMWfwFWIiLQOCjf1ULiRw/luex4zFm9hyaYD61X1S4vmgt7JXNQn9di6rA7m8VgDkfesgpwNVuvO3o0H9jtd0Pty6HOFdWeWw3mCVyIi4p8UbuqhcCP1WbergOc+38yCDdnU/stwGDCsayJXDkrj7G6JBDhPcAaF4hzYshBWvGR1Z9UKS4TOw6HDGZA2GKLaQoDrxN5LRMRPKNzUQ+FGGiKnqJz5P2Tz0do93i4rgKRIF78ekMbofql0TgzHMBp4p9XhmCZkrIC1b8CPH0DZ/l8cYFizJke3g+g0SOwBHc6ElL667VxEWh2Fm3oo3Mix2pZbwlvf7uSd73ax76CJANNiQzinWxJnd0tkSMdYXAEn0KXkroLtX8K2/8HPX1hdV1Wlhz/WFQVdzoXuF1l3ZIXEHP/7ioi0EAo39VC4keNVWe1hwY/ZzFuZwdKt+6is9nj3hQU5GdkrhauGtKN/u+gTa9EBq1WndB/k77DWttq/3boTa/uX1m3oB4vpAG36Q+rJkNofYjtCWIJad0TEryjc1EPhRnyhtLKar7fs4/ON2SzakENOUYV3X3pcKKd1jufUTvGccVI8EcGBvntjj9salLzhP7DpE9i3+fDHGQ4r5HQZAV1HQttBEHicg6JFRJoBhZt6KNyIr5mmyaqd+3ljeQYffb+HioNadIKcDk7tHMewkxLo3z6G7imRBJ7ogOSDleZB5hrYvcoanJz5PRTuBtNd9zjDaY3ZcYVbrUAleyG6PSR0g4SukNjd+hnXBYJCfVefiIiPKNzUQ+FGGlNReRXLf85j6dZ9fPFTDlv3ltTZHxLo5NROcQzrlsjQjnF0jA9r+PIPDeVxW+Fl17dW687mBXUnFayXATEHhZ7kPtD5HI3rERHbKdzUQ+FGmtKWnCLm/5DNt9vzWL0zn4Kyqjr7o0ICGZQey5j+bTinexJBAT5s1allmlC4x2rZcVda4SU0HvZvg72brPl39m6CvRsOc8cW4AiAdkOtyQbdVdbt6eFJ1p1cST2tsT6acVlEGpnCTT0UbsQupmmyIbOIJT/l8MWmvazJyK/ThRUXFsSwrokM7RRH/3bRtI0JbZywc+QCoSTXulNr70Yr9OxYaoWeowlLtG5Xj+kAPS+1Vkt3+nCskYi0ego39VC4keaiyu3hxz2FfPpDFv9euavOoGSwJg9MiQqhb1oU/dvFMDA9lh4pkU0beMBaDX3bF1arjSMAqsqgOBsKMqwxPnlbD31NeBLEn2QdW11u/XRXWt1c3S+y5usJS9DK6SLSYAo39VC4keao2u1h2c/7WLp1H8u27mNTVhFlVe5DjnMFOOjbNpr+7WMY0D6G/u2iiQu3eRbj8gLI2wYFuyDjG1jzJpTmNuy1QeHWTMzR7WtuXw+0lqCoLIWqEohKs2Ztbn+qZmsWaeUUbuqhcCMtgWma7C2uYGtOCasz9rNqx35W7tjP/tKqQ45Niw2hX1oM/dKiObldND1SIgkOtHGNqupKq6WnvMC6/TwgGAJDAdNaMX3DR5Dzo/W8oZxBENcZ4rtYd35VFNbcAdbNugssLAGCoyAiGSLbQO08Qx63dVv8ic47JCK2U7iph8KNtFSmabItt4SVO/azaud+vtu+ny17i/nlv+BAp0GPlEh6t42iU0I4nRLC6d8+hnBXM5rUz+OBigIo2QcFO2H/DijPt7q+PNVWGAoIhqx11jpcxVkNP7crEmI7WLfJF+6xWoNi0q3gU1kKlcVW99jQm62lLESkRVC4qYfCjfiTwvIq1u0qYPXO/azJyGdNRj65xZWHHBfgMBiYHsPgDtbt5+nxYXSICyMqtAUM+jVNa26e3J9g3xarJcYVCdVlB+70Ks2zWnOKMq1w1FBJva3w464CdwVU14x7CgqzHgldrbvBknpZLUchsVC4y6rFNK3noTEQGmfVdKQWIncVmB51rYmcAIWbeijciD8zTZNd+8tYnZHPxsxCtu4t5sfMQjLyyg57fGxYEOlxod6wkx4fRoea8NOsWnoaqrrSCkD7t1u3rke2sUJL3jZrNXZXODgCYd08+OG9Qyc7PBpHwJHDkyPAmg8oJNYKO6GxVkDK/Qmyf7BeF9fFCkwBLivsBIVDZKp1W33tzwCXFYaqy6xb8yuKILFnTZecutek9VK4qYfCjbRG23NL+OKnvWzILGRbbgnb95WQXVhR72sSIlyclBRuLSPRJYGOCWGEBjlPfN2s5qJglzWzszPQGtMT4AJnTctKVYkVLLLWWzNA791kHY9phaO4ztbryvZba4AdaZFTX4rtBGmDrQHXjgCISLW628Bag6w4xxp3FBZvhSbveKeaMU8hMdYt+yEx4DiGO+5MU6FKmgWFm3oo3IhYSiqq2b6vhO25pWzfV8LPe0tqnpfUWf38YMGBDlKiQqyxPIlhJIS7iAsPIjbMRVxYEAkRLhIjXP4TgA5WVWbN/ByReuiipFXlUJZnBZ3SvAO/lxdaASS1nxU0sn+0WpZMjxUYyguscUGFe6wutcI9VmuSI9A6PiTGCl2Za8Fz6GDy4+IIsAZgh8VbK8y7wq3uuKIs6y43Z5AVhtwV1rVUlkBwpNUiFZFs3cEWHGkdX5xjtVLFdoSoNlZLldNljZ8q2Wtdf3UZYEDaEGu2a6cLcjdZk0r+/IV1h11QBCScZA0ObzvIGguVv8NaR83jgbYDoM1A632PxDSt6QkKdlldhCHR1mdVX5BzV1nTGhRlW7N4R7e3liLxx/9+/YDCTT0UbkSOrqCsiu25Jazdlc//ftrL8p/zKKpo2FiW0CAnnRLC6dM2il91jmdgeixRIYFNPz+PP6kogq2fW3MOYVpfygW7rO43sGadDku0jivNtQKJd46hcqtlqSzv8DNQtyRR7azuucCQA112AcFWAMzdfOjA8/Bk6HKuNZN2cU5NkMm0wkxxlhVAfymhG3S7yAprwdGQv9Ma2F642+paND3WewaFWfsjU60QWrDLmvOpusLaHxxpvW9KPys0hcRYr89eb7UEhiVYQSom3Wpp+2UIKy+Agt3WGLPaKRIcNWPkqms+U0eg9bdwOK3Pu6r0wM/AMEjqAa6IY/sb/7KlrqrcqiUkxvZ5qRRu6qFwI3J8SiuryS2qZNf+UjbnFLMtt4Tc4gr2l1ayr7iSvJJK9pVU4vYc/n9SggIcJIS7SIx00SY6hC6JEXRODCc5ymW1/IQHEeEK8M9Wn+aiutIKP8XZ1mzUFYVWEDKcEJliBSR3pfXl6AyyWmWCwq0vt9J9ULQH8jOsUBGRDOGJVgvNvp+tsFAbqIKjrZah4Cjry7ey1JoGYPdKwLRCSmJ3SP+V9XBXWl/4Wd9DxnJrjFJUW2gzwKpt1worZByNI8B6XWVNt2JDBpc7AqxJJ0PjrJm53YdvtWx0gWFWK5r3793AuaKOJibdGhCf1MsKYrXjvfIzrHCcv8O6W7Ek50B4cwRaC+h6PFBZVHMiw/o7BUce+Lu6IqxWstqB8gHBVstedDtrEs8uw31zDTUUbuqhcCPSeKrcHnbmlbI5u4hvfs7jqy25bMkpbvDrA50GcWEukqKCSYkMJjw4AIcBwYFOOsaH0TkxgrTYEJIig+2dy0eOT3mh1coQFFb/cR7PoS0ZJbnW4OzczdaXa2isFQSqK6xQFdXGaiWpXdW+ugJ2fA0/fWaFsvCkA2uiRSRZrToRyVZ3W+17leXDxo9g5zcHuhcjkiG5t9X15gyyWlKqy6Gi2NpfuMc6NqqNNS7KFW61dpTstVp8sr63uvDKC6wWkbgu1vxMJbnWfE/1taaFxACGNV+Tp2aaBNO0ug0Dg63nlaXWz6DQmu0h1s/SPOu67ZLSD377hU9PqXBTD4UbkaZV5fZQWuGmsLyK3OIKsgvLawJQMVv3FpNb0+pT3MBur1pRIYEkRwaTFBVMcqSL5MhgUqNDSI8PIz0ujKiQQIIDHWoJkubB47YeB3ftmOaBoFRZZLU4VRRbASW2Y/1jjBqiZB/k/GC1hGWvtwJPdbnVOhOVZnVnRqdbPyOSa8Kb80DrneE4MM1B6T5rTFNVmRVQwWrBK8u3gpdpWq8pyLBa2WLSYfiDJ1b/Lyjc1EPhRqR5Kq9ys6+kktyiCrIKy8kqKKesyo3HNCkqr2ZrTjFb9haTmV9+2KUpDsfpMAhyOjAMa64fa8BzMEEBDjymSXCgkwHtYxjSIdYbiBwOhSGR5kjhph4KNyItm2maFJZXk10TgLIKy8kptH5m5JWxLbeEXftLOcLQn3o5DAgNCsAAMMAAHA6DiOAA2kaHkhYbQlpMKGmxocSEBREc4CA40ElIkJPgACfBgQ5cgU7CgpwEODWAWsSXjuX7uwXO0iUirZlhGESFBBIVEshJSYe/E8TjMSmtclNcXk2V24NpQqXbTU5RBXuLKqhymzgdsK+4kuXb8li1Yz/7SirxmBy2eyy/tIqMvDKW/dzQGiE+3EVSpIvQwAACA6zWoKpqk2qPh4jgQGJCA4kODSIqJJDo0NpHENEh1s8wlxODuq1IIUHOljm5okgTU8uNiAjW2KD9pZWUVrgxsVqIrNYfk/2lVWTklZKRV0bG/lIy8kopLK+mospNeZWb8mqP9bPKfVwtRsciNiyIdrGhtIsNpX1cKHFhQQQ4HQQ6DQKdDgKcDoKcBgEOB4EBDgIdBoEBDoIDnIQEOQgJCiC0prXJFaAxSdJyqOVGROQYBTodJEYEwxGmBRmUHnvUc5imSZXbpKCsiuzCcrILy6mo9nhbj4ICHDgMKCqvJr+0ivyySuvnL38vraSk8sC4otr8YZqQV2INwF6TkX/C12wYEBLoJDTISXDNz5Ca4GNtD8AV6MBhGDgMcBgGRs3vgU4HTodBgMMgwGngCnASFRJIZEgAAQ5rX+1rHIaB02FgGBDuCiA6NIiI4AAqqz1Uuj3Wz2oPgLdVLjIkEGfN+KfSSuvvFRMaREiQ7pKTo1O4ERHxEcMwCAqwBi4nRLjo1SbKp+cvKq9iZ57VcrRjXyk78kopKKui2u2hym1S5fZQXfOzymNSVe2h2mMFh4pqD6WVbsqq3N4gYZpQWummtPIY19hqIhGuADymWSfoRQYHkBQZTFJkMLFhQRiGdR2uAAdhLiuM/bI7z+mwxlKFBDq9IQuoGVtleH83DDAwCHQaJEcFkxIVTEhQAM7acOcwan43cDioCXDWw2OauD0mbtPE4zExDIMIV4AGqNtE4UZEpIWICA6kZ2oUPVNPLDRVuz2UV3soraymvNJDaVU1ZZVu61Hl9oagssoDXW0e0/R21VV7rC/wao+J2+Oh2mNSXuWmoKyKwrJqqj0ePB7rNe6a15imSbXbpKSymv0lVstUoNO6my0owOoiM02r1as2zBw8K7bTYeD2WIPJC8uL2XwM8yfZJcBhEBtmtTY5DMMboKwWMCtIBTgNwlwBhLsCCK0ZUxUU4PDGsyN1Gx68uTbM1d124DhXzWD34EDr7+wKtFrqagfEB9eEvsqaVsagAIe1jhwGpZXVlFa6Kan5GeAwiAt3ER0SSJXbCs217+EKcFiD6gOsVsC4cJfP/6YNpXAjItLKBDgdhDsdzXZwcpXbQ2FZFfllVRhAYmQwYUFOiiqqySksJ7vQmi8p76A10Cpqw1qV55DzVbsPtFqZJphYA6NME+/z2tGnJta0BNmF5WQWWN2KHo+JxzsGq+GqPSY5RfUvUOuv+qZF88Etp9n2/s3zv2wREWm1Ap0O4sJdh/x//pHBgUQGB9I58RjXS/KR2par2i4oz0HPHUZNl5UDAhwOqj0ea0mS4koqqj3e15o1rVlY/0dltYeSympKKqopqXBTUmHd4Qdg1nnvg34/aM/Boeywx5omFQcNeD/wu4fyautnRbWbardJUICDAIdBpdtDeaXVYhfqchIWZLUqhQY5qXKb5BZXUFhWRWCAo6bFzQqXFdXW+SuqPIQE2jsVgsKNiIhIAxiGgdMAJwZHW/3D6XCSEhVCSlRI0xQndWiWKREREfErCjciIiLiVxRuRERExK8o3IiIiIhfUbgRERERv6JwIyIiIn5F4UZERET8isKNiIiI+BWFGxEREfErCjciIiLiVxRuRERExK8o3IiIiIhfUbgRERERv6JwIyIiIn4lwO4CmpppmgAUFhbaXImIiIg0VO33du33eH1aXbgpKioCIC0tzeZKRERE5FgVFRURFRVV7zGG2ZAI5Ec8Hg979uwhIiICwzB8eu7CwkLS0tLIyMggMjLSp+durnTNumZ/1dquubVdL+iaW9o1m6ZJUVERqampOBz1j6ppdS03DoeDtm3bNup7REZGtrj/aE6Urrl10DX7v9Z2vaBrbkmO1mJTSwOKRURExK8o3IiIiIhfUbjxIZfLxQMPPIDL5bK7lCaja24ddM3+r7VdL+ia/VmrG1AsIiIi/k0tNyIiIuJXFG5ERETEryjciIiIiF9RuBERERG/onDjIzNnziQ9PZ3g4GCGDBnCihUr7C7JZ6ZNm8agQYOIiIggMTGRSy65hE2bNtU5ZtiwYRiGUedx44032lTxiXvwwQcPuZ5u3bp595eXl3PLLbcQFxdHeHg4Y8aMITs728aKT1x6evoh12wYBrfccgvgH5/x//73P0aNGkVqaiqGYfD+++/X2W+aJvfffz8pKSmEhIQwfPhwNm/eXOeYvLw8xo8fT2RkJNHR0UyePJni4uImvIpjU981V1VVcc8999C7d2/CwsJITU1lwoQJ7Nmzp845DvffxvTp05v4ShruaJ/ztddee8j1jBw5ss4x/vQ5A4f9t20YBo8//rj3mJb2OddH4cYH5s6dy5QpU3jggQdYtWoVffv2ZcSIEeTk5Nhdmk988cUX3HLLLXzzzTcsWLCAqqoqzjvvPEpKSuocd/3115OZmel9/PWvf7WpYt/o2bNnnev56quvvPvuvPNO/vOf/zBv3jy++OIL9uzZw2WXXWZjtSfu22+/rXO9CxYsAODXv/6195iW/hmXlJTQt29fZs6cedj9f/3rX3n22Wd54YUXWL58OWFhYYwYMYLy8nLvMePHj+eHH35gwYIFfPTRR/zvf//jhhtuaKpLOGb1XXNpaSmrVq3ivvvuY9WqVbz77rts2rSJiy+++JBjH3744Tqf/W233dYU5R+Xo33OACNHjqxzPW+++Wad/f70OQN1rjUzM5NZs2ZhGAZjxoypc1xL+pzrZcoJGzx4sHnLLbd4n7vdbjM1NdWcNm2ajVU1npycHBMwv/jiC++2M88807z99tvtK8rHHnjgAbNv376H3Zefn28GBgaa8+bN827bsGGDCZjLli1rogob3+2332526tTJ9Hg8pmn632cMmO+99573ucfjMZOTk83HH3/cuy0/P990uVzmm2++aZqmaf74448mYH777bfeYz755BPTMAxz9+7dTVb78frlNR/OihUrTMDcsWOHd1v79u3Np59+unGLaySHu+aJEyeao0ePPuJrWsPnPHr0aPPss8+us60lf86/pJabE1RZWcnKlSsZPny4d5vD4WD48OEsW7bMxsoaT0FBAQCxsbF1tr/++uvEx8fTq1cvpk6dSmlpqR3l+czmzZtJTU2lY8eOjB8/np07dwKwcuVKqqqq6nzm3bp1o127dn7zmVdWVvLaa69x3XXX1Vlg1t8+44Nt27aNrKysOp9rVFQUQ4YM8X6uy5YtIzo6moEDB3qPGT58OA6Hg+XLlzd5zY2hoKAAwzCIjo6us3369OnExcVx8skn8/jjj1NdXW1PgT6yZMkSEhMT6dq1KzfddBP79u3z7vP3zzk7O5uPP/6YyZMnH7LPXz7nVrdwpq/l5ubidrtJSkqqsz0pKYmNGzfaVFXj8Xg83HHHHZx22mn06tXLu/2qq66iffv2pKam8v3333PPPfewadMm3n33XRurPX5Dhgxhzpw5dO3alczMTB566CFOP/101q9fT1ZWFkFBQYf8j39SUhJZWVn2FOxj77//Pvn5+Vx77bXebf72Gf9S7Wd3uH/LtfuysrJITEyssz8gIIDY2Fi/+OzLy8u55557GDduXJ1FFX/3u9/Rv39/YmNjWbp0KVOnTiUzM5OnnnrKxmqP38iRI7nsssvo0KEDW7du5Y9//CPnn38+y5Ytw+l0+v3n/OqrrxIREXFIV7o/fc4KN3JMbrnlFtavX19n/AlQpy+6d+/epKSkcM4557B161Y6derU1GWesPPPP9/7e58+fRgyZAjt27fn7bffJiQkxMbKmsYrr7zC+eefT2pqqnebv33GUldVVRVXXHEFpmny/PPP19k3ZcoU7+99+vQhKCiI3/72t0ybNq1FTuN/5ZVXen/v3bs3ffr0oVOnTixZsoRzzjnHxsqaxqxZsxg/fjzBwcF1tvvT56xuqRMUHx+P0+k85E6Z7OxskpOTbaqqcdx666189NFHLF68mLZt29Z77JAhQwDYsmVLU5TW6KKjoznppJPYsmULycnJVFZWkp+fX+cYf/nMd+zYwcKFC/nNb35T73H+9hnXfnb1/VtOTk4+5EaB6upq8vLyWvRnXxtsduzYwYIFC+q02hzOkCFDqK6uZvv27U1TYCPr2LEj8fHx3v+W/fVzBvjyyy/ZtGnTUf99Q8v+nBVuTlBQUBADBgxg0aJF3m0ej4dFixYxdOhQGyvzHdM0ufXWW3nvvff4/PPP6dChw1Ffs2bNGgBSUlIaubqmUVxczNatW0lJSWHAgAEEBgbW+cw3bdrEzp07/eIznz17NomJiVx44YX1Hudvn3GHDh1ITk6u87kWFhayfPly7+c6dOhQ8vPzWblypfeYzz//HI/H4w17LU1tsNm8eTMLFy4kLi7uqK9Zs2YNDofjkK6blmrXrl3s27fP+9+yP37OtV555RUGDBhA3759j3psi/6c7R7R7A/eeust0+VymXPmzDF//PFH84YbbjCjo6PNrKwsu0vziZtuusmMiooylyxZYmZmZnofpaWlpmma5pYtW8yHH37Y/O6778xt27aZH3zwgdmxY0fzjDPOsLny43fXXXeZS5YsMbdt22Z+/fXX5vDhw834+HgzJyfHNE3TvPHGG8127dqZn3/+ufndd9+ZQ4cONYcOHWpz1SfO7Xab7dq1M++555462/3lMy4qKjJXr15trl692gTMp556yly9erX3zqDp06eb0dHR5gcffGB+//335ujRo80OHTqYZWVl3nOMHDnSPPnkk83ly5ebX331ldmlSxdz3Lhxdl3SUdV3zZWVlebFF19stm3b1lyzZk2df98VFRWmaZrm0qVLzaefftpcs2aNuXXrVvO1114zExISzAkTJth8ZUdW3zUXFRWZd999t7ls2TJz27Zt5sKFC83+/fubXbp0McvLy73n8KfPuVZBQYEZGhpqPv/884e8viV+zvVRuPGR5557zmzXrp0ZFBRkDh482Pzmm2/sLslngMM+Zs+ebZqmae7cudM844wzzNjYWNPlcpmdO3c2f//735sFBQX2Fn4Cxo4da6akpJhBQUFmmzZtzLFjx5pbtmzx7i8rKzNvvvlmMyYmxgwNDTUvvfRSMzMz08aKfWP+/PkmYG7atKnOdn/5jBcvXnzY/5YnTpxomqZ1O/h9991nJiUlmS6XyzznnHMO+Vvs27fPHDdunBkeHm5GRkaakyZNMouKimy4moap75q3bdt2xH/fixcvNk3TNFeuXGkOGTLEjIqKMoODg83u3bubf/nLX+oEgeamvmsuLS01zzvvPDMhIcEMDAw027dvb15//fWH/D+j/vQ513rxxRfNkJAQMz8//5DXt8TPuT6GaZpmozYNiYiIiDQhjbkRERERv6JwIyIiIn5F4UZERET8isKNiIiI+BWFGxEREfErCjciIiLiVxRuRERExK8o3IhIq2cYBu+//77dZYiIjyjciIitrr32WgzDOOQxcuRIu0sTkRYqwO4CRERGjhzJ7Nmz62xzuVw2VSMiLZ1abkTEdi6Xi+Tk5DqPmJgYwOoyev755zn//PMJCQmhY8eOvPPOO3Vev27dOs4++2xCQkKIi4vjhhtuoLi4uM4xs2bNomfPnrhcLlJSUrj11lvr7M/NzeXSSy8lNDSULl268OGHHzbuRYtIo1G4EZFm77777mPMmDGsXbuW8ePHc+WVV7JhwwYASkpKGDFiBDExMXz77bfMmzePhQsX1gkvzz//PLfccgs33HAD69at48MPP6Rz58513uOhhx7iiiuu4Pvvv+eCCy5g/Pjx5OXlNel1ioiP2L1yp4i0bhMnTjSdTqcZFhZW5/Hoo4+apmmtSn/jjTfWec2QIUPMm266yTRN03zppZfMmJgYs7i42Lv/448/Nh0Oh3el59TUVPPee+89Yg2A+ac//cn7vLi42ATMTz75xGfXKSJNR2NuRMR2Z511Fs8//3ydbbGxsd7fhw4dWmff0KFDWbNmDQAbNmygb9++hIWFefefdtppeDweNm3ahGEY7Nmzh3POOafeGvr06eP9PSwsjMjISHJyco73kkTERgo3ImK7sLCwQ7qJfCUkJKRBxwUGBtZ5bhgGHo+nMUoSkUamMTci0ux98803hzzv3r07AN27d2ft2rWUlJR493/99dc4HA66du1KREQE6enpLFq0qElrFhH7qOVGRGxXUVFBVlZWnW0BAQHEx8cDMG/ePAYOHMivfvUrXn/9dVasWMErr7wCwPjx43nggQeYOHEiDz74IHv37uW2227jmmuuISkpCYAHH3yQG2+8kcTERM4//3yKior4+uuvue2225r2QkWkSSjciIjtPv30U1JSUups69q1Kxs3bgSsO5neeustbr75ZlJSUnjzzTfp0aMHAKGhocyfP5/bb7+dQYMGERoaypgxY3jqqae855o4cSLl5eU8/fTT3H333cTHx3P55Zc33QWKSJMyTNM07S5CRORIDMPgvffe45JLLrG7FBFpITTmRkRERPyKwo2IiIj4FY25EZFmTT3nInKs1HIjIiIifkXhRkRERPyKwo2IiIj4FYUbERER8SsKNyIiIuJXFG5ERETEryjciIiIiF9RuBERERG/onAjIiIifuX/AfwsOCDyFugYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(Xtrain, Ytrain,\n",
        "                    epochs=500,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(Xval, Yval),\n",
        "                    shuffle = True,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction and sMAPE"
      ],
      "metadata": {
        "id": "-qB0fayDHdrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEhHEDJz-u3o",
        "outputId": "929e670c-4600-4bee-b065-7a729c2b054f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "    Valori Attesi  Predizioni\n",
            "0            7.72   17.545731\n",
            "1            8.35   13.170266\n",
            "2            7.15   11.756234\n",
            "3            4.97    8.149861\n",
            "4            5.39    6.290635\n",
            "5            8.38   10.180699\n",
            "6           18.05   16.961088\n",
            "7           26.38   24.572052\n",
            "8           27.92   40.341217\n",
            "9           31.97   39.208508\n",
            "10          32.96   40.108181\n",
            "11          29.76   41.124790\n",
            "12          27.53   38.150131\n",
            "13          24.52   38.694969\n",
            "14          23.98   36.150513\n",
            "15          23.91   34.399540\n",
            "16          23.92   37.290310\n",
            "17          27.93   43.491573\n",
            "18          40.13   45.949669\n",
            "19          39.45   43.867119\n",
            "sMAPE: 18.48%\n"
          ]
        }
      ],
      "source": [
        "Yp = model.predict(Xtest)\n",
        "Yp = y_scaler.inverse_transform(Yp)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UviWjawJjJZ"
      },
      "source": [
        "###Support Vector Regressor (SVR)\n",
        "Using the following features:\n",
        "*  24 lagged prices of the previous day in Belgium.\n",
        "*  24 lagged prices of one week before in Belgium.\n",
        "*  The day-ahead grid load forecast in Belgium at prediction hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03s5WLLiJiN5",
        "outputId": "e2117873-14e0-4b1a-c83d-646651373ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ],
      "source": [
        "n_features = 24 + 24 + 24\n",
        "print(n_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "EYwd-WWUOFUB"
      },
      "outputs": [],
      "source": [
        "# Define columns #date is the index!\n",
        "columns = [f'Price_D-1_h{hour}' for hour in hours] + \\\n",
        "          [f'Price_D-7_h{hour}' for hour in hours] + \\\n",
        "          [f'Load_D_h{hour}' for hour in hours]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4Q27cnPOThX"
      },
      "source": [
        "#### Pre-processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "h6FTZQvdOSJ5"
      },
      "outputs": [],
      "source": [
        "train_df.index = pd.to_datetime(train_df.index)\n",
        "val_df.index = pd.to_datetime(val_df.index)\n",
        "test_df.index = pd.to_datetime(test_df.index)\n",
        "\n",
        "train_df.index = train_df.index.round('S')\n",
        "test_df.index = test_df.index.round('S')\n",
        "val_df.index = val_df.index.round('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "dock3LQ_OaWo"
      },
      "outputs": [],
      "source": [
        "indexTrain = train_df.iloc[24:,:].loc[train_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "indexTest = test_df.iloc[24:,:].loc[test_df.index[0] + pd.Timedelta(weeks=1) :].index\n",
        "indexVal = val_df.iloc[24:,:].loc[val_df.index[0] + pd.Timedelta(weeks=1):].index\n",
        "\n",
        "predDatesTrain = indexTrain[::24]\n",
        "predDatesVal = indexVal[::24]\n",
        "predDatesTest = indexTest[::24]\n",
        "\n",
        "indexTrain = pd.DataFrame(index=predDatesTrain, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexVal = pd.DataFrame(index=predDatesVal, columns=['h' + str(hour) for hour in range(24)])\n",
        "indexTest = pd.DataFrame(index=predDatesTest, columns=['h' + str(hour) for hour in range(24)])\n",
        "\n",
        "for hour in range(24):\n",
        "  indexTrain.loc[:, 'h' + str(hour)] = indexTrain.index + pd.Timedelta(hours=hour)\n",
        "  indexVal.loc[:, 'h' + str(hour)] = indexVal.index + pd.Timedelta(hours=hour)\n",
        "  indexTest.loc[:, 'h' + str(hour)] = indexTest.index + pd.Timedelta(hours=hour)\n",
        "\n",
        "# Preallocating in memory the X and Y arrays\n",
        "Xtrain = np.zeros([indexTrain.shape[0], n_features])\n",
        "Ytrain = np.zeros([indexTrain.shape[0], n_hours])\n",
        "Xval = np.zeros([indexVal.shape[0], n_features])\n",
        "Yval = np.zeros([indexVal.shape[0], n_hours])\n",
        "Xtest = np.zeros([indexTest.shape[0], n_features])\n",
        "Ytest = np.zeros([indexTest.shape[0], n_hours])\n",
        "\n",
        "indexFeatures = 0\n",
        "\n",
        "# price D-1, D-7\n",
        "for past_day in [1, 7]:\n",
        "  for hour in range(24): # For each possible horizon\n",
        "        # We define the corresponding past time indexs\n",
        "        pastIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)  - pd.Timedelta(hours=24*past_day)\n",
        "        pastIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values) - pd.Timedelta(hours=24*past_day)\n",
        "\n",
        "        # price D-1/7\n",
        "        Xtrain[:, indexFeatures] = train_df.loc[pastIndexTrain, 'Prices']\n",
        "        Xtest[:, indexFeatures] = test_df.loc[pastIndexTest, 'Prices']\n",
        "        Xval[:, indexFeatures] = val_df.loc[pastIndexVal, 'Prices']\n",
        "        indexFeatures += 1\n",
        "\n",
        "\n",
        "#adding load inputs at day D\n",
        "for hour in range(24):\n",
        "    #define the corresponding future index at time D\n",
        "    futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "    futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "    # Adding Load inputs at day D\n",
        "    Xtrain[:, indexFeatures] = train_df.loc[futureIndexTrain, 'System load forecast']\n",
        "    Xval[:, indexFeatures] = val_df.loc[futureIndexVal, 'System load forecast']\n",
        "    Xtest[:, indexFeatures] = test_df.loc[futureIndexTest, 'System load forecast']\n",
        "    indexFeatures += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "WaffT75dS0cq"
      },
      "outputs": [],
      "source": [
        "# Extracting the predicted values Y\n",
        "for hour in range(24):\n",
        "  futureIndexTrain = pd.to_datetime(indexTrain.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexVal = pd.to_datetime(indexVal.loc[:, 'h' + str(hour)].values)\n",
        "  futureIndexTest = pd.to_datetime(indexTest.loc[:, 'h' + str(hour)].values)\n",
        "\n",
        "  Ytrain[:, hour] = train_df.loc[futureIndexTrain, 'Prices']\n",
        "  Yval[:,hour] = val_df.loc[futureIndexVal, 'Prices']\n",
        "  Ytest[:, hour] = test_df.loc[futureIndexTest, 'Prices']\n",
        "\n",
        "# Redefining indexTest to return only the dates at which a prediction is made\n",
        "indexTest = indexTest.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "RiN4su9IN0Tk"
      },
      "outputs": [],
      "source": [
        "#normalize data to [0,1]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "Xtrain = scaler.fit_transform(Xtrain)\n",
        "Xval = scaler.transform(Xval)\n",
        "Xtest = scaler.transform(Xtest)\n",
        "\n",
        "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Ytrain = y_scaler.fit_transform(Ytrain)\n",
        "Yval = y_scaler.transform(Yval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8msWyFNJOpnR"
      },
      "source": [
        "#### Model, training and prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To consider only the prices and the load on that specific hour!\n",
        "def select_and_concatenate_columns(matrix, range_end, specific_column_index):\n",
        "    # Select the first 'range_end' columns\n",
        "    selected_columns_range = matrix[:, :range_end]\n",
        "\n",
        "    # Select the specific column\n",
        "    specific_column = matrix[:, specific_column_index].reshape(-1, 1)\n",
        "\n",
        "    # Concatenate the selected columns\n",
        "    concatenated_matrix = np.hstack((selected_columns_range, specific_column))\n",
        "\n",
        "    return concatenated_matrix"
      ],
      "metadata": {
        "id": "h9bl7g0sH9kR"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOP5lz-sM7xC",
        "outputId": "e68c9837-b8e4-4d67-ecdc-7eadeba8dfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Valori Attesi  Predizioni\n",
            "0            7.72   25.212949\n",
            "1            8.35   19.775712\n",
            "2            7.15   15.361842\n",
            "3            4.97    6.164310\n",
            "4            5.39    6.219910\n",
            "5            8.38   13.009758\n",
            "6           18.05   23.269352\n",
            "7           26.38    7.626910\n",
            "8           27.92   42.690111\n",
            "9           31.97   46.068627\n",
            "10          32.96   46.453095\n",
            "11          29.76   50.420986\n",
            "12          27.53   39.207184\n",
            "13          24.52   33.889988\n",
            "14          23.98   32.404092\n",
            "15          23.91   22.615516\n",
            "16          23.92   28.254784\n",
            "17          27.93   51.097158\n",
            "18          40.13   57.233654\n",
            "19          39.45   64.502649\n",
            "sMAPE: 22.02%\n"
          ]
        }
      ],
      "source": [
        "# for storing predictions\n",
        "Yp = np.zeros_like(Ytest)\n",
        "\n",
        "C = 9.97  # Penalty parameter\n",
        "epsilon = 0.0038  # Epsilon\n",
        "\n",
        "# Train an individual SVR model for each horizon (hour)\n",
        "for hour in range(n_hours):\n",
        "    svr_model = SVR(C=C, epsilon=epsilon)\n",
        "    X = select_and_concatenate_columns(Xtrain, 48, 48+hour)\n",
        "    svr_model.fit(X, Ytrain[:, hour])     # Train the SVR on the input data for the current hour\n",
        "    Xt = select_and_concatenate_columns(Xtest, 48, 48+hour)\n",
        "    Yp[:, hour] = svr_model.predict(Xt)\n",
        "\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "Yp = y_scaler.inverse_transform(Yp)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Valori Attesi': Ytest.flatten(),\n",
        "    'Predizioni': Yp.flatten()\n",
        "})\n",
        "\n",
        "print(results.head(20))\n",
        "\n",
        "# Calculate and print the metrics\n",
        "smape_value = smape(tf.cast(Ytest, dtype=tf.float64), tf.cast(Yp, dtype=tf.float64))\n",
        "print(f'sMAPE: {smape_value:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "900jp2ldSC6w",
        "KR5tPOVOiHV9",
        "MLQe3qyuiOJ8",
        "F4r7AeNlou5z"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}